print("test for git")
install.packages("rmarkdown")
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
print("HEllo")
getwd()
install.packages("swirl")
packageVersion("swirl")
library(swirl)
install_from_swirl("R Programming")
swirl()
5+7
x <- 5 + 7
x
y <- x-3
y
c(1.1, 9, 3.14)
Z <- c(1.1, 9, 3.14)
z <- c(1.1, 9, 3.14)
"?c"
?c
z
c(z, 555, z)
z * 2 + 100
my_sqrt <- sqrt(z - 1)
my_sqrt
my_div <- z / my_sqrt
my_div
c(1, 2, 3, 4) + c(0, 10)
c(1, 2, 3, 4) + c(0, 10, 100)
z * 2 + 100
z * 2 + 1000
my_div
getwd()
ls()
x <- 9
ls()
dir()
?list.files
list.files().args()
list.files.args()
args(list.files)
old.dir <- getwd()
dir.create()
dir.create( "testdir")
setwd("testdir")
file.create("mytest.R")
dir()
file.exists("mytest.R")
file.info("mytest.R")
file.rename("mytest.R")
file.rename("mytest.R", "mytest2.R")
file.copy("mytest2.R", "mytest3.R")
file.path("mytest3.R")
file.path('folder1', 'folder2' )
?dir.create
dir.create(file.path("testdir2", "testdir3"))
dir.create(file.path("testdir2", "testdir3"), recursive = TRUE)
setwd(old.dir)
1:20
pi:10
15:1
?`:`
seq(1, 20)
seq(0, 10, by=0.5)
my_seq <- seq(5, 10, length=30)
length(my_seq)
1:length(my_seq)
seq(along.with = my_seq)
seq_along(my_seq)
rep(0, times = 40)
rep(c(0, 1, 2), times = 10)
rep(c(0, 1, 2), each = 10)
num_vect <- c(0.5, 55, -10, 6)
tf <- num_vect < 1
tf
num_vect >= 6
my_char <- c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
my_name <- c(my_char, "Anna")
my_name
paste(my_char, collapse = " ")
paste(my_name, collapse = " ")
paste("Hello", "world!", sep = " ")
paste(1:3, c("X", "Y", "Z"),  sep = "")
paste(LETTERS, 1:4, sep = "-")
x <- c(44, NA, 5, NA)
x*3
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y, z), 100)
my_na <- is.na(my_data)
my_na
my_data == NA
sum(my_na)
my_data
0/0
Inf -Inf
x
x[1:10]
x[is.na(x)]
y <- x[!is.na(x)]
y
y[y > 0]
x[x > 0]
x[!is.na(x) & x > 0]
x[c(3,5,7)]
x[0]
X[300]
x[300]
x[3000]
x[c(-2, -10)]
x[-c(2, 10)]
vect <- c(foo = 11, bar = 2, norf = NA)
vect
names(vect)
vect2 <- c(11, 2, NA)
names(vect2) <- c("foo", "bar", "norf")
identical(vect, vect2)
vect["bar"]
vect[c("foo", "bar")]
my_vector <- 1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector) <- c(4, 5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix <- my_vector
?matrix
my_matrix2 <- (1:20, 4, 5)
my_matrix2 <- (seq(1, 20), 4, 5)
my_matrix2 <- (1:20, nrow=4, ncol=5)
my_matrix2 <- matrix(1:20, nrow=4, ncol=5)
identical(my_matrix, my_matrix2)
patients <- c("Bill", "Gina", "Kelly", "Sean")
cbind(patients, my_matrix)
my_data <- data.frame(patients, my_matrix)
my_data
class(my_data)
cnames <- c("patient", "age", "weight", "bp", "rating", "test")
?colnames
colnames(my_data, cnames)
colnames(my_data) <- cnames
my_data
add2 <- function(x, y) {
x + y
}
add2(1,2)
above10 <- function(x) {
use <- x > 10
x[use]
}
above10(1:20)
above <- function(x, n) {
use <- x > n
x[use]
}
x <- 1:20
above(x, 5)
above <- function(x, n = 10) {
use <- x > n
x[use]
}
above(x)
columnmean <- function(y) {
nc <- ncol(y)
means <- numeric(nc)
for (i in 1:nc) {
means[i] <- mean(y[, i])
}
means
}
source('~/work/data_science_coursera/coursera_course/functions.R')
columnmean(airquality)
source('~/work/data_science_coursera/coursera_course/functions.R')
columnmean(airquality)
lm
search()
formals(above)
y <- 10
f <- function(x) {}
}
y <- 10
f <- function(x) {}
y <- 10
f <- function(x) {
y <- 2
}
y <- 10
f <- function(x) {
y <- 2
y^2 + g(x)
}
g <- function(x) {}
g <- function(x) { x*y}
f(3)
unclass(as.Date("1968-04-29"))
as.Date("1968-04-29")
unclass(as.Date("2020-11-12"))
x <- Sys.time()
x
p <- as.POSIXlt(x)
p
names(unclass(p))
p$sec
p
unclass(p)
?strptime
savehistory("~/work/data_science_coursera/intro_r/intro_r.Rhistory")
print("test for git")
install.packages("rmarkdown")
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
print("HEllo")
getwd()
directory <- "/Users/ashipunova/work/data_science_coursera/intro_r/specdata"
files <- list.files(path = directory, pattern = "*.csv", full.names = T)
tbl <- sapply(files[1:10], read_csv, simplify=FALSE) %>% bind_rows(.id = "ID")
library(magrittr)
tbl <- sapply(files[1:10], read_csv, simplify=FALSE) %>% bind_rows(.id = "ID")
library(readr)
version
directory <- "/Users/ashipunova/work/data_science_coursera/intro_r/specdata"
filenames <- list.files(directory, pattern="*.csv", full.names=TRUE)
ldf <- lapply(filenames, read.csv)
View(ldf)
res <- lapply(ldf, summary)
View(res)
res[1]
res[1]["sulfate"]
res[1]["sulfate"]["Mean"]
res[1]$"sulfate"
res[1][1]
names(res) <- substr(filenames, 6, 30)
names()
names
substr(filenames, 6, 30)
subset(ldf, ldf$ID == 2)
head (ldf)
ldf[1]
ldf[1][1]
ldf[[1]][1]
ldf[[1]][[1]]
head(ldf[[1]][[1]])
head(ldf[[1]]["sulfate"])
head(ldf[[1]]["ID"])
res[[1]]
res[[122]]
res[[122]]$sulfate
res[[122]]["sulfate"]
class(res[[122]])
res[[122]][1]
res[[122]][1,1]
res[[122]][1,2]
f122 <-  res[[122]]
f122[1,3]
f122[1]
f122
summary(f122)
class(f122)
sum(f122)
?summary.table(f122)
?summary
summary.table(f122)
f122[,1]
f122[,2]
View(ldf)
read.csv(paste(directory, "/001.csv"))
read.csv(paste(directory, "/001.csv", ""))
?paste
f1 <- read.csv(paste(directory, "/001.csv", sep = ""))
View(f1)
?summary
head(f1)
f1$sulfate
!is.na(f1$sulfate)
mean(f1$sulfate[!is.na(f1$sulfate)])
mean(f1$sulfate)
summary(f1)
summary(f1)["sulfate"]
summary(f1)[["sulfate"]]
str(summary(f1))
dim(summary(f1))
dimnames(summary(f1))
summary(f1)[[2]]["sulfate"]
summary(f1)[[2]]
summary(f1)[[3]]
summary(f1)[[4]]
summary(f1)[[5]]
summary(f1)$sulfate
colnames(summary(f1))
colnames(summary(f1))[2]
summary(f1)$colnames(summary(f1))[2]
sulf_name <- colnames(summary(f1))[2]
summary(f1)[sulf_name]
sulf_name
str(summary(summary(f1)))
str(summary(f1))
unclass(summary(f1))
unclass(summary(f1))$sulfate
unclass(summary(f1))["sulfate"]
colnames(unclass(summary(f1)))
unclass(summary(f1))["   sulfate"]
unclass(summary(f1))[2]
unclass(summary(f1))[3]
unclass(summary(f1))[4]
as.data.frame(t(unclass(summary(f1))))
res1 <- as.data.frame(t(unclass(summary(f1))))
res1
dim(re1)
dim(res1)
res1[2,]
?summary
?mean
na.rm = TRUE
View(res)
View(ldf)
fl1 < ldf[1:2]
fl1 <- ldf[1:2]
summary(fl1)
fl1
names(fl1)
names(fl1[1])
names(fl1[[1]])
fl1[[1]]$sulfate
mean(fl1[[1]]$sulfate, na.rm = TRUE)
getwd
getwd()
setwd("/Users/ashipunova/Documents/GitHub/datasciencecoursera/")
getwd()
s <- "sulfate"
mean(fl1[[1]][s], na.rm = TRUE)
mean(fl1[[1]]["sulfate"], na.rm = TRUE)
ff <- fl1[[1]]
ff["sulfate"]
mean(ff["sulfate"], na.rm = TRUE)
head(ff)
head(ff$sulfate)
head(ff[sulfate])
head(ff["sulfate"])
mean(ff["sulfate"])
mean(ff$sulfate)
mean(ff$sulfate, rm.na = TRUE)
mean(ff$sulfate, na.rm = TRUE)
mean(ff["sulfate"], na.rm = TRUE)
s
ff$s
pp <- "sulfate"
ff[pp]
mean(ff[pp], na.rm = TRUE)
fp <- ff[pp]
fp
head(ff[pp])
head(fp)
mean(fp, na.rm = TRUE)
fp <- as.table(ff[pp])
fp <- as.data.frame(ff[pp])
fp
summary(fp)
summary(fp$mean)
unclass(summary(fp))
str(summary(fp))
mean(fp)
df1 <- subset(fl, !is.na(sulfate))
df1 <- subset(fl1, !is.na(sulfate))
fl1
head(fl1)
ff["sulfate"]
mean(ff$sulfate, rm.na = TRUE)
fl1 < ldf[1:2]
fl1 <- ldf[1:2]
savehistory("~/Documents/GitHub/datasciencecoursera/pollut.Rhistory")
data_f1 <- ""
head(fl1[[1]])
fl1[[1]]$sulfate
!is.na(fl1[[1]])
data_f1 <- subset(fl1[[1]], !is.na(fl1[[1]]))
head(data_f1)
head(!is.na(fl1[[1]]$sulfate))
data_f1 <- subset(fl1[[1]], !is.na(fl1[[1]]$sulfate))
head(data_f1)
mean(data_f1$sulfate)
mean(data_f1["sulfate"])
?read.csv
class(data_f1)
str(data_f1)
mat <- as.matrix(data_f1)
class(mat)
nrow(mat)
ncol(mat)
names(mat)
mat[1:4, 1:2]
mat[sulf_name]
mat[,2]
files <- list.files(path = directory, pattern = "*.csv", full.names = T)
files[4]
mean(data_f1[,"sulfate"])
sul_n
sulf_name
sulf_name < "sulfate"
sulf_name <- "sulfate"
mean(data_f1[, sulf_name])
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
?for
?for()
?for
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean(pollutant = "sulfate", id = 1:3)
directory
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean(pollutant = "sulfate", id = 1:3)
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean(directory, pollutant = "sulfate", id = 1:3)
print(pollutantmean(directory, pollutant = "sulfate", id = 1:3))
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean(directory, pollutant = "sulfate", id = 1:3)
head(res)
str(res)
head(ldf[[1]]["ID"])
head(ldf[[1]]["sulfate"])
head(ldf[[1]][sulf_name])
files <- list.files(path = directory, pattern = "*.csv", full.names = T)
id <- 2:4
for (i in id) {
df<-read.csv(files[i])
mean.df <- mean(df[, sulf_name], na.rm = TRUE)
print(mean.df)
}
all_means <- list()
all_means <- vector("list", length = length(id))
summary(all_means)
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean(directory, pollutant = "sulfate", id = 1:3)
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean(directory, pollutant = "sulfate", id = 1:3)
x <- c(2,3,4)
all_means <- vector("list", length = length(id))
id
class(all_means)
mean(all_means)
all_means <- vector(length = length(id))
class(all_means)
aall_all_means
all_means
all_means <- vector("vector", length = length(id))
?vector
all_means <- vector("numeric", length = length(id))
all_means
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean(directory, pollutant = "sulfate", id = 1:3)
x <- c(3.880701, 4.327613, 4.460811)
class(x)
mean(x)
files[1]
res$`files[1]`
View(res)
res <- lapply(ldf, summary)
res[1]
res$`files[1]`
res[[1]]
res[[1]][,sulfate]
res[[1]][, "sulfate"]
names(res[[1]])
class(res[[1]])
?table
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean(directory, pollutant = "sulfate", id = 2:5)
pollutantmean(directory, pollutant = "sulfate", id = 1:3)
pollutantmean(directory, pollutant = "sulfate")
print(R.version.string)
savehistory("~/Documents/GitHub/datasciencecoursera/pollutantmean.Rhistory")

getwd()
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean(directory, "sulfate", 1:10)
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean(directory, "sulfate", 1:10)
pollutantmean(directory, "nitrate", 70:72)
pollutantmean(directory, "nitrate", 23)
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean(directory, "nitrate", 23)
pollutantmean(directory, "nitrate", 1:23)
pollutantmean(directory, "nitrate")
pollutantmean(directory, "nitrate", 70:72)
x <- c(0.0000000, 0.0000000, 0.0000000, 0.2551667, 1.4316005, 2.3632054)
mean(x)
x <- c(0.0000000, 0.0000000, 0.0000000, 0.2551667, 1.4316005, 2.3632054, NA, NA)
mean(x)
mean(x, na.rm = TRUE)
x <- c(0.0000000, 0.0000000, 0.0000000, NA, NA, 0.2551667, 1.4316005, 2.3632054, NA, NA)
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean(directory, "nitrate", 70:72)
pollutantmean(directory, "nitrate", 23)
pollutantmean("specdata", "sulfate", 1:10)
getwd
getwd()
setwd("/Users/ashipunova/work/data_science_coursera/intro_r")
getwd()
pollutantmean("specdata", "sulfate", 1:10)
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean("specdata", "sulfate", 1:10)
View(ldf)
files <- list.files(path = directory, pattern = "*.csv", full.names = T)
files <- list.files(path = "specdata", pattern = "*.csv", full.names = T)
files[1]
files[10]
id <- 1:10
all_means <- vector("numeric", length = length(id))
for (i in id) {
df <- read.csv(files[i])
mean.df <- mean(df[, pollutant], na.rm = TRUE)
print(summary(df))
all_means[i] <- mean.df
}
pollutant <- "sulfate"
for (i in id) {
df <- read.csv(files[i])
mean.df <- mean(df[, pollutant], na.rm = TRUE)
print(summary(df))
all_means[i] <- mean.df
}
res[[1]]
str(res[[1]])
res[[1]]$`sulfate`
summary(f1)
s_f <- summary(f1)
str(s_f)
class(s_f)
sulfate1_10_means <- c(3.881, 4.461, 4.328, 4.215, 4.210, 4.102, 3.820, 4.781, 3.646, 0.6244)
mean(sulfate1_10_means)
pollutantmean("specdata", "sulfate", 1:10)
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
directory
files <- list.files(path = directory, pattern = "*.csv", full.names = T)
dat <- data.frame()
for (i in id) {
dat <- rbind(dat, read.csv(files_list[i]))
}
files_list <- list.files(path = directory, pattern = "*.csv", full.names = T)
for (i in id) {
dat <- rbind(dat, read.csv(files_list[i]))
}
head(dat)
summary(dat)
dat_subset <- dat[which(dat[, "ID"] == id)]
id
dat_subset <- dat[which(dat[, "ID"] in id)]
dat[which(dat$ID == 25), ]
dat[which(dat$ID == 5), ]
median(dat_30$Weight)
mean(dat$sulfate)
mean(dat$sulfate, na.rm=TRUE)
summary(dat)
View(dat)
mean(dat[, sulf_name], na.rm=TRUE)
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean(directory, "nitrate", 23)
pollutantmean("specdata", "nitrate", 70:72)
?bind
?rbind
directory
files_full <- list.files(path = directory, pattern = "*.csv", full.names = T)
summary(files_full)
head(files_full)
length(files_full)
tmp <- vector(mode = "list", length = length(files_full))
summary(tmp)
seq_along(files_full)
?seq_along
for (i in seq_along(files_full)) {
tmp[[i]] <- read.csv(files_full[[i]])
}
str(tmp)
str(lapply(files_full, read.csv))
head(tmp[[1]][,"sulfate"])
head(tmp[[10]][,"ID"])
output <- do.call(rbind, tmp)
str(output)
dat <- lapply(files_full, read.csv)
head(dat)
str(dat)
tmp1 <- lapply(files_full, read.csv)
identical(tmp, tmp1)
?lapply
?rapply
dat <- do.call(rbind, tmp)
pollutant
mean(dat[, pollutant], na.rm = TRUE)
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean("specdata", "nitrate", 70:72)
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean(directory, "nitrate", 23)
files_full <- list.files(path = directory, pattern = "*.csv", full.names = T)
id
files_full[id]
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean(directory, "nitrate", 23)
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean("specdata", "nitrate", 70:72)
length(dat)
summary(dat)
id
tmp <- lapply(files_full[id], read.csv)
dat <- do.call(rbind, tmp)
names(dat)
str(names)
str(dat)
dat[!is.na(dat$sulfate) & !is.na(dat$nitrate)]
!is.na(dat$sulfate) & !is.na(dat$nitrate)
length(!is.na(dat$sulfate) & !is.na(dat$nitrate))
d <- subset(dat, dat[!is.na(dat$sulfate)])
dat[!is.na(dat$sulfate)
]
head(dat$sulfate)
dat$ID[!is.na(dat$sulfate)]
length(dat$ID[!is.na(dat$sulfate) $ !is.na(dat$nitrate)])
length(dat$ID[!is.na(dat$sulfate) & !is.na(dat$nitrate)])
head(tmp)
summary(tmp)
savehistory("~/work/data_science_coursera/intro_r/complete.Rhistory")

View(tmp)
summary(tmp)
files_full[id]
for(f in tmp) {}
for(f in tmp) {
print(tmp$ID[!is.na(tmp$sulfate) & !is.na(tmp$nitrate)])
}
for(f in tmp) {
print(length(tmp$ID[!is.na(tmp$sulfate) & !is.na(tmp$nitrate)])
}
length(tmp$ID[!is.na(tmp$sulfate) & !is.na(tmp$nitrate)]
length(tmp$ID[!is.na(tmp$sulfate) & !is.na(tmp$nitrate)])
tmp$ID[!is.na(tmp$sulfate) & !is.na(tmp$nitrate)]
tmp$ID[!is.na(tmp$sulfate)]
tmp[[1]]$ID[!is.na(tmp[[1]]$sulfate)]
for(f in tmp) {
print(length(f$ID[!is.na(f$sulfate) & !is.na(f$nitrate)])
}
for(f in tmp[1:2]) {
print(head(f))
f$ID[!is.na(f$sulfate) & !is.na(f$nitrate)]
}
for(f in tmp[1:2]) {
f$ID[!is.na(f$nitrate)]
}
for(f in tmp[1:2]) {
print(f$ID[!is.na(f$nitrate)])
}
dat$ID[!is.na(dat$sulfate) & !is.na(dat$nitrate)]
com <- dat$ID[!is.na(dat$sulfate) & !is.na(dat$nitrate)]
summary(com)
str(com)
as.data.frame(table(com))
t(as.data.frame(table(com))[,2])
com_res <- as.data.frame(table(com))
names(com_res)
names(com_res) <- c("id", "nobs")
names(com_res)
as.data.frame(table(com), row.names = c("id", "nobs"))
as.data.frame(table(com), col.names = c("id", "nobs"))
as.data.frame(table(com), col.names = names(c("id", "nobs")))
as.data.frame(table(com), col.names = c("id", "nobs"))
source('~/work/data_science_coursera/intro_r/complete.R')
savehistory("~/work/data_science_coursera/intro_r/complete1.Rhistory")

source('~/work/data_science_coursera/intro_r/complete.R')
com <- dat$ID[!is.na(dat$sulfate) & !is.na(dat$nitrate)]
complete("specdata", 1)
source('~/work/data_science_coursera/intro_r/complete.R')
complete("specdata", 1)
complete("specdata", c(2, 4, 8, 10, 12))
complete("specdata", 3)
table(com)
as.data.frame(table(com))
names(com_res) <- c("id", "nobs")
source('~/Documents/GitHub/datasciencecoursera/complete.R')
complete("specdata", 1)
complete("specdata", c(2, 4, 8, 10, 12))
complete("specdata", 3)
as.data.frame(com)
files_full <- list.files(path = directory, pattern = "*.csv", full.names = T)
tmp <- lapply(files_full, read.csv)
dat <- do.call(rbind, tmp)
com <- dat$ID[!is.na(dat$sulfate) & !is.na(dat$nitrate)]
com_res <- as.data.frame(table(com))
names(com_res) <- c("id", "nobs")
com_res
com_res[com_res$id >800]
com_res$id
com_res$id > 800
as.numeric(as.character(com_res$id)) > 800
as.numeric(as.character(com_res$id))
names(com_res)
as.numeric(as.character(com_res$nobs)) > 800
com_res$id[as.numeric(as.character(com_res$nobs)) > 800]
class(!$)
com_res800 <- com_res$id[as.numeric(as.character(com_res$nobs)) > 800]
class(com_res800)
table(com_res$id[as.numeric(as.character(com_res$nobs)) > 800])
as.numeric(as.character(com_res800))
com_res_l <- as.numeric(as.character(com_res800))
com_res_l
class(com_res_l)
length(com_res_l)
?cor
dat$sulfate[dat$ID == 2]
sul2 <- dat$sulfate[dat$ID == 2]
nit2 <- dat$nitrate[dat$ID == 2]
cor(sul2, nit2)
class(sul2)
nit20 <- subset(dat$nitrate, dat$ID == 2)
identical(nit2, nit20)
identical(nit2, sul2)
source('~/Documents/GitHub/datasciencecoursera/complete.R')
cr <- corr("specdata", 150)
head(cr)
source('~/Documents/GitHub/datasciencecoursera/complete.R')
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr1 <- corr("specdata", 150)
identical(cr, cr1)
head(cr)
class(1:10)
nit2 <- dat$nitrate[dat$ID == 2]
class(nit2)
com_res$id[as.integer(as.character(com_res$nobs)) > threshold]
threshold <- 800
com_res$id[as.integer(as.character(com_res$nobs)) > threshold]
cor(sul2, nit2, na.rm = TRUE)
cor(x = sul2, y = nit2, na.rm = TRUE)
cor(x = sul2, y = nit2)
class(ok_ids)
com_res0 <- com_res$id[as.numeric(as.character(com_res$nobs)) > threshold]
ok_ids <- as.numeric(as.character(com_res0))
dat.sulfate <- subset(dat$sulfate, dat$ID in ok_ids)
dat.sulfate <- subset(dat$sulfate, dat$ID ok_ids)
?subset
dat[dat$ID == 2]
dat[dat$ID = 2]
dat$sulfate[dat$ID == 2]
ld <- lapply(ok_ids, function(x){dat$sulfate[dat$ID == x]} )
selected_sulfate <- lapply(ok_ids, function(x){dat$sulfate[dat$ID == x]})
selected_sulfate_list <- lapply(ok_ids, function(x){dat$sulfate[dat$ID == x]})
selected_sulfate <- do.call(rbind, selected_sulfate_list)
View(selected_sulfate)
which(dat$ID %in% ok_ids)
ok_ids
dat$sulfate[(dat$ID %in% ok_ids)]
tmp_ds <- dat$sulfate[(dat$ID %in% ok_ids)]
tmp_ds1 <- dat$sulfate[dat$ID %in% ok_ids]
identical(tmp_ds, tmp_ds1)
table(dat$ID %in% ok_ids)
View(selected_sulfate)
View(selected_sulfate_list)
1 %in% 1:3
1 %in% 2:3
1 %in% ok_ids
2 %in% ok_ids
4018*31
View(selected_sulfate)
View(selected_sulfate_list)
selected_sulfate_list[[1]]
selected_sulfate_list[[1]][1:10]
selected_sulfate_list <- lapply(ok_ids, function(x){dat$sulfate[dat$ID == x]})
selected_sulfate <- do.call(rbind, selected_sulfate_list)
selected_nitrate_list <- lapply(ok_ids, function(x){dat$nitrate[dat$ID == x]})
selected_nitrate <- do.call(rbind, selected_nitrate_list)
View(selected_sulfate)
View(selected_sulfate_list)
View(selected_nitrate)
View(selected_sulfate)
str(selected_nitrate_list)
head(str(selected_nitrate_list))
str(selected_sulfate_list)
cummary(selected_sulfate_list)
summary(selected_sulfate_list)
summary(selected_sulfate_list)[1:3]
summary(selected_nitrate_list)[1:3]
identical(summary(selected_sulfate_list), summary(selected_nitrate_list))
cor(selected_sulfate_list, selected_nitrate_list)
typeof(selected_sulfate_list)
selected_sulfate_0 <- selected_sulfate_list[is.na(selected_sulfate_list)] <- 0
View(selected_sulfate_list)
View(selected_sulfate)
selected_sulfate_list[is.na(selected_sulfate_list)] <- 0
View(selected_sulfate_list)
typeof(selected_nitrate_list)
source('~/Documents/GitHub/datasciencecoursera/complete.R')
source('~/Documents/GitHub/datasciencecoursera/corr.R')
id <- 1:10
directory <- "/Users/ashipunova/work/data_science_coursera/intro_r/specdata"
complete("specdata", 3)
complete("specdata", 30:25)
source('~/Documents/GitHub/datasciencecoursera/complete.R')
files_full <- list.files(path = directory, pattern = "*.csv", full.names = T)
id
tmp <- lapply(files_full[id], read.csv)
dat <- do.call(rbind, tmp)
com <- dat$ID[!is.na(dat$sulfate) & !is.na(dat$nitrate)]
com_res <- as.data.frame(table(com))
names(com_res) <- c("id", "nobs")
com_res
complete("specdata", 1)
files_full[id]
source('~/Documents/GitHub/datasciencecoursera/complete.R')
complete("specdata", 1)
source('~/Documents/GitHub/datasciencecoursera/complete.R')
complete("specdata", 1)
class(files_full[id])
?list.files
savehistory("~/work/data_science_coursera/intro_r/complete2.Rhistory")

source('~/Documents/GitHub/datasciencecoursera/complete.R')
complete("specdata", 1)
class(files_list)
str(lapply(files_full[id], read.csv))
weightmedian <- function(directory, day)  {
files_list <- list.files(directory, full.names=TRUE)   #creates a list of files
dat <- data.frame()                             #creates an empty data frame
for (i in 1:5) {
#loops through the files, rbinding them together
dat <- rbind(dat, read.csv(files_list[i]))
}
dat_subset <- dat[which(dat[, "Day"] == day),]  #subsets the rows that match the 'day' argument
median(dat_subset[, "Weight"], na.rm=TRUE)      #identifies the median weight
#while stripping out the NAs
}
dataset_url <- "http://s3.amazonaws.com/practice_assignment/diet_data.zip"
download.file(dataset_url, "diet_data.zip")
unzip("diet_data.zip", exdir = "diet_data")
list.files("diet_data")
andy <- read.csv("diet_data/Andy.csv")
head(andy)
length(andy$Day)
dim(andy)
str(andy)
summary(andy)
names(andy)
andy[1, "Weight"]
andy[30, "Weight"]
andy[which(andy$Day == 30), "Weight"]
andy[which(andy[,"Day"] == 30), "Weight"]
subset(andy$Weight, andy$Day==30)
andy_start <- andy[1, "Weight"]
andy_end <- andy[30, "Weight"]
andy_loss <- andy_start - andy_end
andy_loss
files <- list.files("diet_data")
files
files[1]
files[2]
files[3:5]
head(read.csv(files[3]))
weightmedian <- function(directory, day)  {
files_list <- list.files(directory, full.names=TRUE)   #creates a list of files
dat <- data.frame()                             #creates an empty data frame
for (i in 1:5) {
#loops through the files, rbinding them together
dat <- rbind(dat, read.csv(files_list[i]))
}
dat_subset <- dat[which(dat[, "Day"] == day),]  #subsets the rows that match the 'day' argument
median(dat_subset[, "Weight"], na.rm=TRUE)      #identifies the median weight
#while stripping out the NAs
}
files_list[1]
files_list[1:3]
lapply(files_full[1:3], read.csv)
source('~/Documents/GitHub/datasciencecoursera/complete.R')
complete("specdata", 1)
version
source('~/Documents/GitHub/datasciencecoursera/complete.R')
complete("specdata", 1)
setwd("/Users/ashipunova/work/data_science_coursera/intro_r")
complete("specdata", 1)
source('~/Documents/GitHub/datasciencecoursera/complete.R')
complete("specdata", 1)
source('~/Documents/GitHub/datasciencecoursera/complete.R')
complete("specdata", 1)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
typeof(selected_nitrate_list)
class(selected_nitrate_list)
selected_nitrate_list[1:2]
selected_nitrate_list[1]
selected_nitrate_list[1][1]
t(simplify2array(selected_nitrate_list))
selected_nitrate_b <- do.call(rbind, selected_nitrate_list)
selected_nitrate <- do.call(rbind, selected_nitrate_list)
head(selected_nitrate)
typeof(selected_nitrate)
selected_nitrate[1]
selected_nitrate[-1]
summary(selected_nitrate)
class(selected_nitrate)
selected_sulfate <- do.call(rbind, selected_sulfate_list)
cor(selected_nitrate, selected_sulfate)
head(str(selected_sulfate_list))
len <- length(selected_sulfate_list)
len
len1 <- length(selected_nitrate_list)
identical(len, len1)
for (i in 1:len) {
cor(selected_sulfate_list[i], selected_nitrate_list[i])
}
head(str(selected_sulfate_list[1])
)
typeof(selected_sulfate_list[1]))
typeof(selected_sulfate_list[1])
class(selected_sulfate_list[1])
dim(selected_sulfate_list[1])
dim(selected_sulfate_list)
class(selected_sulfate_list)
mt1 <- matrix(unlist(selected_sulfate_list))
summary(mt1)
typeof(mt1)
mt1
mt1 <- matrix(unlist(selected_sulfate_list[1]))
mt1
summary(mt1)
dim(mt1)
mt1[1:10]
mt1[3650:3652]
mt2 <- matrix(unlist(selected_nitrate_list[1]))
cor(mt1, mt2)
dim(mt2)
mt2 <- matrix(unlist(selected_nitrate_list[2]))
mt1 <- matrix(unlist(selected_sulfate_list[2]))
cor(mt1, mt2)
selected_nitrate_list <- lapply(ok_ids, function(x){dat$nitrate[dat$ID == x & !is.na(dat$sulfate) & !is.na(dat$nitrate)]})
selected_sulfate_list <- lapply(ok_ids, function(x){dat$sulfate[dat$ID == x & !is.na(dat$sulfate) & !is.na(dat$nitrate)]})
length(selected_sulfate_list)
i <- 2
mt_sulf <- matrix(unlist(selected_sulfate_list[i]))
mt_nitr <- matrix(unlist(selected_nitrate_list[i]))
dim(mt_nitr)
mt_nitr
mt_sulf
selected_sulfate_list
cor(selected_sulfate_list, selected_nitrate_list)
class(selected_nitrate_list)
typeof(selected_nitrate_list)
dim(selected_nitrate_list)
selected_nitrate_list[1]
length(selected_nitrate_list)
length(selected_nitrate_list[2])
length(selected_nitrate_list[1])
class(selected_nitrate_list[1])
unlist(selected_nitrate_list[1])
mt_sulf <- matrix(unlist(selected_sulfate_list[i]))
mt_nitr <- matrix(unlist(selected_nitrate_list[i]))
cor(mt_sulf, mt_nitr)
cor(unlist(selected_sulfate_list[i]), unlist(selected_nitrate_list[i]))
selected_sulfate_list[i][1:10]
selected_sulfate_list[[1]
]
selected_sulfate_list[[1]][1:10]
selected_nitrate_list[[1]][1:10]
sl <- selected_sulfate_list[[1]][1:10]
nl <- selected_nitrate_list[[1]][1:10]
class(sl)
cor(sl, nl)
i
mt_sulf <- matrix(unlist(selected_sulfate_list[[i]]))
mt_nitr <- matrix(unlist(selected_nitrate_list[[i]]))
class(mt_nitr)
cor(mt_sulf, mt_nitr)
mt_sulf <- selected_sulfate_list[[i]]
mt_nitr <- selected_nitrate_list[[i]]
cor(mt_sulf, mt_nitr)
class(mt_sulf)
mt_sulf
class(selected_sulfate_list[[1]])
selected_sulfate_list[[1]]
mt_sulf <- selected_sulfate_list[[2]]
mt_nitr <- selected_nitrate_list[[2]]
cor(mt_sulf, mt_nitr)
length(mt_sulf)
mt_sulf
summary(mt_sulf)
summary(selected_sulfate_list)
mt_nitr <- selected_nitrate_list[[1]]
mt_sulf <- selected_sulfate_list[[1]]
summary(mt_sulf)
cor(mt_sulf, mt_nitr)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 150)
head(cr)
seq_len(31)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 150)
len(cr)
length(cr)
head(cr)
cc <- c(-0.01895754 -0.14051254 -0.04389737 -0.06815956 -0.12350667 -0.07588814)
identical(cc, cr)
class(c)
class(cr)
class(cc)
cc
cc <- c(-0.01895754, -0.14051254, -0.04389737, -0.06815956, -0.12350667, -0.07588814)
cc
identical(cc, cr)
cc -cr
cr
summary(cr)
cr <- corr("specdata", 400)
head(cr)
summary(cr)
cr <- corr("specdata", 5000)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 400)
head(cr)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 400)
head(cr)
summary(cr)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 400)
summary(cr)
head(cr)
cr <- corr("specdata")
summary(cr)
length(cr)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata")
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata")
complete("specdata")
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata")
length(cr)
complete("specdata")
threshold = 0
directory
com_res0 <- com_res$id[as.numeric(as.character(com_res$nobs)) > threshold]
length(com_res)
summary(com_res)
dim(com_res)
complete("specdata", c(2, 4, 8, 10, 12))
complete("specdata", 30:25)
##   id nobs
## 1 30  932
## 2 29  711
## 3 28  475
## 4 27  338
## 5 26  586
## 6 25  463
complete("specdata", 30:25)
com_res0 <- com_res$id[as.numeric(as.character(com_res$nobs > threshold)) ]
as.numeric(as.character(com_res$nobs))
com_res$nobs
complete("specdata")
com_res$nobs
com_result <- complete("specdata")
length(com_res)
length(com_res$nobs)
length(com_result)
length(com_result$nobs)
source('~/Documents/GitHub/datasciencecoursera/complete.R')
source('~/Documents/GitHub/datasciencecoursera/corr.R')
length(com_result$nobs)
cr <- corr("specdata", 150)
com_result <- complete("specdata")
head(com_result)
threshold
threshold <- 500
com_result$id[as.numeric(as.character(com_result$nobs)) > threshold]
v
com_res0 <- com_result$id[as.numeric(as.character(com_result$nobs)) > threshold]
head (com_res0)
length(com_res0)
dim(com_res0)
com_result$nobs[as.numeric(as.character(com_result$nobs)) > threshold]
ok_ids <- as.numeric(as.character(com_res0))
selected_sulfate_list <- lapply(ok_ids, function(x){dat$sulfate[dat$ID == x]})
View(selected_sulfate_list)
selected_nitrate_list <- lapply(ok_ids, function(x){dat$nitrate[dat$ID == x]})
len <- length(selected_sulfate_list)
all_cors <- vector("numeric", length = length(len))
for (i in 1:len) {
print(i)
mt_sulf <- selected_sulfate_list[[i]]
mt_nitr <- selected_nitrate_list[[i]]
print(length(mt_sulf))
print(length(mt_nitr))
all_cors[[i]] <- cor(mt_sulf, mt_nitr, use = "pairwise.complete.obs")
}
mt_sulf <- selected_sulfate_list[[2]]
dat$sulfate[dat$ID == 17]
dat$sulfate[dat$ID == 24]
head(dat)
dat$ID
dat$ID == 24
dat$Date[dat$ID == 24]
unique(dat$ID)
source('~/Documents/GitHub/datasciencecoursera/complete.R')
source('~/Documents/GitHub/datasciencecoursera/corr.R')
source('~/Documents/GitHub/datasciencecoursera/complete.R')
source('~/Documents/GitHub/datasciencecoursera/corr.R')
source("corr.R")
source("complete.R")
cr <- corr("specdata", 150)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 150)
source('~/Documents/GitHub/datasciencecoursera/complete.R')
source('~/Documents/GitHub/datasciencecoursera/corr.R')
print("unique(dat$ID) 5")
source('~/Documents/GitHub/datasciencecoursera/corr.R')
print("unique(dat$ID)")
unique(dat$ID)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 150)
directory
files_full <- list.files(path = directory, pattern = "*.csv", full.names = T)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 150)
head(cr)
summary(cr)
cr <- corr("specdata", 400)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 400)
head(cr)
summary(cr)
cr <- corr("specdata", 5000)
cr <- corr("specdata")
summary(cr)
length(cr)
savehistory("~/work/data_science_coursera/intro_r/corr.Rhistory")

?tryCatch
demo(error.catching)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 15000)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 15000)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 15000)
cr <- corr("specdata", 5000)
summary(cr)
length(cr)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 15000)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 15000)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 15000)
cr <- corr("specdata", 150)
head(cr)
## [1] -0.01895754 -0.14051254 -0.04389737 -0.06815956 -0.12350667 -0.07588814
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -0.21057 -0.04999  0.09463  0.12525  0.26844  0.76313
cr <- corr("specdata", 400)
head(cr)
## [1] -0.01895754 -0.04389737 -0.06815956 -0.07588814  0.76312884 -0.15782860
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -0.17623 -0.03109  0.10021  0.13969  0.26849  0.76313
cr <- corr("specdata", 5000)
summary(cr)
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
##
length(cr)
## [1] 0
cr <- corr("specdata")
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -1.00000 -0.05282  0.10718  0.13684  0.27831  1.00000
length(cr)
## [1] 323
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata")
summary(cr)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata")
selected_sulfate_list[[1000]]
try(selected_sulfate_list[[1000]])
try(selected_sulfate_list[[1000]], silent = TR)
try(selected_sulfate_list[[1000]], silent = TRue)
try(selected_sulfate_list[[1000]], silent = TRUE)
x <- try(selected_sulfate_list[[1000]], silent = TRUE)
x
is.error <- function(x) inherits(x, "try-error")
succeeded <- !vapply(results, is.error, logical(1))
is.error(try(selected_sulfate_list[[1000]], silent = TRUE))
is.error(try(selected_sulfate_list[[1]], silent = TRUE))
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata")
summary(cr)
cr <- corr("specdata", 150)
head(cr)
## [1] -0.01895754 -0.14051254 -0.04389737 -0.06815956 -0.12350667 -0.07588814
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -0.21057 -0.04999  0.09463  0.12525  0.26844  0.76313
cr <- corr("specdata", 400)
head(cr)
## [1] -0.01895754 -0.04389737 -0.06815956 -0.07588814  0.76312884 -0.15782860
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -0.17623 -0.03109  0.10021  0.13969  0.26849  0.76313
cr <- corr("specdata", 5000)
summary(cr)
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
##
length(cr)
## [1] 0
cr <- corr("specdata")
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -1.00000 -0.05282  0.10718  0.13684  0.27831  1.00000
length(cr)
## [1] 323
savehistory("~/work/data_science_coursera/intro_r/corr2.Rhistory")

source('~/Documents/GitHub/datasciencecoursera/corr.R')
source('~/Documents/GitHub/datasciencecoursera/complete.R')
complete(directory, 2:5)
cr <- corr("specdata", 150)
head(cr)
## [1] -0.01895754 -0.14051254 -0.04389737 -0.06815956 -0.12350667 -0.07588814
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -0.21057 -0.04999  0.09463  0.12525  0.26844  0.76313
cr <- corr("specdata", 400)
head(cr)
## [1] -0.01895754 -0.04389737 -0.06815956 -0.07588814  0.76312884 -0.15782860
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -0.17623 -0.03109  0.10021  0.13969  0.26849  0.76313
cr <- corr("specdata", 5000)
summary(cr)
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
##
length(cr)
## [1] 0
cr <- corr("specdata")
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -1.00000 -0.05282  0.10718  0.13684  0.27831  1.00000
length(cr)
## [1] 323
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 150)
head(cr)
## [1] -0.01895754 -0.14051254 -0.04389737 -0.06815956 -0.12350667 -0.07588814
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -0.21057 -0.04999  0.09463  0.12525  0.26844  0.76313
cr <- corr("specdata", 400)
head(cr)
## [1] -0.01895754 -0.04389737 -0.06815956 -0.07588814  0.76312884 -0.15782860
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -0.17623 -0.03109  0.10021  0.13969  0.26849  0.76313
cr <- corr("specdata", 5000)
summary(cr)
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
##
length(cr)
## [1] 0
cr <- corr("specdata")
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -1.00000 -0.05282  0.10718  0.13684  0.27831  1.00000
length(cr)
## [1] 323
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 150)
head(cr)
## [1] -0.01895754 -0.14051254 -0.04389737 -0.06815956 -0.12350667 -0.07588814
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -0.21057 -0.04999  0.09463  0.12525  0.26844  0.76313
cr <- corr("specdata", 400)
head(cr)
## [1] -0.01895754 -0.04389737 -0.06815956 -0.07588814  0.76312884 -0.15782860
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -0.17623 -0.03109  0.10021  0.13969  0.26849  0.76313
cr <- corr("specdata", 5000)
summary(cr)
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
##
length(cr)
## [1] 0
cr <- corr("specdata")
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -1.00000 -0.05282  0.10718  0.13684  0.27831  1.00000
length(cr)
## [1] 323
complete("specdata", 2:5)
cr <- corr("specdata", 400)
cr
source('~/Documents/GitHub/datasciencecoursera/corr.R')
complete(directory, 2:5)
complete(directory, 2:7)
complete(directory, 7:3)
cr <- corr("specdata", 400)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
cr <- corr("specdata", 400)
source('~/Documents/GitHub/datasciencecoursera/corr.R')
complete(directory, 18)
cr <- corr("specdata", 150)
head(cr)
## [1] -0.01895754 -0.14051254 -0.04389737 -0.06815956 -0.12350667 -0.07588814
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -0.21057 -0.04999  0.09463  0.12525  0.26844  0.76313
cr <- corr("specdata", 400)
head(cr)
## [1] -0.01895754 -0.04389737 -0.06815956 -0.07588814  0.76312884 -0.15782860
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -0.17623 -0.03109  0.10021  0.13969  0.26849  0.76313
cr <- corr("specdata", 5000)
summary(cr)
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
##
length(cr)
## [1] 0
cr <- corr("specdata")
summary(cr)
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
## -1.00000 -0.05282  0.10718  0.13684  0.27831  1.00000
length(cr)
## [1] 323
?order
a <- c(4, 3, 2, NA, 1)
b <- c(4, NA, 2, 7, 1)
a
b
z <- cbind(a, b)
z
o <- order(a, b)); z[o, ]
(o <- order(a, b)); z[o, ]
(o <- order(a, b, na.last = FALSE)); z[o, ]
all(diff(a) >= 0)
all(diff(a) <= 0)
diff(a)
?diff
id
diff(id)
all(diff(a) >= 0)
diff(a) >= 0
diff(1:10, 2)
diff(1:10, 2, 2)
diff(a, 1) >= 0
diff(1:10)
diff(1:10) >= 0
all(diff(1:10) >= 0)
all(diff(10:1) >= 0)
files_full[1:3]
files_full[3:1]
complete(directory, 3:1)
complete(directory, 33:30)
id
id <- 32:30
id
tmp <- lapply(files_full[id], read.csv)
files_full[id]
View(tmp)
unique(tmp[[1]]$ID)
dat <- do.call(rbind, tmp)
unique(dat$ID)
com <- dat$ID[!is.na(dat$sulfate) & !is.na(dat$nitrate)]
unique(com)
table(com)
id
class(id)
all(diff(id1) >= 0)
all(diff(id) >= 0)
all(diff(id) <= 0)
all(diff(10:1) >= 0)
all(diff(30:35) >= 0)
all(diff(35:30) >= 0)
is.asc <- function(v){all(diff(v) >= 0)}
is.asc(1:4)
is.asc(14:4)
?table
table(com)
as.data.frame(table(com))
# > population[order(population$age),]
com_res[order(com_res$com, decreasing = is.asc),]
is.asc
is.asc(id)
# > population[order(population$age),]
com_res[order(com_res$com, decreasing = is.asc(id)),]
com_res$com
com <- dat$ID[!is.na(dat$sulfate) & !is.na(dat$nitrate)]
com_res <- as.data.frame(table(com))
com_res$com
com_res[order(com_res$com, decreasing = is.asc(id)),]
id
is.decr <- function(v){all(diff(v) <= 0)}
com_res[order(com_res$com, decreasing = is.decr(id)),]
source('~/Documents/GitHub/datasciencecoursera/complete.R')
complete(1:3)
complete(directory, 1:3)
complete(directory, 3:1)
complete("specdata", 1)
##   id nobs
## 1  1  117
complete("specdata", c(2, 4, 8, 10, 12))
##   id nobs
## 1  2 1041
## 2  4  474
## 3  8  192
## 4 10  148
## 5 12   96
complete("specdata", 30:25)
##   id nobs
## 1 30  932
## 2 29  711
## 3 28  475
## 4 27  338
## 5 26  586
## 6 25  463
complete("specdata", 3)
##   id nobs
## 1  3  243
source('~/Documents/GitHub/datasciencecoursera/complete.R')
complete("specdata", 30:25)
source('~/Documents/GitHub/datasciencecoursera/complete.R')
complete("specdata", 30:25)
table(com)
attach(mtcars)
head(mtcars)
newdata <- mtcars[order(mpg),]
head(newdata)
newdata <- mtcars[order(mpg, cyl),]
head(newdata)
newdata <- mtcars[order(mpg, -cyl),]
head(newdata)
hp
newdata <- mtcars[order(mpg, -hp),]
head(newdata)
detach(mtcars)
com
table(com)
order(table(com))
table(com)[1,]
dim(table(com))
com_res <- as.data.frame(table(com))
com_res
com_res$com
dim(  com_res <- as.data.frame(table(com))
)
dim(com_res)
source('~/Documents/GitHub/datasciencecoursera/complete.R')
##   id nobs
## 1  1  117
complete("specdata", c(2, 4, 8, 10, 12))
##   id nobs
## 1  2 1041
## 2  4  474
## 3  8  192
## 4 10  148
## 5 12   96
complete("specdata", 30:25)
##   id nobs
## 1 30  932
## 2 29  711
## 3 28  475
## 4 27  338
## 5 26  586
## 6 25  463
complete("specdata", 3)
##   id nobs
## 1  3  243
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean("specdata", "nitrate", 70:72)
pollutantmean("specdata", "sulfate", 34)
pollutantmean("specdata", "nitrate")
cc <- complete("specdata", c(6, 10, 20, 34, 100, 200, 310))
print(cc$nobs)
cc <- complete("specdata", 54)
print(cc$nobs)
RNGversion("3.5.1")
set.seed(42)
cc <- complete("specdata", 332:1)
use <- sample(332, 10)
print(cc[use, "nobs"])
head (cc)
head(use)
length(cc)
dim(cc)
dim(use)
length(use)
use
cc[304]
cc[304, "nobs"]
head(com_res)
id <- 332:1
tmp <- lapply(files_full[id], read.csv)
dat <- do.call(rbind, tmp)
com <- dat$ID[!is.na(dat$sulfate) & !is.na(dat$nitrate)]
com_res <- as.data.frame(table(com))
names(com_res) <- c("id", "nobs")
head(com_res)
us
use
print(com_res[use, "nobs"])
cr <- corr("specdata")
cr <- sort(cr)
hear(cr)
head(cr)
RNGversion("3.5.1")
set.seed(868)
out <- round(cr[sample(length(cr), 5)], 4)
print(out)
cr <- corr("specdata", 129)
cr <- sort(cr)
n <- length(cr)
RNGversion("3.5.1")
set.seed(197)
out <- c(n, round(cr[sample(n, 5)], 4))
print(out)
cr <- corr("specdata", 2000)
n <- length(cr)
cr <- corr("specdata", 1000)
cr <- sort(cr)
print(c(n, round(cr, 4)))
class(com)
table(com)
id <- 3:1
files_full <- list.files(path = directory, pattern = "*.csv", full.names = T)
tmp <- lapply(files_full[id], read.csv)
dat <- do.call(rbind, tmp)
com <- dat$ID[!is.na(dat$sulfate) & !is.na(dat$nitrate)]
com
table(com)
?table
table(com, dnn <- id)
id
a <- letters[1:3]
table(a, sample(a))                    # dnn is c("a", "")
table(a, sample(a), deparse.level = 0) # dnn is c("", "")
table(a, sample(a), deparse.level = 2) # dnn is c("a", "sample(a)")
id <- 33:30
> files_full <- list.files(path = directory, pattern = "*.csv", full.names = T)
> tmp <- lapply(files_full[id], read.csv)
> dat <- do.call(rbind, tmp)
> com <- dat$ID[!is.na(dat$sulfate) & !is.na(dat$nitrate)]
files_full <- list.files(path = directory, pattern = "*.csv", full.names = T)
tmp <- lapply(files_full[id], read.csv)
dat <- do.call(rbind, tmp)
com <- dat$ID[!is.na(dat$sulfate) & !is.na(dat$nitrate)]
head(com)
unique(com)
table(com)
distinct(com)
table(factor(com, levels=unique(com)))
source('~/Documents/GitHub/datasciencecoursera/complete.R')
complete(32:31)
complete(directory, 32:31)
complete("specdata", 30:25)
cc <- complete("specdata", 332:1)
head(cc)
cc <- complete("specdata", 33:1)
cc
source('~/Documents/GitHub/datasciencecoursera/complete.R')
cc <- complete("specdata", 33:1)
cc
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean("specdata", "nitrate", 70:72)
pollutantmean("specdata", "sulfate", 34)
pollutantmean("specdata", "nitrate")
cc <- complete("specdata", c(6, 10, 20, 34, 100, 200, 310))
print(cc$nobs)
cc <- complete("specdata", 54)
print(cc$nobs)
RNGversion("3.5.1")
set.seed(42)
cc <- complete("specdata", 332:1)
use <- sample(332, 10)
print(cc[use, "nobs"])
cr <- corr("specdata")
cr <- sort(cr)
RNGversion("3.5.1")
set.seed(868)
out <- round(cr[sample(length(cr), 5)], 4)
print(out)
cr <- corr("specdata", 129)
cr <- sort(cr)
n <- length(cr)
RNGversion("3.5.1")
set.seed(197)
out <- c(n, round(cr[sample(n, 5)], 4))
print(out)
cr <- corr("specdata", 2000)
n <- length(cr)
cr <- corr("specdata", 1000)
cr <- sort(cr)
print(c(n, round(cr, 4)))
RNGversion("3.5.1")
set.seed(42)
cc <- complete("specdata", 332:1)
use <- sample(332, 10)
print(cc[use, "nobs"])
head(cc)
use
use <- sample(332, 10)
use
set.seed(42)
use <- sample(332, 10)
use
print(cc[use, "nobs"])
use <- sample(332, 10)
use
print(cc[use, "nobs"])
use <- sample(332, 10)
print(cc[use, "nobs"])
use <- sample(332, 10)
print(cc[use, "nobs"])
use <- sample(332, 10)
print(cc[use, "nobs"])
use <- sample(332, 10)
print(cc[use, "nobs"])
?factor
factor(letters[1:20], labels = "letter")
x <- c("Man", "Male", "Man", "Lady", "Female")
x
(xf <- factor(x, levels = c("Male", "Man" , "Lady",   "Female"),
labels = c("Male", "Male", "Female", "Female")))
savehistory("~/work/data_science_coursera/intro_r/order.Rhistory")

x <- matrix(rnorm(200), 20, 10)
x
apply(x, 2, mean)
apply(x, 1, sum)
dim(x)
apply(x, 1, quantile, probs = c(0.25, 0.75))
a <- array(rnorm(2*2*10), c(2,2,10))
apply(a, c(1,2), mean)
rowMeans(a, dim = 2)
mapply(rep, 1:4, 4:1)
q <- mapply(rep, 1:4, 4:1)
q
class(q)
x <- c(rnom(10), runif(10), rnorm(10, 1))
x <- c(rnorm(10), runif(10), rnorm(10, 1))
x
f <- gl(3, 10)
f
?gl
tapply(x, f, mean)
tapply(x, f, mean, simplify = FALSE)
tapply(x, f, range)
x1 <- c(rep("f", 3), rep("m", 2))
x1
split(x1, [1:2])
split(x1, c(1,2))
split(x1, c(1,3))
split(x1, c(3,1))
head(airquality)
s <- split(airquality, airquality$Month)
lapply(s, function(x) colMeans(x[, c("Ozone", "Solar.R", "Wind")]))
sapply(s, function(x) colMeans(x[, c("Ozone", "Solar.R", "Wind")]))
sapply(s, function(x) colMeans(x[, c("Ozone", "Solar.R", "Wind")], na.rm = TRUE))
str(split(x, list(f1, f2), drop =TRUE))
gl(2, 8, labels = c("Control", "Treat"))
gl(2, 1, 20)
gl(2, 2, 20)
str(split(x, list(f1, f2), drop =TRUE))
traceback()
debug(str(split(x, list(f1, f2), drop =TRUE)))
debug(lm(x ~ o))
debug(lm(x ~ y))
options(error = recover)
read.csv("no")
swirl()
library(swirl)
install.packages("swirl")
library(swirl)
install_from_swirl("R Programming")
swirl()
head(flags)
dim(flags)
class(flags)
as.list(flags)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
cls_vect <- sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[, 11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[, 19:23]
lapply(flag_shapes, range)
sapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6, 6)
)
unique_vals <- lapply(flags, unique)
unique_vals
sapply(unique_vals, length)
unique_vals <- sapply(flags, unique)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags, unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
savehistory("~/work/data_science_coursera/intro_r/assig2.Rhistory")

source('~/work/data_science_coursera/intro_r/cash.R')
debug(makeVector([1:3]))
debug(makeVector(1:3))
makeVector(1:5)
source('~/work/data_science_coursera/intro_r/cash.R')
cachemean(1:9)
pop_land <- tapply(flags$population, flags$landmass, summary)
class(pop_land)
pop_land
cachemean(pop_land)
makeVector()
makeVector(1:10)
pop_vec <- makeVector(1:10)
View(pop_vec)
cachemean(pop_vec)
is.null(m)
data <- x$get()
data
m
x
data(iris)
library(datasets)
data(iris)
?iris
head(iris)
Sepal.Length
tapply(iris$Sepal.Length, iris$Species, summary)
apply(iris[, 1:4], 1, mean)
head(iris[, 1:4])
dim(iris)
names(iris)
apply(iris[, 1:4], 2, mean)
rowMeans(iris[,1:4])
class(apply(iris[, 1:4], 2, mean))
summary(iris)
library(datasets)
data(mtcars)
?mtcars
tapply(flags$population, flags$landmass, summary)
head(mtcars)
class(mtcars)
names(mtcars)
list(mtcars.index)
row.names(mtcars)
mean(mtcars$mpg, mtcars$cyl)
tapply(mtcars$mpg, mtcars$cyl, mean)
split(mtcars, mtcars$cyl)
sappy(split(mtcars, mtcars$cyl), summary)
sapply(split(mtcars, mtcars$cyl), summary)
sapply(mtcars, cyl, mean)
lapply(mtcars, mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
apply(mtcars, 2, mean)
head(mtcars[,2])
with(mtcars, tapply(mpg, cyl, mean))
tapply(mtcars$mpg, mtcars$cyl, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
names(mtcars)
tapply(mtcars$hp, mtcars$cyl, mean)
82.63636 - 209.21429
209.21429 - 82.63636
mt <- tapply(mtcars$hp, mtcars$cyl, mean)
mt$8 - mt$4
mt$8
name(mt)
names(mt)
mt$"8"
mt["8"]
mt["8"] - mt["4"]
debug(ls)
ls
ls(pattern = "O")
v
0
.Ob <- 1
ls(pattern = "O")
ls()
debug(ls)
ls()
Q
xx
data(iris)
summary(iris)
iris[iris$Species == virginica]
iris[iris$Species == "virginica"]
is <- iris$Sepal.Length[iris$Species == "virginica"]
is
mean(is)
apply(iris[, 1:4], 2, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
as.matrix(1:10)
as.matrix(1:10, nrow = 2)
as.matrix(1:10, nrow = 2, ncol = 3)
mdat <- matrix(c(1,2,3, 11,12,13), nrow = 2, ncol = 3, byrow = TRUE,
dimnames = list(c("row1", "row2"),
c("C.1", "C.2", "C.3")))
mdat
matrix(1:10, nrow = 2, ncol = 3)
matrix(1:10, nrow = 5, ncol = 2)
solve(mdat)
matrix(1:16, nrow = 4, ncol = 4)
solve(mdat)
a %*% x = b
2 %*% x
2 %*% 3
A <- matrix( c(5, 1, 0,
3,-1, 2,
4, 0,-1), nrow=3, byrow=TRUE)
A
det(A)
sum(c(5, 1, 0,
+                3,-1, 2,
+                4, 0,-1))
(x <- matrix(1:4, ncol = 2))
unlist(determinant(x))
det(x)
det(print(cbind(1, 1:3, c(2,0,1))))
det(A) != 0
(AI  <- inv(A))
(AI  <- solve(A))
A
AI %*% A
solve(4, 8)
xm <- matrix(1:4, ncol = 2)
xm
solve(xm)
nrow(xm)
diag(nrow(xm))
xm %*% solve(xm)
source('~/work/data_science_coursera/intro_r/ProgrammingAssignment2/cachematrix.R')
nm <- makeCacheMatrix(xm)
source('~/work/data_science_coursera/intro_r/ProgrammingAssignment2/cachematrix.R')
nm <- makeCacheMatrix(xm)
nm
source('~/work/data_science_coursera/intro_r/ProgrammingAssignment2/cachematrix.R')
sxm <- solve(xm)
sxm
cacheSolve(xm)
class(xm)
cacheSolve(nm)
source('~/work/data_science_coursera/intro_r/ProgrammingAssignment2/cachematrix.R')
cacheSolve(nm)
nm1 <- makeCacheMatrix(xm)
cacheSolve(nm1)
str(Iris)
str(iris)
str(airquality)
m <- matrix(rnorm(100), 10, 10)
str(m)
s <- split(airquality, airquality$Month)
str(s)
x < rnorm(10)
x <- rnorm(10)
x
x <- rnorm(10, 20, 2)
x
set.seed(1)
rnorm(5)
set.seed(20)
x <- rnorm(100)
e <- rnorm(100, 0, 2)
y <- 0.5 + 2 * x + e
summary(y)
plot(x, y)
x <- rbinom(100, 1, 0.5)
summary(y)
e <- rnorm(100, 0, 2)
summary(y)
y <- 0.5 + 2 * x + e
summary(y)
plot(x, y)
set.seed(1)
x <- rnorm(100)
log.mu <- 0.5 + 0.3 * x
y <- rpois(100, exp(log.mu))
summary(y)
plot(x, y)
set.seed(1)
sample(1:10, 4)
sample(letters, 4)
sample(1:10)
sample(1:10, replace = TRUE)
x <- rnorm(100)
plot(x)
x <- rbinom(100, 1, 0.5)
plot(x)
x <- rpois(100)
x <- rpois(100, 2)
plot(x)
m <- matrix(rnorm(100), 10, 10)
plot(m)
system.tyme()
system.time()
system.time(matrix(rnorm(100), 10, 10))
system.time(readLines("http://www.jhsph.edu"))
hilbert <- function(n) {}
1 <- 1:n
1/ outer(i -1, i, "+")
hilbert <- function(n) {1 <- 1:n
1/ outer(i -1, i, "+")}
x <- hilbert(1000)
hilbert <- function(n) {
1 <- 1:n
1 / outer(i - 1, i, "+")}
x <- hilbert(1000)
hilbert <- function(n) {i <- 1:n
1/ outer(i -1, i, "+")}
x <- hilbert(1000)
system.time(svd(x))
Rprof()
summaryRprof()
tapply(mtcars$cyl, mtcars$mpg, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
with(mtcars, tapply(mpg, cyl, mean))
sapply(split(mtcars$mpg, mtcars$cyl), mean)
Rprof(tapply(mtcars$mpg, mtcars$cyl, mean))
str(Rprof)
?rprof
system.time( tapply(mtcars$mpg, mtcars$cyl, mean))
system.time(with(mtcars, tapply(mpg, cyl, mean)))
system.time(sapply(split(mtcars$mpg, mtcars$cyl), mean))
sample.interval=1000
$by.self
summaryRprof()
pollutantmean("specdata", "nitrate", 70:72)
directory
pollutantmean(directory, "nitrate", 70:72)
summaryRprof$by.self()
summaryRprof()
set.seed(1)
rpois(5, 2)
?qpois
?dpois()
?ppois
?rpois
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
plot(x,y)
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
swirl()
library(swirl)
swirl()
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
object.size(plants) ? 1024
object.size(plants) / 1024
object.size(plants) / 1024 ? 1024
object.size(plants) / 1024 / 1024
names(plants)
head(plants)
head(plants, 10)
tail(plants, 15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6, 4, replace = TRUE)
sample(1:20, 10)
LETTERS
sample(LETTERS)
flips <- sample(c(0, 1), 100, replace = TRUE, prob = c(0.3, 0.7))
flips
sum(flips$1)
names(flips)
str(flips)
sum(flips)
?rbinom
rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(100, size = 1, prob = 0.7)
flips2
sum(fflips)
sum(flips)
sum(flips2)
?rnorm
rnorm(10)
rnorm(10, 100, 25)
rpois(5, 10)
my_pois <- replicate(100, rpois(5, 10))
my_pois
cm <- colMeans(my_pois)
hist(cm)
data(cars)
?cars
head(cars)
plot(cars)
?plot()
?plot
plot(x = cars$speed, y = cars$dist)
plot(y = cars$speed, x = cars$dist)
plot(y = cars$speed, x = cars$dist, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plots(cars, main = "My Plot")
plot(cars, main = "My Plot")
plot(cars, sub = "My Plot Subtitle")
?par
plot(cars, col = 2)
plot(cars, xlim = c(10, 15))
plot(cars, pch = 2)
data(mtcars)
play()
dim(mtcars)
str(mtcars)
nxt()
?boxplot
boxplot(mpg ~ cyl, data = mtcars)
hist(mtcars$mpg)
setwd("/Users/ashipunova/work/data_science_coursera/intro_r/assign3/")
ls
ls()
outcome <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
head(outcome)
ncol(outcome)
names(outcome)
outcome[, 11] <- as.numeric(outcome[, 11])
hist(outcome[, 11])
source('~/.active-rstudio-document')
savehistory("~/work/data_science_coursera/intro_r/assign3/assign3_0.Rhistory")

outcome <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
setwd("/Users/ashipunova/work/data_science_coursera/intro_r/assign3/")
outcome <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
states
all_outcome <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
outcome[, 11] <- as.numeric(outcome[, 11])
states <- as.numeric(all_outcome[, 7])
states
states <- all_outcome[, 7]
str(states)
states <- unique(all_outcome[, 7])
str(states)
state <- "MA"
is.state <- any(states, state)
state %in% states
state1 <- "BB"
state1 %in% states
o <- "heart attack"
all_outcome[, 11] <- as.numeric(all_outcome[, 11])
all_outcome[, 17] <- as.numeric(all_outcome[, 17])
all_outcome[, 23] <- as.numeric(all_outcome[, 23])
min(all_outcome[, 11])
?min
min(all_outcome[, 11], na.rm = TRUE)
mha <- min(all_outcome[, 11], na.rm = TRUE)
mha
with(all_outcome, Hospital.name[State = "TX"]
)
str(all_outcome)
all_outcome[,2][all_outcome[]]
colnames_idx <- data.frame(colnames(all_outcome))
head(colnames_idx)
all_outcome[, colnames_idx[2]]
colnames_idx[2]
colnames_idx[2,]
,
all_outcome[, colnames_idx[2,]]
all_outcome[, colnames_idx[2,]] == outcome & all_outcome$State = "TX"
all_outcome[, colnames_idx[2,]] == outcome & all_outcome$State == "TX"
all_outcome[, colnames_idx[2,]][all_outcome$State == "TX"]
all_outcome[, colnames_idx[2,]][all_outcome$State == "TX" & all_outcome[, colnames_idx[11 ,] == mha]]
all_outcome[, colnames_idx[2,]][all_outcome[, colnames_idx[11 ,] == mha]]
all_outcome[, colnames_idx[11 ,]
]
str(all_outcome[, colnames_idx[11 ,]])
all_outcome[, colnames_idx[2,]][all_outcome[, colnames_idx[11,] == 10.1]]
all_outcome[, colnames_idx[2,]][all_outcome[, colnames_idx[11,]] == 10.1]
all_outcome[, colnames_idx[11,]]
all_outcome[, colnames_idx[11,]] = mha
all_outcome[, colnames_idx[11,]]
all_outcome <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
all_outcome[, colnames_idx[2,]][all_outcome[, colnames_idx[11]] == mha]
all_outcome[, colnames_idx[2,]]
all_outcome[, colnames_idx[11]]
all_outcome[, colnames_idx[11,]]
all_outcome[, colnames_idx[2,]][all_outcome[, colnames_idx[11,]] == mha]
seach_vector <- all_outcome$State == "TX" & all_outcome[, colnames_idx[11, ]] == mha
all_outcome[, colnames_idx[2,]][seach_vector]
all_outcome[, colnames_idx[2,]][ll_outcome[, colnames_idx[11, ]] == mha]
all_outcome[, colnames_idx[2,]][all_outcome[, colnames_idx[11, ]] == mha]
all_outcome[, colnames_idx[2,]][all_outcome[, colnames_idx[11, ]] == min(all_outcome[, 11], na.rm = TRUE) & ]
state
state <- "TX"
this_state_data <- subset(all_outcome, all_outcome$State == state)
head(this_state_data[,7])
min(this_state_data[, colnames_idx[11, ]])
this_state_data$Hospital.Name[min(this_state_data[, colnames_idx[11, ]], na.rm = TRUE)]
this_state_data$Hospital.Name[this_state_data[, colnames_idx[11, ]] == min(this_state_data[, colnames_idx[11, ]], na.rm = TRUE)]
short_names <- table(c("heart attack", "heart failure", "pneumonia"), c(colnames_idx[11, ], colnames_idx[17, ], colnames_idx[23, ]))
short_names
hash()
new.env(hash=TRUE)
myhash <- hash()
short_names <- c(colnames_idx[11, ], colnames_idx[17, ], colnames_idx[23, ])
names(short_names) <- c("heart attack", "heart failure", "pneumonia")
short_names$"heart attack"
short_names$heart attack
str(short_names)
short_names["heart attack"]
str(outcome)
outcome <- "heart attack"
short_names[outcome]
this_state_data[, full_outcome_name]
full_outcome_name <- short_names[outcome]
this_state_data[, full_outcome_name]
source('~/Documents/GitHub/datasciencecoursera/best.R')
this_state_data[, full_outcome_name]
best("TX", "heart attack")
subset(this_state_data, this_state_data[, full_outcome_name] == min(this_state_data[, full_outcome_name], na.rm = TRUE))
a <- subset(this_state_data, this_state_data[, full_outcome_name] == min(this_state_data[, full_outcome_name], na.rm = TRUE))
a$Hospital.Name
min_data <- this_state_data[, full_outcome_name]
str(min_data)
this_state_data <- subset(all_outcome, all_outcome$State == state)
curr_outcome <- this_state_data[, full_outcome_name]
curr_min <- min(curr_outcome, na.rm = TRUE)
this_state_data$Hospital.Name[curr_outcome == curr_min]
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("TX", "heart attack")
res <- this_state_data$Hospital.Name[curr_outcome == curr_min]
res
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("TX", "heart attack")
r <- best("TX", "heart attack")
str(r)
class(r)
com <- dat$ID[!is.na(dat$sulfate) & !is.na(dat$nitrate)]
this_state_data$Hospital.Name[curr_outcome == curr_min & !is.na(this_state_data$Hospital.Name)]
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("TX", "heart attack")
this_state_data$Hospital.Name[curr_outcome == curr_min & !is.na(this_state_data$Hospital.Name)]
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("TX", "heart attack")
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("TX", "heart attack")
!is.na(this_state_data$Hospital.Name)
curr_outcome == curr_min & !is.na(this_state_data$Hospital.Name)
this_state_data$Hospital.Name[curr_outcome == curr_min & !is.na(this_state_data$Hospital.Name)]
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("TX", "heart failure")
full_outcome_name
str(curr_outcome)
str(this_state_data)
str(curr_min)
this_state_data$Hospital.Name[curr_outcome == curr_min & !is.na(this_state_data$Hospital.Name)]
str(this_state_data$Hospital.Name[curr_outcome == curr_min & !is.na(this_state_data$Hospital.Name)])
class(v)
class(this_state_data$Hospital.Name[curr_outcome == curr_min & !is.na(this_state_data$Hospital.Name)])
unique(this_state_data$Hospital.Name[curr_outcome == curr_min & !is.na(this_state_data$Hospital.Name)])
uv <- unique(this_state_data$Hospital.Name[curr_outcome == curr_min & !is.na(this_state_data$Hospital.Name)])
length(uv)
uv[!is.na(uv)]
res <- this_state_data$Hospital.Name[curr_outcome == curr_min]
res[!is.na(res)]
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("TX", "heart failure")
res
best("MD", "heart attack")
best("MD", "pneumonia")
best("MA", "pneumonia")
res1 <- subset(this_state_data, curr_outcome == curr_min)
str(rres)
str(res1)
res1$Hospital.Name
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("MD", "pneumonia")
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("MD", "pneumonia")
is.na(curr_outcome)
sum(is.na(curr_outcome))
best("MA", "pneumonia")
debugSource('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
length(curr_min)
length(res)
length(res[!is.na(res)])
res[!is.na(res)]
res
debugSource('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
debugSource('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
sort(res_no_na)
res_no_na
sort(res_no_na)[1]
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("BB", "pneumonia")
best("MA", "pneumoniaaa")
source('~/Documents/GitHub/datasciencecoursera/best.R')
debugSource('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
this_state_data$Hospital.Name[is.na(curr_outcome)]
this_state_data$Hospital.Name[!is.na(curr_outcome)]
this_state_data[!is.na(curr_outcome)]
debugSource('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
debugSource('~/Documents/GitHub/datasciencecoursera/best.R')
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
best("TX", "heart failure")
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
debugSource('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
debugSource('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
debugSource('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
all_outcome
str(all_outcome)
this_state_data$Hospital.Name[(curr_outcome == curr_min)]
this_state_data$Hospital.Name[(curr_outcome == curr_min) & (!is.na(curr_outcome))]
debugSource('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
length(res_no_na)
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
best("MA", "pneumoniaa")
best("DD", "pneumoniaa")
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumoniaa")
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
best("MA", "pneumoniaa")
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MD", "heart failure", 5)
this_state_data[order(curr_outcome)]
str(this_state_data[order(curr_outcome)])
ord_r <- this_state_data[order(curr_outcome),]
View(ord_r)
ord_r1 <- this_state_data[order(curr_outcome), full_outcome_name]
ord_r1 <- this_state_data[order(curr_outcome), "Hospital.Name"]
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("MA", "pneumonia")
best("MA", "pneumoniaaa")
best("BB", "pneumonia")
best("MD", "heart attack")
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MD", "heart failure", 5)
!is.na(ranked_hsp)
this_state_data[order(curr_outcome), "Hospital.Name" & !is.na(curr_outcome)]
ranked_hsp[1]
ranked_hsp[1:5]
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MD", "heart failure", "best")
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("TX", "heart failure", "7")
this_state_data[order(curr_outcome, this_state_data$Hospital.Name)
]
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("TX", "heart failure", "7")
this_state_data[order(curr_outcome, this_state_data$Hospital.Name),]
temp <- this_state_data[order(curr_outcome, this_state_data$Hospital.Name),]
View(temp)
temp <- this_state_data[order(curr_outcome, this_state_data$Hospital.Name), c(2, 17)]
View(temp)
length(this_state_data$Hospital.Name)
source('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("TX", "heart failure", 4)
rankhospital("MD", "heart attack", "worst")
rankhospital("MN", "heart attack", 5000)
source('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MN", "heart attack", 5000)
rankhospital("MD", "heart attack", "worst")
rankhospital("TX", "heart failure", 4)
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MD", "heart attack", "worst")
num
cnt_hospitals
temp <- this_state_data[order(curr_outcome, this_state_data$Hospital.Name), c(2, 17)]
View(temp)
temp <- this_state_data[order(curr_outcome, this_state_data$Hospital.Name), c(2, 17)]
head(curr_outcome)
View(this_state_data)
temp <- this_state_data[order(curr_outcome, this_state_data$Hospital.Name), c(2, 17)]
View(temp)
temp <- this_state_data[order(curr_outcome, this_state_data$Hospital.Name), c("Hospital.Name", full_outcome_name)]
View(temp)
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MD", "heart attack", "worst")
this_state_data[order(!is.na(curr_outcome), this_state_data$Hospital.Name), "Hospital.Name"]
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
this_state_data[order(curr_outcome_no_na, this_state_data$Hospital.Name), "Hospital.Name"]
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MD", "heart attack", "worst")
this_state_data[order(curr_outcome_no_na, this_state_data$Hospital.Name), "Hospital.Name"]
q <- this_state_data[, !is.na(curr_outcome)]
View(q)
?subset
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
setwd("/Users/ashipunova/work/data_science_coursera/intro_r/assign3/")
rankhospital("MD", "heart attack", "worst")
View(this_state_data1)
this_state_data1[2,17]
this_state_data1[,c(2,17)]
n <- names(all_outcome)
n[11]
n[17]
n[23]
savehistory("~/work/data_science_coursera/intro_r/assign3/assign3_1.Rhistory")

all_outcome[, full_outcome_name]
this_state_data <- subset(all_outcome, (all_outcome$State == state) & !is.na(all_outcome[, full_outcome_name]))
this_state_data <- subset(all_outcome, !is.na(all_outcome[, full_outcome_name]))
str(this_state_data)
view(this_state_data)
View(this_state_data)
this_state_data1 <- subset(this_state_data, all_outcome$State == state)
str(all_outcome[, full_outcome_name])
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MD", "heart attack", "worst")
class(all_outcome[, 11])
str(all_outcome[, 11])
class(all_outcome[, full_outcome_name])
all_outcome[!is.na(all_outcome[, 11])]
all_outcome[, !is.na(all_outcome[, 11])]
all_outcome[, c(2, 11)][!is.na(all_outcome[, 11])]
all_outcome[c(2, 11)][!is.na(all_outcome[, 11])]
all_outcome[c(2, 11)]
o2_11 <- all_outcome[c(2, 11)]
View(o2_11)
re <- all_outcome[match(outcome), names(all_outcome)]
re <- all_outcome[, match(outcome), names(all_outcome)]
re <- all_outcome[, match(outcome, names(all_outcome))]
names(all_outcome))
names(all_outcome)
match(outcome, names(all_outcome))
temp <- all_outcome[c(2,11)]
View(temp)
temp[][temp[,2] >10]
temp$Hosptial.name[temp[,2] >10]
str(temp[,2] >10)
str(!is.na(temp[,2]))
temp$Hospital.Name[!is.na(temp[,2])]
temp[c(1,2)][!is.na(temp[,2])]
(!is.na(all_outcome[, full_outcome_name]))
subset(all_outcome, (!is.na(all_outcome[, full_outcome_name])))
not_na_outcome <- subset(all_outcome, (!is.na(all_outcome[, full_outcome_name])))
View(not_na_outcome)
not_na_outcome[,c(2,11)]
str(not_na_outcome[,c(2,11)])
dim(not_na_outcome[,c(2,11)])
not_na_outcome <- subset(all_outcome, (!is.na(all_outcome[, full_outcome_name])))
this_state_data <- subset(this_state_data, not_na_outcome$State == state)
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MD", "heart attack", "worst")
View(this_state_data)
subset(this_state_data, not_na_outcome$State == state, this_state_data[, full_outcome_name])
subset(this_state_data, not_na_outcome$State == state, select = this_state_data[, full_outcome_name])
subset(this_state_data, State == state, select = this_state_data[, full_outcome_name])
c
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MD", "heart attack", "worst")
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MD", "heart attack", "worst")
subset(not_na_outcome, State == state)
View(ranked_hsp)
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MD", "heart attack", "worst")
str(this_state_data[, full_outcome_name])
names(this_state_data[, full_outcome_name])
v
full_outcome_name
str(this_state_data$`full_outcome_name`)
str(this_state_data$full_outcome_name)
str(this_state_data[full_outcome_name])
a1 <- this_state_data[full_outcome_name]
a2 <- this_state_data[,full_outcome_name]
identical(a1, a2)
diff(a1, a2)
str(a1)
a1 <- this_state_data[full_outcome_name]
a2 <- this_state_data[,full_outcome_name]
str(a1)
str(a2)
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MD", "heart attack", "worst")
a1 <- this_state_data[full_outcome_name]
a2 <- this_state_data[,full_outcome_name]
str(a1)
str(a2)
str(this_state_data$Hospital.Name)
full_outcome_name
str(this_state_data$`Hospital.Name`)
str(this_state_data$`Hospital.30.Day.Death..Mortality..Rates.from.Heart.Attack`)
num
ranked_hsp[num]
source('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("TX", "heart failure", 4)
rankhospital("MD", "heart attack", "worst")
rankhospital("MN", "heart attack", 5000)
source('~/Documents/GitHub/datasciencecoursera/rankall.R')
all_outcome <- read_outcome_data()
source('~/Documents/GitHub/datasciencecoursera/rankall.R')
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MD", "heart attack", "worst")
nn <- all_outcome[!is.na(all_outcome[full_outcome_name]),]
identical(nn, not_na_outcome)
newdata <- mydata[ which(mydata$gender=='F'
& mydata$age > 65), ]
nnn <- all_outcome[ which(!is.na(all_outcome[full_outcome_name]) & all_outcome.State == state), ]
nnn <- all_outcome[ which(!is.na(all_outcome[full_outcome_name]) & all_outcome$State == state), ]
str(nnn)
nnn <- all_outcome[ which((!is.na(all_outcome[, full_outcome_name])) & (all_outcome$State == state), ]
nnn <- all_outcome[ which(!is.na(all_outcome[full_outcome_name])), ]
identical(nnn, nn)
n4 <- all_outcome[ which(!is.na(all_outcome[full_outcome_name]) & all_outcome.State == state), ]
n4 <- all_outcome[ which(!is.na(all_outcome[full_outcome_name]) & all_outcome$State == state), ]
str(n4)
identical(this_state_data, n4)
debugSource('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("MD", "heart attack", "worst")
aa1 <- all_outcome[all_outcome$State == state]
aa1 <- all_outcome[all_outcome$State == state, ]
identical(aa1, this_state_data)
aa1 <- all_outcome[all_outcome$State == state, ]
identical(aa1, this_state_data)
str(aa1)
aa1 <- not_na_outcome[not_na_outcome$State == state, ]
identical(aa1, this_state_data)
source('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
rankhospital("TX", "heart failure", 4)
rankhospital("MD", "heart attack", "worst")
rankhospital("MN", "heart attack", 5000)
dim(all_outcome)
for (s in all_outcome$Hospital.Name) {print(s[1:2])}
for (s in all_outcome$Hospital.Name) {print(s)}
debugSource('~/Documents/GitHub/datasciencecoursera/rankall.R')
head(rankall("heart attack", 20), 10)
debugSource('~/Documents/GitHub/datasciencecoursera/rankall.R')
head(rankall("heart attack", 20), 10)
debugSource('~/Documents/GitHub/datasciencecoursera/rankall.R')
source('~/Documents/GitHub/datasciencecoursera/rankall.R')
debugSource('~/Documents/GitHub/datasciencecoursera/rankall.R')
source('~/Documents/GitHub/datasciencecoursera/rankall.R')
debugSource('~/Documents/GitHub/datasciencecoursera/rankall.R')
source('~/Documents/GitHub/datasciencecoursera/rankall.R')
head(rankall("heart attack", 20), 10)
debugSource('~/Documents/GitHub/datasciencecoursera/rankall.R')
savehistory("~/work/data_science_coursera/intro_r/assign3/assign3_2.Rhistory")

debugSource('~/Documents/GitHub/datasciencecoursera/rankall.R')
head(rankall("heart attack", 20), 10)
setwd("/Users/ashipunova/work/data_science_coursera/intro_r/assign3/")
debugSource('~/Documents/GitHub/datasciencecoursera/rankall.R')
head(rankall("heart attack", 20), 10)
View(this_state_data)
unique(this_state_data$State)
debugSource('~/Documents/GitHub/datasciencecoursera/rankall.R')
head(rankall("heart attack", 20), 10)
View(output)
debugSource('~/Documents/GitHub/datasciencecoursera/rankall.R')
head(rankall("heart attack", 20), 10)
num
res
View(output)
output$hospital
output$State
state
output[2] <- state
output[2]
output[1,]
head(output)
dim(output)
df = NULL
for (k in 1:10)
{
x = 1
y = 2
z = 3
df = rbind(df, data.frame(x,y,z))
}
df
debugSource('~/Documents/GitHub/datasciencecoursera/rankall.R')
source('~/Documents/GitHub/datasciencecoursera/pollutantmean.R')
source('~/Documents/GitHub/datasciencecoursera/rankall.R')
head(rankall("heart attack", 20), 10)
source('~/Documents/GitHub/datasciencecoursera/rankall.R')
head(rankall("heart attack", 20), 10)
debugSource('~/Documents/GitHub/datasciencecoursera/rankall.R')
head(rankall("heart attack", 20), 10)
state
all_outcome$State[1]
all_outcome$State[2]
all_outcome$State[3]
unique(all_outcome$State)
debugSource('~/Documents/GitHub/datasciencecoursera/rankall.R')
head(rankall("heart attack", 20), 10)
View(output)
sorted(unique(all_outcome$State)
)
sort(unique(all_outcome$State)
)
source('~/Documents/GitHub/datasciencecoursera/rankall.R')
head(rankall("heart attack", 20), 10)
source('~/Documents/GitHub/datasciencecoursera/rankall.R')
head(rankall("heart attack", 20), 10)
tail(rankall("pneumonia", "worst"), 3)
tail(rankall("heart failure"), 10)
tail(rankall("heart failure"), "best")
head(rankall("heart failure"), "best", 2)
head(rankall("heart failure"), "best")
head((rankall("heart failure"), "best"), 2)
head(rankall("heart failure"), "best")
head(rankall("heart failure"), 2)
head(rankall("pneumonia"), 2)
head(rankall("pneumonia"), 1)
head(rankall("heart attack"), 1)
source('~/Documents/GitHub/datasciencecoursera/best.R')
best("SC", "heart attack")
best("NY", "pneumonia")
best("AK", "pneumonia")
source('~/Documents/GitHub/datasciencecoursera/rankhospital.R')
best("AK", "pneumonia")
rankhospital("NC", "heart attack", "worst")
rankhospital("WA", "heart attack", 7)
rankhospital("TX", "pneumonia", 10)
rankhospital("NY", "heart attack", 7)
source('~/Documents/GitHub/datasciencecoursera/rankall.R')
r <- rankall("heart attack", 4)
as.character(subset(r, state == "HI")$hospital)
r <- rankall("pneumonia", "worst")
as.character(subset(r, state == "NJ")$hospital)
r <- rankall("heart failure", 10)
as.character(subset(r, state == "NV")$hospital)
packageVersion("swirl")
library(swirl)
savehistory("~/work/data_science_coursera/intro_r/assign3/assign3_3.Rhistory")

rm(list=ls())
install_from_swirl("Getting and Cleaning Data")
swirl()
path2csv <- "/Users/ashipunova/work/data_science_coursera/cleaning_data/2014-07-08.csv"
path2csv
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran,
r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(-(X:size))
select(-(date:2))
select(date:2)
select(date:size)
select(ccran, -(date:2))
select(cran, -(date:2))
select(cran, -(X:size))
cran
unfo()
info()
select(cran, -(date:size))
skip()
swirl()
View(cran)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version == "3.0.2", country == "IN")
filter(cran, r_version ,= "3.0.2", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu)
)
""
")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10)
)
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
View(cran2)
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
View(cran3)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
cran3
mutate(cran3, correct_size = size + 1000)
summarize(cran,  avg_bytes = mean(size))
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
r_arch:country)
select(cran,
r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(-(X:size))
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran,  avg_bytes = mean(size))
library(dplyr)
old_cran11 <- cran
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
old_by_package <- by_package
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
?n
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
filter(pack_sum, count > 679)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts <- arrange(top_counts, count)
arrange(top_counts, desc(count))
top_counts <- arrange(top_counts, desc(count))
top_counts <- filter(pack_sum, count > 679)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
View(result3)
cran %>%
select(ip_id, country, package, size) %>%
print
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
c
students2
res <- gather(students2, sex_class, count)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(data = res, col = sex_class, into = c("sex", "class"))
submit()
students3
submit()
?gather
submit()
?spread
View(students3)
submit()
res1 <- students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE)
res1
spread(res1, name, test)
spread(res1, key = c(midterm, final), test)
spread(res1, key = c("midterm", "final"), test)
spread(res1, test, grade)
submit()
library(readr)
parse_number("class5")
submit()
View(students4)
students4
submit()
passed
failed
passed <- mutate(passed, status = "passed")
failed <- mutate(failed, status = "failed")
bind_rows(passed, failed)
savehistory("~/work/data_science_coursera/cleaning_data/cleaning_data0.Rhistory")

sat
View(sat)
?select
submit()
sat %>%
select(-contains("total"))
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
print()
View(sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range))
a1 <- sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range)
a2 <- sat %>%
select(-contains("total")) %>%
gather(key = part_sex, value = count, -score_range)
identical(a1, a2)
sat %>%
select(-contains("total")) %>%
gather(key = part_sex, value = count, -score_range) %>%
separate(col = part_sex, into = c("part", "sex"))
submit()
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex, c("part", "sex")) %>%
group_by(part, sex)
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day < today()
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
now()
this_moment <- now()
this_moment
hour(this_moment)
ymd("1989-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920/1/2")
d1
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 19, minutes = 30)
this_moment
nyc <- now("America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?interval
how_long <- interval(arrive - last_time)
how_long <- interval(last_time, arrive)
as.period(how_long)
stopwatch()
ida <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", method = "curl")
ida <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", method = "curl", destfile = "/Users/ashipunova/work/data_science_coursera/cleaning_data/2014-07-08.csv")
read.csv("/Users/ashipunova/work/data_science_coursera/cleaning_data/2014-07-08.csv")
ida_data <- read.csv("/Users/ashipunova/work/data_science_coursera/cleaning_data/2014-07-08.csv")
head(ida_data)
library(data.table)
install.packages("data.table")
library(data.table)
filter(ida_data, val > 24)
filter(ida_data, ida_data$val > 24)
class(ida_data)
names(ida_data)
select(ida_data, VAL)
filter(ida_data, ida_data$VAL > 24)
ida
rm(ida)
ida_data[ida_data$VAL > 24]
ida_data[ida_data$VAL > 24, ]
class(cran)
filter(ida_data, VAL > 24)
select(ida_data, VAL)
head(select(ida_data, VAL))
new_ida <- select(ida_data, VAL)
filter(new_ida, VAL = 17)
filter(new_ida, VAL == 17)
filter(new_ida, VAL > 24)
filter(new_ida, VAL > 20)
filter(new_ida, VAL >= 24)
sum(filter(new_ida, VAL >= 24))
length(filter(new_ida, VAL >= 24))
1272/24
xl.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
laibrary(xlsx)
library(xlsx)
install.packages(xlsx)
install.packages("xlsx")
savehistory("~/work/data_science_coursera/cleaning_data/cleaning_data1.Rhistory")

download.file(xl.url, )
ddir <- "/Users/ashipunova/work/data_science_coursera/cleaning_data"
download.file(xl.url, destfile = ddir, method = curl)
download.file(xl.url, destfile = ddir, method = "curl")
xl.url
download.file(xl.url, destfile = ddir)
download.file(xl.url, destfile = paste(ddir, "/ngap.xlsx")
)
download.file(xl.url, destfile = paste(ddir, "/ngap.xlsx", sep = "")
)
xl.data <- read.table(paste(ddir, "/ngap.xlsx", sep = ""))
head(xl.data)
xl.data <- read.xlsx(paste(ddir, "/ngap.xlsx", sep = ""))
library(xlsx)
xl.data <- read.xlsx(paste(ddir, "/ngap.xlsx", sep = ""))
xl.data <- read.xlsx(paste(ddir, "/ngap.xlsx", sep = ""), sheetIndex = 1)
head(xl.data)
xl.data <- read.xlsx(paste(ddir, "/ngap.xlsx", sep = ""), sheetIndex = 1, startRow = 18, endRow = 23, colIndex = 7:15)
names(xl.data)
all_xl <- read.xlsx(paste(ddir, "/ngap.xlsx", sep = ""), sheetIndex = 1)
names(all_xl)
dat <- read.xlsx(paste(ddir, "/ngap.xlsx", sep = ""), sheetIndex = 1, rowIndex = 18:23, colIndex = 7:15)
sum(dat$Zip*dat$Ext,na.rm=T)
dat1 <- read.xml("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
library(XML)
install.packages(XML)
install.packages("XML")
dat1 <- read.xml("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
library("XML")
library(XML)
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
fileURL
doc <- xmlTreeParse(fileURL, useInternal=TRUE)
doc <- xmlParse(fileURL)
library (RCurl)
library (XML)
curlVersion()$features
curlVersion()$protocol
temp <- getURL(fileURL, ssl.verifyPeer=FALSE)
View(temp)
DFX <- xmlTreeParse(temp,useInternal = TRUE)
View(DFX)
temp <- getURL(fileURL, ssl.verifyPeer=FALSE)
fileURL
fileURLs < fileURL
fileURLs <- fileURL
fileURL <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileURL, useInternal=TRUE)
class(doc)
head(doc)
View(doc)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
scores <- xpathSApply(doc, "//li[@class='score]", xmlValue)
xpathSApply(rootNode, xmlValue)
xmlValue
xmlName(rootNode)
scores <- xpathSApply(doc, "//li[@class='score]", xmlValue)
scores <- xpathSApply(doc, "//zipcode", xmlValue)
scores
scores[scores == 21231]
length()
length(scores[scores == 21231])
url5 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
url5_fname <- paste(ddir, "url5.csv", sep = "")
download.file(url5, destfile = url5_fname)
fread(url5_fname)
DT <- fread(url5_fname)
mean(DT$pwgtp15, by=DT$SEX)
sapply(split(DT$pwgtp15, DT$SEX), mean)
tapply(DT$pwgtp15, DT$SEX, mean)
DT[,mean(DT$pwgtp15), by=SEX]
data.table::mean(DT$pwgtp15, by=DT$SEX)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
system.time(mean(DT$pwgtp15, by=DT$SEX))
system.time(sapply(split(DT$pwgtp15, DT$SEX), mean))
system.time(tapply(DT$pwgtp15, DT$SEX, mean))
system.time(DT[,mean(DT$pwgtp15), by=SEX])
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15)); system.time(mean(DT[DT$SEX==2,]$pwgtp15))
savehistory("~/work/data_science_coursera/cleaning_data/cleaning_data2.Rhistory")

install.package(RMySQL)
install.packages("RMySQL")
library(RMySQL)
uscsDb <- dbConnect(MySQL(), user="genome", host="genome-mysql.soe.ucsc.edu")
result <- dbGetQuery(uscsDb, "show databases;"); dbDisconnect(uscsDb)
uscsDb <- dbConnect(MySQL(), user="genomep", password="password", host="genome-mysql.soe.ucsc.edu")
result <- dbGetQuery(uscsDb, "show databases;"); dbDisconnect(uscsDb)
result
str(result)
hg19 <- dbConnect(MySQL(), user="genomep", password="password", host="genome-mysql.soe.ucsc.edu", db="hg19")
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affyData <- dbReadTable(hg19, "affyU133Plus2")
warnings()
head(affyData)
class(affyData)
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
affyMis < fetch(query)
affyMis <- fetch(query)
quantile(affyMis$misMatches)
affyMisSmall <- fetch(query, n = 10); dbClearResult(query)
dim(affyMisSmall)
dim(affyMis)
dbDisconnect(hg19)
source("http://bioconductor.org/biocLite.R")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.12")
biocLite("rhdf5")
BiocManager::install(c("rhdf5"))
BiocManager::available()
library(rhdf5)
created = h5createFile("example.h5")
created
created = h5createGroup("example.h5", "foo")
created = h5createGroup("example.h5", "baa")
created = h5createGroup("example.h5", "foo/foobaa")
h5ls("example.h5")
A = matrix(1:10, nr=5, nc=2)
A
h5write(A, "example.h5", "foo/A")
B = array(seq(0.1, 2.0, by = 0.1), dim = c(5,2,2))
B
attr(B, "scale") <- "liter"
B
h5write(B, "example.h5", "foo/foobaa/B")
h5ls("example.h5")
df = data.frame(1L:5L, seq(0, 1, length.out = 5)),
df = data.frame(1L:5L, seq(0, 1, length.out = 5)), c("ab", "cde", "fghi", "a", "s"), stringsAsFactors=FALSE)
df = data.frame(1L:5L, seq(0, 1, length.out = 5), c("ab", "cde", "fghi", "a", "s"), stringsAsFactors=FALSE)
h5write(df, "example.h5", "df")
h5ls
h5ls("example.h5")
readA = h5read("example.h5", "foo/A")
readB = h5read("example.h5", "foo/foobaa/B")
readf = h5read("example.h5", "df")
readA
h5write(c(12,13,14), "example.h5", "foo/A", index=list(1:3, 1))
h5read("example.h5", "foo/A")
jl = "https://scholar.google.com/citations?hl=en&user=HI-I6C0AAAAJ"
con = url(jl)
htmlCode = readLines(con)
close(con = )
close(con = con)
htmlCode
savehistory("~/work/data_science_coursera/h1.Rhistory")
savehistory("~/work/data_science_coursera/coursera_course/h1.Rhistory")

str(htmlCode)
library(XML)
html <- htmlTreeParse(jl, useInternalNodes = T)
xpathSApply(html, "//title", xmlValue)
jl
xpathSApply(html, "//td[@id='col-citeby']", xmlValue)
jl_url <- sub("s", "", jl)
jb_url
sub("s", "", jl)
jl_url
html <- htmlTreeParse(jl_url, useInternalNodes = T)
html <- htmlTreeParse(jl, useInternalNodes = T)
?htmlTreeParse
html <- htmlTreeParse(jl, useInternalNodes = T, isURL = T)
html <- htmlTreeParse(jl, useInternalNodes = T)
library(httr)
html2 = get(jl)
html2 = GET(jl)
content2 = content(html2, as = "text")
parsedHtml = htmlParse(content2, asText = T)
xpathSApply(parsedHtml, "//title", xmlValue)
xpathSApply(parsedhtml, "//td[@id='col-citeby']", xmlValue)
xpathSApply(parsedHtml, "//td[@id='col-citeby']", xmlValue)
str(parsedHtml)
str(content2)
pg1 = GET("https://httpbin.org/basic-auth/user/passwd")
pg1
pg2 = GET("https://httpbin.org/basic-auth/user/passwd", authenticate("user", "passwd"))
pg2
names(pg2)
google = handle("http://google.com")
pg1 = GET(handle = google, path= "/")
pg1 = GET(handle = google, path = "search")
pg2 = GET(handle = google, path = "search")
pg1 = GET(handle = google, path= "/")
pg1
pg2
names(pg2)
names(pg1)
identical(pg1, pg2)
myapp = oath_app("twitter", key= "", secret= "")
myapp = oauth_app("twitter", key= "", secret= "")
sig = sign_oauth1.0(myapp, token = "", token_secret = "")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
str(homeTL)
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
toJSON
jsonlite::toJSON()
json2 = jsonlite::fromJSON(jsonlite::toJSON(json1))
json2
json2[1,1:4]
savehistory("~/work/data_science_coursera/coursera_course/h2.Rhistory")

html2 = get(jl)
html_url = "http://biostat.jhsph.edu/~jleek/contact.html"
html2 = GET(html_url)
str(html2)
content2 = content(html2, as = "text")
str(content2)
parsedHtml = htmlParse(content2, asText = T)
str(parsedHtml)
parsedHtml
parsedHtml[10]
parsedHtml[10,]
xlass(parsedHtml)
class(parsedHtml)
?xpathApply
?xpathsApply
xpathsApply(parsedHtml, "//", nchar)
xpathApply(parsedHtml, "//", nchar)
xpathApply(parsedHtml, "/", nchar)
xpathApply(parsedHtml, "/", print)
xpathApply(parsedHtml, "/", "nchar")
xpathApply(parsedHtml, "/", xmlGetAttr)
html_flat <- readLines(html_url)
length(html_flat)
dim(html_flat)
html_flat[1]
html_flat[10]
nchar(html_flat[10])
nchar(html_flat[20])
nchar(html_flat[30])
nchar(html_flat[100])
install.packages("read.fwf")
read.fwf
x <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
skip=4,
widths=c(12, 7, 4, 9, 4, 9, 4, 9, 4))
View(x)
sum(x$V4)
x1 <- read.fwf(
+     file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"))
x1 <- read.fwf(file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"))
head(x)
sum(25.1, 25.2)
summary(x)
dim(x)
25*1611
summary(x$V4)
sum(x$V4)
library(readr)
x <- read_fwf(
file="http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for",
skip=4,
fwf_widths(c(12, 7, 4, 9, 4, 9, 4, 9, 4)))
str(x)
sum(x$X4)
s <- sapply(x, sum)
s <- sapply(x[,2:9], sum)
s
savehistory("~/work/data_science_coursera/coursera_course/h3.Rhistory")

mydata <- data.frame(var4 = substr(x,29,32))
dd<-read.fwf("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for",
widths=c(10, rep(c(9,4),4)), skip=4)
mydata <- data.frame(var4 = substr(dd,29,32))
str(dd$V4)
cumsum(dd$V4)
tail(cumsum(dd$V4))
source('~/work/data_science_coursera/r_github_api.R')
#install.packages("jsonlite")
library(jsonlite)
#install.packages("httpuv")
library(httpuv)
#install.packages("httr")
library(httr)
# Can be github, linkedin etc depending on application
oauth_endpoints("github")
# Change based on what you
myapp <- oauth_app(appname = "Coursera_John_Hopkins",
key = "8758a6bf9a146e1da0c1",
secret = "b9504edde46b794414495bd9c33ea28cbfd87824")
# Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
myapp <- oauth_app("github",
key = "0361e8877782c1238975",
secret = "f3aa7ef2ac0d21bfb6fe0d4acf9207740b50d118"
)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
# Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
View(req)
# Take action on http error
stop_for_status(req)
# Extract content from a request
json1 = content(req)
View(json1)
# Convert to a data.frame
gitDF = jsonlite::fromJSON(jsonlite::toJSON(json1))
View(gitDF)
# Subset data.frame
gitDF[gitDF$full_name == "jtleek/datasharing", "created_at"]
names(gitDF)
order(gitDF)
str(gitDF)
names(gitDF)["created_at"]
names(gitDF)
order(names(gitDF))
sort(names(gitDF))
gitDF$full_name
gitDF[gitDF$full_name == "jtleek/datasharing"]
str(gitDF[gitDF$full_name == "jtleek/datasharing"])
set.seed
set.seed(13435)
X <-data.frame("var1"=sample(1:5), "var2" = sample(6:10, "var3" = sample(11:15)))
X <-data.frame("var1"=sample(1:5), "var2" = sample(6:10), "var3" = sample(11:15))
X
X <-X[sample(1:5),]; X$var2[c(1,3)] = NA
X
X[,1]
X[,"var1"]
X[1:2, "var2"]
X[(X$var1 <= 3 & X$var3 >11),]
X[(X$var1 <= 3 | X$var3 >15),]
X[which(X$var2 >8),]
sort(X$var1)
sort(X$var1, decreasing = T)
sort(X$var2, na.last = T)
X[order(X$var1),]
X[sort(X$var1),]
X[order(X$var1, X$var3),]
library(plyr)
install.packages("plyr")
library(plyr)
arrange(X, var1)
arrange(X, desc(var1))
X$var4 <- rnorm(5)
X
Y <- cbind(X, rnorm(5))
Y
Z <- rbind(X, rnorm(4))
Z
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl, destfile = "./data/restaurants.csv", method = "curl")
restData <- read.csv("./data/restaurants.csv")
View(restData)
head(restData, n=3)
tail(restData, n=3)
summary(restData)
str(restData)
quantile(restData$councilDistrict, na.rm = T)
quantile(restData$councilDistrict, probs = c(0.5, 0.75, 0.9))
table(restData$zipCode, useNA = "ifany")
table(restData$councilDistrict, restData$zipCode)
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$zipCode > 0)
any(restData$zipCode > 0)
colSums(is.na(restData))
all(colSums(is.na(restData)) == 0)
all(colSums(is.na(restData[1:6])) == 0)
table(restData$zipCode %in% c("21212"))
table(restData$zipCode %in% 21212)
table(restData$zipCode %in% c("21212", "21213"))
table(restData$zipCode %in% c(21212, 21213))
restData[restData$zipCode %in% c(21212, 21213), ]
str(restData[restData$zipCode %in% c(21212, 21213), ])
Data(UCBAdmissions)
data(UCBAdmissions)
DF = as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq ~ Gender + Admit, data = DF)
xt
str(DF)
warpbreaks$replcate <- rep(1:9, len = 54)
xt1 = xtabs(breaks ~.,data = warpbreaks)
xt1
str(warpbreaks$replcate)
str(warpbreaks)
ftable(xt1)
fakeData <- rnorm(1e5)
object.size(fakeData)
print(object.size(fakeData), units = "Mb")
savehistory("~/work/data_science_coursera/coursera_course/h4.Rhistory")

str(restData)
s1 <- seq(1, 10, by = 2)
s1
s1 <- seq(1, 10, length=3)
s1
x < c(1,3,8,25,100)
x <- c(1,3,8,25,100)
seq(along = x)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
restData$zipWrong = ifelse(restData$zipCode < 0, TRUE, FALSE)
table(restData$zipWrong, restData$zipCode < 0)
restData$zipGroups = cut(restData$zipCode, breaks = quantile(restData$zipCode))
table(restData$zipGroups)
table(restData$zipGroups, restData$zipCode)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
restData$zipGroups2 = cut2(restData$zipCode, g = 4)
identical(restData$zipGroups, restData$zipGroups2)
table(restData$zipGroups2)
restData$zcf <- factor(restData$zipCode)
restData$zcf[1:10]
str(restData$zcf)
class(restData$zcf)
class(restData$zipCode)
yesno <- sample(c("yes", "no"), size = 10, replace = T)
yesnofac <- factor(yesno, levels = c("yes", "no"))
relevel(yesnofac, ref = "yes")
as.numeric(yesnofac)
yesno
yesnofac
library(plyr)
restData2 = mutate(restData, zipGr)
restData2 = mutate(restData, zipGroups = cut2(zipCode, g=4))
table(restData2$zipGroups)
str(restData2)
savehistory("~/work/data_science_coursera/coursera_course/h5.Rhistory")

library(reshape2)
install.packages("reshape2")
library(reshape2)
head(mtcars)
mtcars$carname <-rownames(mtcars)
carMelt <- mel(mtcars, id = c("carname", "gear", "cyl"), measure.vars = c("mpg", "hp"))
carMelt <- melt(mtcars, id = c("carname", "gear", "cyl"), measure.vars = c("mpg", "hp"))
str(carMelt)
head(carMelt, n=3)
tail(carMelt, n=3)
#casting
cylData <- dcast(carMelt, cyl ~ variable)
cylData
cylData <- dcast(carMelt, cyl ~ variable, mean)
cylData
#averaging
head(InsectSprays)
tapply(InsectSprays$count, InsectSprays$spray, sum)
spIns = split(InsectSprays$count, InsectSprays$spray)
str(spIns)
sum(spIns$A)
sprCount = lapply(spIns, sum)
str(sprCount)
unlist(sprCount)
sapply(spIns, sum)
ddply(InsectSprays, .(spray), summarize, sum = sum(count)
)
ddply(InsectSprays,.(spray), summarize, sum = sum(count))
library(plyr)
ddply(InsectSprays,.(spray), summarize, sum = sum(count))
?ddply
ddply(InsectSprays, "spray", summarize, sum = sum(count))
ddply(InsectSprays, .(spray), summarize, sum = sum(count))
dfx <- data.frame(
group = c(rep('A', 8), rep('B', 15), rep('C', 6)),
sex = sample(c("M", "F"), size = 29, replace = TRUE),
age = runif(n = 29, min = 18, max = 54)
)
ddply(dfx, .(group, sex), summarize,
mean = round(mean(age), 2),
sd = round(sd(age), 2))
detach(plyr)
detach("plyr")
detach("dplyr")
detach(dplyr)
ddply(InsectSprays, .(spray), summarise, sum = sum(count))
ddply(InsectSprays, .(spray), plyr::summarize, sum = sum(count))
spraySums <- ddply(InsectSprays, .(spray), summarise, sum = ave(count, FUN = sum)
)
dim(spraySums)
str(spraySums)
?ave
detach(plyr)
detach("package:plyr")
library(dplyr)
options(width = 105)
chicago <-readRDS("chicago.rds")
names(mtcars)
head(select(mtcars, cyl:hp))
chicago <- mtcars
head(select(mtcars, -(cyl:hp))
)
i <- match("cyl", names(chicago))
j <- match("hp", names(chicago))
head(chicago[, -(i:j)])
chicago <-readRDS("/Users/ashipunova/Downloads/chicago.rds")
chic.f <-filter(chicago, pm25tmean)
chic.f <-filter(chicago, pm25tmean2)
names(chicago)
chic.f <-filter(chicago, pm25tmean2 > 30)
head(chic.f)
head(chicago)
chic.f <-filter(chicago, pm25tmean2 > 30 & tmpd > 80)
head(chic.f)
chicago <- arrange(chicago, date
)
head(chicago)
tail(chicago)
chicago <- arrange(chicago, desc(date))
head(chicago)
chicago <- rename(chicago, pm25 = pm25tmean2, dewpoint = dptp)
names(chicago)
head(chicago)
chicago <- mutate(chicago, pm25detrend = pm25 - mean(pm25, na.rm = T))
head(select(chicago, pm25, pm25detrend))
plot(chicago$pm25)
plot(chicago$pm25detrend)
plot(chicago$pm25)
plot(chicago$pm25detrend)
chicago <- mutate(chicago, tempcat = factor(1 * (tmpd > 80), labels = (c("cold", "hot"))))
hotcold <- group_by(chicago, tempcat)
str(hotcold)
summarize(hotcold, pm25 = mean(pm25), o3 = max(o3tmean2), no2 = median(no2tmean2))
summarize(hotcold, pm25 = mean(pm25, na.rm = T), o3 = max(o3tmean2), no2 = median(no2tmean2))
chicago <- mutate(chicago, year = as.POSIXlt(date)$year + 1900)
str(chicago)
years <- group_by(chicago, year)
str(years)
summarize(years, pm25 = mean(pm25, na.rm = T), o3 = max(o3tmean2), no2 = median(no2tmean2))
chicago %>%
mutate(month = as.POSIXlt(date)$mon + 1)
chicago %>%
mutate(month = as.POSIXlt(date)$mon + 1) %>%
group_by(month) %>%
summarise(pm25 = mean(pm25, na.rm = T), o3 = max(o3tmean2), no2 = median(no2tmean2))
ls
ls()
chicago %>%
mutate(month = as.POSIXlt(date)$mon + 1)
detach
detach("packages:magrittr")
detach("package:magrittr")
savehistory("~/work/data_science_coursera/coursera_course/h6.Rhistory")

library(dplyr)
chicago <-readRDS("chicago.rds")
chicago <-readRDS("/Users/ashipunova/Downloads/chicago.rds")
str(chicago)
chicago %>%
mutate(month = as.POSIXlt(date)$mon + 1)
chicago %>%
mutate(month = as.POSIXlt(date)$mon + 1) %>%
group_by(month)
chicago %>%
mutate(month = as.POSIXlt(date)$mon + 1) %>%
group_by(month) %>%
summarise(pm25 = mean(pm25tmean2, na.rm = T), o3 = max(o3tmean2), no2 = median(no2tmean2))
if(!file.exists("./data")){dir.create("./data")}
fileUrl1 = "https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
fileUrl2 = "https://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
download.file(fileUrl1,destfile="./data/reviews.csv",method="curl")
download.file(fileUrl2,destfile="./data/solutions.csv",method="curl")
reviews = read.csv("./data/reviews.csv"); solutions <- read.csv("./data/solutions.csv")
head(reviews,2)
head(solutions,2)
if(!file.exists("./data")){dir.create("./data")}
fileUrl1 = "https://github.com/DataScienceSpecialization/courses/blob/master/03_GettingData/03_05_mergingData/data/reviews.csv"
fileUrl2 = "https://github.com/DataScienceSpecialization/courses/blob/master/03_GettingData/03_05_mergingData/data/solutions.csv"
download.file(fileUrl1,destfile="./data/reviews.csv",method="curl")
download.file(fileUrl2,destfile="./data/solutions.csv",method="curl")
reviews = read.csv("./data/reviews.csv"); solutions <- read.csv("./data/solutions.csv")
head(reviews,2)
head(solutions,2)
if(!file.exists("./data")){dir.create("./data")}
fileUrl1 = "https://github.com/DataScienceSpecialization/courses/blob/master/03_GettingData/03_05_mergingData/data/reviews.csv"
fileUrl2 = "https://github.com/DataScienceSpecialization/courses/blob/master/03_GettingData/03_05_mergingData/data/solutions.csv"
download.file(fileUrl1,destfile="./data/reviews.csv",method="curl")
download.file(fileUrl2,destfile="./data/solutions.csv",method="curl")
reviews = read.csv("/Users/ashipunova/work/data_science_coursera/data/reviews.csv"); solutions <- read.csv("/Users/ashipunova/work/data_science_coursera/data/solutions.csv")
head(reviews,2)
head(solutions,2)
names(reviews)
names(solutions)
mergdData = merge(reviews, solutions, by.x = "solution_id", by.y = "id", all = T)
str(mergdData)
intersect(names(solutions), names(reviews))
mergedData2 = merge(reviews, solutions, all = T)
head(mergedData2)
d1 = data.frame(id = sample(1:10), x = rnorm(10))
d2 = data.frame(id = sample(1:10), y = rnorm(10))
View(d1)
View(d2)
arrange(join(df1, df2), id)
library(plyr)
arrange(join(df1, df2), id)
df1 = data.frame(id = sample(1:10), x = rnorm(10))
df2 = data.frame(id = sample(1:10), y = rnorm(10))
arrange(join(df1, df2), id)
df3 = data.frame(id = sample(1:10), z = rnorm(10))
dfList = list(df1, df2, df3)
join_all(dfList)
swirl()
library(swirl)
swirl()
read.csv(path2csv, stringsAsFactors = FALSE)
mydf = read.csv(path2csv, stringsAsFactors = FALSE)
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
print(cran)
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10)).
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size - 1000)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
mydf
str(mydf)
rm("mydf")
str(cran)
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarise(by_package, avg_bytes = mean(size))
summarise(by_package, mean(size))
summarize(by_package, mean(size))
submit()
detach("package:plyr")
submit()
summarize(by_package, mean(size))
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts)
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique
)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
arrange(top_unique, desc(unique))
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
View(result3)
submit()
select(cran, ip_id, country, package, size)
submit()
cran %>%
select(cran, ip_id, country, package, size) %>%
print
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, count())
res <- gather(students2, sex_class, count
)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(data = res, col = sex_class, into = c("sex", "class"))
submit()
students3
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE)
submit()
?spread
View(students3)
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade)
submit()
library(readr)
parse_number("class5")
x <- c("class1", "class2")
mutate()
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade) %>%
mutate(class1:class5, parse_number(class1:class5))
mutate(class1:class5 = parse_number(class1:class5))
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade) %>%
mutate(class1:class5 = parse_number(class1:class5))
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade) %>%
### Call to mutate() goes here %>%
mutate(class1 = parse_number(class1))
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade) %>%
mutate(class11 = parse_number(class1))
submit()
reset()
savehistory("~/work/data_science_coursera/coursera_course/h7.Rhistory")

library(swirl)
swirl()
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade) %>% mutate(class1 = parse_number("class1"))
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade) %>% mutate(class = parse_number("class"))
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, grade) %>% mutate(class = parse_number(class))
submit()
students4
submi
submit()
passed
failed
passed <- mutate(passed, status = "passed")
passed
failed <- failed %>% mutate(status = "failed")
bind_rows(passed, failed)
sat
View(sat)
sat %>%
select(-contains("total"))
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range)
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
### <Your call to separate()>
separate(part_sex, into = c("part", "sex"))
submit()
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex, c("part", "sex")) %>%
### <Your call to group_by()>
group_by(part, sex) %>%
print()
submit()
ida <- read_csv("/Users/ashipunova/work/data_science_coursera/cleaning_data/2014-07-08.csv")
ida <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", method = "curl", destfile = "/Users/ashipunova/work/data_science_coursera/cleaning_data/2014-07-08.csv")
idaD <- read_csv("/Users/ashipunova/work/data_science_coursera/cleaning_data/2014-07-08.csv")
ida_df <- tbl_df(idaD)
str(idaD)
str(ida_df)
identical(idaD, ida_df)
head(filter(ida_df, ACR == 3))
head(filter(ida_df, ACR == 3 & AGS == 6))
head(ida_df[ida_df$ACR == 3 & ida_df$AGS == 6])
ida_df[ida_df$ACR == 3]
ida_df[ida_df$ACR == 3, ]
head(ida_df[ida_df$ACR == 3 & ida_df$AGS == 6,])
str(ida_df[ida_df$ACR == 3 & ida_df$AGS == 6,])
str(ida_df$SERIALNO[ida_df$ACR == 3 & ida_df$AGS == 6,])
str(ida_df$SERIALNO[ida_df$ACR == 3 & ida_df$AGS == 6])
savehistory("~/work/data_science_coursera/coursera_course/h8.Rhistory")
download.file(fgdp_url, destfile = "./data/FGDP.csv", method = "curl")
fgdp <- read_csv("./data/FGDP.csv")
View(fgdp)
fgdp <- read_csv("./data/FGDP.csv", skip = 4)
mm <- sapply(fgdp$X5, gsub(",", ""))
gsub(",", "", fgdp$X5) %>% head()
gsub(",", "", fgdp$X5) %>% as.numeric %>% head
gsub(",", "", fgdp$X5) %>% as.numeric %>% mean(rm.na = T)
amm <- gsub(",", "", fgdp$X5)
tail(amm)
amm[!is.na(amm)] %>% length()
amm <- amm[!is.na(amm)]
mean(amm)
str(amm)
amm <- (gsub(",", "", fgdp$X5) %>% as.numeric)
str(amm)
tail(amm)
length(amm)
amm <- amm[!is.na(amm)]
length(amm)
mean(amm)
tail(fgdp)
mm <- fgdp$X5
tail(mm)
mm <- mm[!is.na(mm)]
tail(mm)
tail(fgdp, n = 15)
mm <- gsub(",", "", mm)
mm <- as.numeric(mm)
any(is.na(mm))
which(is.na(mm))
mm[191]
fgdp$X5[191]
fgdp$X5[c(paste(which(is.na(mm)), sep = ","))]
mean(mm, rm.na = T)
mm
mmi <- mm[!is.na(mm)]
mean(mmi)
gdp_new <- read_csv(/Users/ashipunova/Downloads/GDP.csv)
gdp_new <- read_csv("/Users/ashipunova/Downloads/GDP.csv")
GDPrank <- data.table::fread('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
, skip=5
, nrows=190
, select = c(1, 2, 4, 5)
, col.names=c("CountryCode", "Rank", "Country", "GDP")
)
View(GDPrank)
gsub(pattern = ",", replacement = "", GDPrank$GDP) %>% head
gsub(pattern = ",", replacement = "", GDPrank$GDP) %>% str_trim() %>% head
gsub(pattern = ",", replacement = "", GDPrank$GDP) %>% str_trim() %>% as.numeric %>% head
mmp <- (gsub(pattern = ",", replacement = "", GDPrank$GDP) %>% str_trim() %>% as.numeric)
mean(mmp)
names(GDPrank)
names(GDPrank)[1]
names(GDPrank)[3] <- "countryNames"
GDPrank %>% grep("^United", countryNames)
grep("^United", GDPrank$countryNames)
countryNames <- GDPrank$countryNames
grep("^United", countryNames)
grep("^United", countryNames), 3
grep("^United", countryNames, value = T)
grep("^United", countryNames[1:98], value = T)
countryNames[99]
countryNames[186]
grep("^United", countryNames[-c(99, 186)], value = T)
f_name32
data2<-read.csv(dest32,stringsAsFactors = FALSE)
str(data2)
View(data2)
rank_long <- join(data2, GDPrank, by = "CountryCode")
rank_long <- plyr::join(data2, GDPrank, by = "CountryCode")
View(rank_long)
grep("year", names(rank_long), value = T)
grep("end", names(rank_long), value = T)
rank_long$National.accounts.base.year
rank_long$National.accounts.base.year[length(rank_long$National.accounts.base.year) > 4]
rank_long$National.accounts.base.year[length(rank_long$National.accounts.base.year) > 6]
rank_long$National.accounts.base.year[[1]]
rank_long$National.accounts.base.year[[1]] %>% length()
rank_long$National.accounts.base.year[[1]] %>% nchar
rank_long$National.accounts.base.year[nchar(rank_long$National.accounts.base.year) > 4]
year_name <- grep("year", names(rank_long), value = T)
fisc_name <- grep("fisc", names(rank_long), value = T)
year_name
rank_long$National.accounts.reference.year[nchar(rank_long$National.accounts.reference.year) > 4]
rank_long$National.accounts.reference.year
rank_long$National.accounts.reference.year[nchar(rank_long$National.accounts.reference.year) > 4 & !is.na(rank_long$National.accounts.reference.year)]
rank_long %>% filter(!is.na(National.accounts.reference.year))
rank_long %>% filter(!is.na(National.accounts.reference.year)) %>% select(National.accounts.reference.year)
year_name
rank_long %>% filter(!is.na(PPP.survey.year)) %>% select(PPP.survey.year) %>% head()
rank_long %>% filter(!is.na(PPP.survey.year)) %>% select(PPP.survey.year) %>% nchar() > 4
ppp_s <- rank_long %>% filter(!is.na(PPP.survey.year)) %>% select(PPP.survey.year)
rank_long$PPP.survey.year[nchar(rank_long$PPP.survey.year) > 4 & !is.na(rank_long$PPP.survey.year)]
unique(ppp_s)
year_name <- grep("onth", names(rank_long), value = T)
year_name
names(rank_long)
head(rank_long)
l <- sapply(colnames(rank_long), function(x) grep("fiscal year end", rank_long[, x], value = T, ignore.case = T))
l
l$Special.Notes
grep("June", l$Special.Notes, value = T, ignore.case = T)
grep("June", l$Special.Notes, value = T, ignore.case = T) %>% length()
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
View(sampleTimes)
str(sampleTimes)
grep("2012", sampleTimes, value = T) %>% head
grep("2012", sampleTimes, value = T) %>% length()
sampleTimes %>% year() %>% head()
sampleTimes %>% year() == 2007 %>% head()
sampleTimes %>% year() == 2012 %>% table()
tt <- sampleTimes %>% year() == 2012
head(tt)
table(tt)
tt <- sampleTimes %>% year() == 2012 & wday() == 2
tt <- sampleTimes %>% year() == 2012
sampleTimes[tt] %>% head
sampleTimes[tt] %>% wday(1)
sampleTimes[tt] %>% wday()
sampleTimes[tt] %>% wday(label = T)
grep("Mon", sampleTimes[tt] %>% wday(label = T), value = T)
grep("Mon", sampleTimes[tt] %>% wday(label = T), value = T) %>% length()
file_url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
if(!file.exists("./data")){ dir.create("./data") }
temp <- tempfile()
download.file(file_url, temp)
str(temp)
arch_info <- unzip(zipfile, list = FALSE)
arch_info <- unzip(temp, list = FALSE)
str(arch_info)
View(arch_info)
# arch_info <- unzip(temp, list = FALSE)
unzip(temp, exdir = file_destination)
file_destination <- "./data/cleaning_project_data/"
# arch_info <- unzip(temp, list = FALSE)
unzip(temp, exdir = file_destination)
unlink(temp)
d_data <- read.table(paste(file_destination, "UCI HAR Dataset/train/", "X_train.txt"))
d_data <- read.table(paste(file_destination, "UCI HAR Dataset/train/", "X_train.txt", sep = ""))
str(d_data)
561/128
features <- read.table(paste(file_destination, "UCI HAR Dataset/train/", "features.txt", sep = ""))
features <- read.table(paste(file_destination, "UCI HAR Dataset/", "features.txt", sep = ""))
X_train <- read.table(paste(file_destination, "UCI HAR Dataset/train/", "X_train.txt", sep = ""))
X_test <- read.table(paste(file_destination, "UCI HAR Dataset/test/", "X_test.txt", sep = ""))
str(X_test)
X_train <- read.table(paste(file_destination, "UCI HAR Dataset/train/", "X_train.txt", sep = ""))
X_test <- read.table(paste(file_destination, "UCI HAR Dataset/test/", "X_test.txt", sep = ""))
features <- read.table(paste(file_destination, "UCI HAR Dataset/", "features.txt", sep = ""))
file_destination <- "./data/cleaning_project_data/"
X_train <- read.table(paste(file_destination, "UCI HAR Dataset/train/", "X_train.txt", sep = ""))
X_test <- read.table(paste(file_destination, "UCI HAR Dataset/test/", "X_test.txt", sep = ""))
features <- read.table(paste(file_destination, "UCI HAR Dataset/", "features.txt", sep = ""))
savehistory("~/work/data_science_coursera/coursera_course/h5.Rhistory")
activity_labels <- read.table(paste(file_destination, "UCI HAR Dataset/", "activity_labels.txt", sep = ""))
list.files(paste(file_destination, "UCI HAR Dataset", sep = ""))
list.files(paste(file_destination, "UCI HAR Dataset", sep = ""), recursive = T)
View(X_test)
file_destination <- "./data/cleaning_project_data/"
x_train <- read.table(paste(file_destination, "UCI HAR Dataset/train/", "X_train.txt", sep = ""))
y_train <- read.table(paste(file_destination, "UCI HAR Dataset/train/", "y_train.txt", sep = ""))
subject_train <- read.table(paste(file_destination, "UCI HAR Dataset/train/", "subject_train.txt", sep = ""))
x_test <- read.table(paste(file_destination, "UCI HAR Dataset/test/", "X_test.txt", sep = ""))
y_test <- read.table(paste(file_destination, "UCI HAR Dataset/test/", "y_test.txt", sep = ""))
subject_test <- read.table(paste(file_destination, "UCI HAR Dataset/test/", "subject_test.txt", sep = ""))
features <- read.table(paste(file_destination, "UCI HAR Dataset/", "features.txt", sep = ""))
activity_labels <- read.table(paste(file_destination, "UCI HAR Dataset/", "activity_labels.txt", sep = ""))
features %>% tolower() gsub([])
features %>% tolower()
{ browser(); . } %>% head() %>%
gsub("\W+", "_")
str_replace_all("angle(z,gravitymean)", "\W", "_")
str_replace_all("angle(z,gravitymean)", "[^a-z]", "_")
str_replace_all("angle(z,gravitymean)", "[^a-z]+", "_")
features %>%
tolower() %>%
{ browser(); . } %>% head() %>%
str_replace_all("[^a-z]+", "_") %>%
{ browser(); . } %>% head() %>%
{.} -> feature_names_ok
exit()
0
features %>%
tolower() %T>%
head() %>%
str_replace_all("[^a-z]+", "_")
features %>%
tolower() %T>%
head() %>%
str_replace_all("[^a-z ]+", "_") %>%
head()
features %>%
tolower() %T>%
head() %>%
str_replace_all("[^a-z ]+", "_") -> feature_names_ok
features$V2 %>%
tolower() %T>%
head() %>%
str_replace_all("[^a-z ]+", "_") %>%
{.}-> feature_names_ok
View(feature_names_ok)
names(x_test) <- feature_names_ok
new_set <- rbind(x_train, x_test)
names(x_train) <- feature_names_ok
new_set <- rbind(x_train, x_test)
7352+2947
full_set <- rbind(x_train, x_test)
View(new_set)
rm(new_set)
View(feature_names_ok)
new_set.filter(regex=("_mead_|_std_")) %>% head()
new_set %>% filter(regex=("_mead_|_std_")) %>% head()
full_set %>% filter(regex=("_mead_|_std_")) %>% head()
full_set %>% filter(regex == ("_mead_|_std_")) %>% head()
names(full_set) %>%
head()
unique(names(full_set)) %>% length()
unique(features$V1)  %>% length()
unique(features$V2)  %>% length()
unique(feature_names_ok)  %>% length()
sapply(feature_names_ok, function(x) length(unique(x)))
sapply(feature_names_ok, function(x) length(unique(x))) %>% head()
table(feature_names_ok)
table(feature_names_ok) %>%
{.} -> table_feature_names_ok
str(v)
str(table_feature_names_ok)
filter(table_feature_names_ok, function(x) x > 1)
as.data.frame(table(feature_names_ok)) %>% filter(function(x) x > 1)
as.data.frame(table(feature_names_ok))
as.data.frame(table(feature_names_ok)) %>% filter(Freq > 1)
as.data.frame(table(feature_names_ok)) %>% filter(Freq > 1) %>% regex("mead|std")
as.data.frame(table(feature_names_ok)) %>% filter(Freq > 1) %>% filter(regex("mead|std"))
as.data.frame(table(feature_names_ok)) %>% filter(Freq > 1) %>% filter(regex == "mead|std")
as.data.frame(table(feature_names_ok)) %>% filter(Freq > 1) -> repeating_names
str(repeating_names)
repeating_names %>% filter(regexpr("mead|std", feature_names_ok))
full_set %>% filter(regexpr("mead|std"), colnames())
colnames(full_set) %>% filter(regexpr("mead|std"))
colnames(full_set) %>% grep(regexpr("mead|std"))
colnames(full_set) %>% grepl(regexpr("mead|std"))
colnames(full_set) %>% grepl("mead")
colnames(full_set) %>% grepl("mean")
colnames(full_set) %>% regexpr("mean")
regexpr("mean", colnames(full_set))
regexpr("mean|std", colnames(full_set), value = T) %>% head
regexpr("mean|std", colnames(full_set)) %>% head
which(regexpr("mean|std", colnames(full_set)))
filter(colnames(full_set), regexpr("mean|std", colnames(full_set)))
regexpr("mean|std", colnames(full_set)) %>% head
ff <- colnames(full_set)
regexpr("mean|std", colnames(full_set)) %>% ff
txt <- c("The", "licenses", "for", "most", "software", "are",
"designed", "to", "take", "away", "your", "freedom",
"to", "share", "and", "change", "it.",
"", "By", "contrast,", "the", "GNU", "General", "Public", "License",
"is", "intended", "to", "guarantee", "your", "freedom", "to",
"share", "and", "change", "free", "software", "--",
"to", "make", "sure", "the", "software", "is",
"free", "for", "all", "its", "users")
txt
regexpr("en", txt)
gregexpr("e", txt)
findArgs <- function(env, pattern) {
nms <- ls(envir = as.environment(env))
nms <- nms[is.na(match(nms, c("F","T")))] # <-- work around "checking hack"
aa <- sapply(nms, function(.) { o <- get(.)
if(is.function(o)) names(formals(o)) })
iw <- sapply(aa, function(a) any(grepl(pattern, a, ignore.case=TRUE)))
aa[iw]
}
sapply(ff, function(a) any(grepl("mean", a, ignore.case=TRUE)))
sapply(ff, function(a) any(grepl("_mean_", a, ignore.case=TRUE)))
sapply(ff, function(a) any(grepl("\_mean\_", a, ignore.case=TRUE)))
sapply(ff, function(a) any(grepl("_mean_", a, ignore.case=TRUE)))
sapply(ff, function(a) grepl("_mean_", a, ignore.case=TRUE))
grep("_mean_", ff, ignore.case=TRUE, value = T)
grep("_mean_", ff, ignore.case=TRUE, value = T) %>% length()
grep("_mean_", ff, ignore.case=TRUE, value = T) %>%
unique() %>%
length()
grep("_std_", ff, ignore.case=TRUE, value = T) %>%
unique() %>%
length()
grep("_std_", ff, ignore.case=TRUE, value = T) %>%
length()
grep("_std_", ff, ignore.case=TRUE, value = T) -> std_names
grep("_mean_", ff, ignore.case=TRUE, value = T) -> mean_names
cat(std_names, mean_names)
cat(std_names, mean_names) %>% length()
select(full_set, contains("mean")) %>% str
full_set %>%
select(contains("_mean_|_std_")) %>% str
full_set %>%
select(contains("_mean_")) %>% str
full_set %>%
select(matches("_mean_|_std_")) %>% str
full_set %>%
select(matches("_mean_|_std_")) -> mean_std_set
subject_y_x_test <- cbind(subject_test, y_test, c_test)
subject_y_x_test <- cbind(subject_test, y_test, x_test)
subject_y_x_test <- cbind(subject = subject_test, activity = y_test, x_test)
subject_y_x_test <- cbind(subject_test, y_test, x_test)
colnames(subject_y_x_test$V1) <- "subject"
q <- cbind(subj=subject_test, act=y_test)
names(q)
rm(q)
subject_y_x_test <- cbind("subject" = subject_test, "activity" = y_test, x_test)
subject_y_x_test <- cbind("subject"=subject_test, "activity"=y_test, x_test)
subject_y_x_test <- as.data.frame(cbind("subject" = subject_test, "activity" = y_test, x_test))
setnames(subject_y_x_test, old = c('V1','V2'), new = c('subject','activity'))
library(data.table)
setnames(subject_y_x_test, old = c('V1','V2'), new = c('subject','activity'))
names(subject_y_x_test)
names(subject_y_x_test)[1:2]
subject_y_x_test <- cbind("subject" = subject_test, "activity" = y_test, x_test)
cbind(subject_test, x_test) %>%
setnames(old = "V1", new = "subject") %T>%
names()[1:2] %>%
cbind(y_test, x_test) %>%
setnames(old = "V1", new = "activity") %T>%
names()[1:2] %>%
{.} -> subj_activ_x_test
cbind(subject_test, x_test) %>%
setnames(old = "V1", new = "subject") %>%
cbind(y_test, x_test) %>%
setnames(old = "V1", new = "activity") %>%
{.} -> subj_activ_x_test
rm(subject_y_x_test)
as.data.frame(subject_test)
as.data.frame(subject_test) %>% head
as.data.frame(subject_test)
%>% setnames(old = "V1", new = "subject")
%>% head
as.data.frame(subject_test) %>%
setnames(old = "V1", new = "subject") %>%
head
cbind("subject" = as.data.frame(subject_test), "activity" = y_test, as.data.frame(x_test)) %>%
head
subj_act_test <- cbind("subject" = as.data.frame(subject_test), "activity" = as.data.frame(y_test), x_test)
rm(subj_act_test)
rm(subj_activ_x_test)
str(y_test)
str(subject_test)
names(subject_train)
names(subject_train) <- "subject"
names(subject_train)
names(subject_test)
names(y_test)
names(y_test) <- "activity"
names(y_train) <- "activity"
# combine train set
subject_activity_x_train <- cbind(subject_train, y_train, x_train)
# combine test set
subject_activity_x_test <- cbind(subject_test, y_test, x_test)
View(x_test)
View(subject_activity_x_test)
full_set <- rbind(subject_activity_x_train, subject_activity_x_test)
full_set %>%
select(matches("_mean_|_std_")) -> mean_std_set
savehistory("~/work/data_science_coursera/coursera_course/h6.Rhistory")
left_join(full_set, activity_labels, by = c("activity" = "V1")) %>% str()
full_set %>%
select(matches("_mean_|_std_")) %>%
cbind(select(full_set, subject, activity))
{.}-> mean_std_set
full_set %>%
select(matches("_mean_|_std_")) %>%
cbind(select(full_set, subject, activity)) %>%
{.}-> mean_std_set
full_set %>%
select(matches("_mean_|_std_")) %>%
cbind() %>%
{.}-> mean_std_set
full_set %>%
select(subject, activity) %>%
cbind(select(full_set, matches("_mean_|_std_"))) %>%
{.}-> mean_std_set
full_set %>%
select(subject, activity) %>%
cbind(select(matches("_mean_|_std_"))) %>%
{.}-> mean_std_set1
left_join(mean_std_set, activity_labels, by = c("activity" = "V1")) %>%
str()
left_join(mean_std_set, activity_labels, by = c("activity" = "V1")) %T>%
str() %>%
mutate(activity = V2, after = subject) %>%
str()
left_join(mean_std_set, activity_labels, by = c("activity" = "V1")) %>%
mutate(activity = V2, .after = subject) %>%
str()
left_join(mean_std_set, activity_labels, by = c("activity" = "V1")) %>%
mutate(activity = V2, .after = subject, .keep = "unused") %>%
str()
left_join(mean_std_set, activity_labels, by = c("activity" = "V1")) %>%
mutate(activity = V2, .after = subject, .keep = "unused") %T>%
str() %>%
{.} -> activity_mean_std_set
activity_mean_std_set %>%
savehistory("~/work/data_science_coursera/coursera_course/h7.Rhistory")
activity_mean_std_set %>%
group_by(subject, activity) %>%
str() %>% head()
activity_mean_std_set %>%
group_by(subject, activity) -> t1
sapply(t1, function(field) {summarise(mean(x))})
activity_mean_std_set %>%
group_by(subject, activity) -> t1
sapply(t1, function(field) {summarise(mean(field))})
activity_mean_std_set %>%
group_by(subject, activity) %>%
str()
for (field in names(t1)) {}
for (field in names(t1)) {
summarise(field_avg = mean(field, na.rm = T))
}
for (field in names(t1)) {
summarise(t1, field_avg = mean(field, na.rm = T))
}
summarise(t1, field_avg = mean(t1[1], na.rm = T))
summarise(t1, field_avg = mean(t1[3], na.rm = T))
t1[3] %>% head
summarise(t1, field_avg = mean(t1[3], na.rm = T))
t1$field_avg %>% head
summarise(t1, field_avg = mean(t1[4], na.rm = T))
summarise(t1, field_avg = mean(t1[manes(t1)[3]], na.rm = T))
nn <- names(t1)[3]
summarise(t1, field_avg = mean(nn, na.rm = T))
t1 %>% head()
t1 %>% group_by(subject) %>%
summarise(avg_tbodygyrojerkmag_mean_ = mean(v, na.rm = T)) %>%
head()
t1 %>% group_by(subject) %>%
summarise(avg_tbodygyrojerkmag_mean_ = mean(tbodygyrojerkmag_mean_, na.rm = T)) %>%
head()
mean_std_set %>% group_by(subject, activity) %>%
summarise(avg_tbodygyrojerkmag_mean_ = mean(tbodygyrojerkmag_mean_, na.rm = T)) %>%
head()
mean_std_set %>% group_by(subject, activity) %>%
summarise(mean(na.rm = T)) %>%
head()
mean_std_set %>% group_by(subject, activity) %>%
summarise(avg_tbodygyrojerkmag_mean_ = mean(tbodygyrojerkmag_mean_, na.rm = T)) %>% table()
mean_std_set %>% group_by(subject, activity) %>%
summarise(across(everything(), list(mean)))
View(activity_mean_std_set)
activity_mean_std_set %>% group_by(subject, activity) %>%
summarise(across(everything(), list(mean))) -> all_mean
View(all_mean)
View(activity_mean_std_set)
68*6
18*6
unique(full_set$subject)
max(full_set$subject)
30*6
x_train <- read.table(paste(file_destination, "UCI HAR Dataset/train/", "X_train.txt", sep = ""))
y_train <- read.table(paste(file_destination, "UCI HAR Dataset/train/", "y_train.txt", sep = ""))
subject_train <- read.table(paste(file_destination, "UCI HAR Dataset/train/", "subject_train.txt", sep = ""))
x_test <- read.table(paste(file_destination, "UCI HAR Dataset/test/", "X_test.txt", sep = ""))
y_test <- read.table(paste(file_destination, "UCI HAR Dataset/test/", "y_test.txt", sep = ""))
subject_test <- read.table(paste(file_destination, "UCI HAR Dataset/test/", "subject_test.txt", sep = ""))
features <- read.table(paste(file_destination, "UCI HAR Dataset/", "features.txt", sep = ""))
activity_labels <- read.table(paste(file_destination, "UCI HAR Dataset/", "activity_labels.txt", sep = ""))
features$V2 %>%
tolower() %>%
str_replace_all("[^a-z ]+", "_") %>%
{.} -> feature_names_ok
names(x_test) <- feature_names_ok
names(x_train) <- feature_names_ok
names(subject_train) <- "subject"
names(subject_test) <- "subject"
names(y_test) <- "activity"
names(y_train) <- "activity"
subject_activity_x_train <- cbind(subject_train, y_train, x_train)
## combine test set
subject_activity_x_test <- cbind(subject_test, y_test, x_test)
full_set <- rbind(subject_activity_x_train, subject_activity_x_test)
full_set %>%
select(subject, activity) %>%
cbind(select(full_set, matches("_mean_|_std_"))) %>%
{.} -> mean_std_set
mean_std_set %>%
group_by(subject, activity) %>%
summarise(across(everything(), list(mean))) -> all_means
full_set %>%
select(subject, activity) %>%
cbind(select(full_set, matches("_mean_|_std_"))) %>%
{.} -> mean_std_set
left_join(mean_std_set, activity_labels, by = c("activity" = "V1")) %>%
mutate(activity = V2, .after = subject, .keep = "unused") %T>%
str() %>%
{.} -> activity_mean_std_set
activity_mean_std_set %>%
group_by(subject, activity) %>%
summarise(across(everything(), list(mean))) -> all_means
View(activity_mean_std_set)
View(all_means)
write_csv(all_means, paste(file_destination, "/tidy_all_means.csv", sep = ""))
out_file_name <- paste(file_destination, "/tidy_all_means.csv.gz", sep = "")
write.csv(all_means, file=gzfile(out_file_name))
list.files("/var/folders/j4/90zh63717l98153d_0cyw9140000gn/T/")
rmarkdown::render("/Users/ashipunova/Documents/GitHub/datasciencecoursera/cleaning_data_project/CodeBook.md")
file_path_code_book = "/Users/ashipunova/Documents/GitHub/datasciencecoursera/cleaning_data_project/CodeBook.md"
source('~/Documents/GitHub/datasciencecoursera/cleaning_data_project/run_analysis.R')
savehistory("~/work/data_science_coursera/coursera_course/h8.Rhistory")

source('~/Documents/GitHub/datasciencecoursera/cleaning_data_project/run_analysis.R')
out_file_name <- paste(file_destination, "/tidy_all_means.txt", sep = "")
write.table(all_means, file = out_file_name, row.name=FALSE)
d <- "Nov 23, 2020 07:01 PST"
mdy(d)
mdy_hm(d, tz = "PST")
d <- "Nov 23, 2020 07:01"
mdy_hm(d, tz = "PST")
mdy_hm(d, tz = "A")
Sys.timezone()
str(OlsonNames())
library(stringr)
grep("Francisco", OlsonNames())
grep("America", OlsonNames())
grep("America", OlsonNames(), value = T)
mdy_hm(d, tz = "America/Los_Angeles")
mdy_hm(d, tz = "America/Los_Angeles") %>% str()
mdy_hm(d, tz = "America/Los_Angeles") %>% format(tz = "America/New_York")
savehistory("~/work/data_science_coursera/coursera_course/h9.Rhistory")

source('~/.active-rstudio-document')
library(dplyr)
# read train data
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")
Y_train <- read.table("./UCI HAR Dataset/train/Y_train.txt")
Sub_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
# read test data
X_test <- read.table("./UCI HAR Dataset/test/X_test.txt")
Y_test <- read.table("./UCI HAR Dataset/test/Y_test.txt")
Sub_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
# read data description
variable_names <- read.table("./UCI HAR Dataset/features.txt")
# read activity labels
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")
# 1. Merges the training and the test sets to create one data set.
X_total <- rbind(X_train, X_test)
Y_total <- rbind(Y_train, Y_test)
Sub_total <- rbind(Sub_train, Sub_test)
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
selected_var <- variable_names[grep("mean\\(\\)|std\\(\\)",variable_names[,2]),]
X_total <- X_total[,selected_var[,1]]
# 3. Uses descriptive activity names to name the activities in the data set
colnames(Y_total) <- "activity"
Y_total$activitylabel <- factor(Y_total$activity, labels = as.character(activity_labels[,2]))
activitylabel <- Y_total[,-1]
# 4. Appropriately labels the data set with descriptive variable names.
colnames(X_total) <- variable_names[selected_var[,1],2]
# 5. From the data set in step 4, creates a second, independent tidy data set with the average
# of each variable for each activity and each subject.
colnames(Sub_total) <- "subject"
total <- cbind(X_total, activitylabel, Sub_total)
total_mean <- total %>% group_by(activitylabel, subject) %>% summarize_each(funs(mean))
write.table(total_mean, file = "./UCI HAR Dataset/tidydata.txt", row.names = FALSE, col.names = TRUE)
savehistory("~/work/data_science_coursera/coursera_course/h10.Rhistory")

getwd()
library(datasets)
data(cars)
with(cars, plot(speed, dist))
library(lattice)
state <- data.frame(state.x77, region = state.region)
xyplot(Life.Exp ~ Income | region, data = state, layout = c(4, 1))
library(ggplot2)
data("mpg")
qplot(displ, hwy, data = mpg)
hist(airquality$Ozone)
with(airquality, plot(Wind, Ozone))
airquality <- transform(airquality, Month = factor(Month))
boxplot(Ozone ~ Month, airquality, xlab = "Month", ylab = "Ozone (ppb")
colors()
par("bg")
library(datasets)
with(airquality, plot(Wind, Ozone))
title(main = "Ozone and Wind in New York City")  ## Add a title
with(airquality, plot(Wind, Ozone, main = "Ozone and Wind in New York City"))
with(subset(airquality, Month == 5), points(Wind, Ozone, col = "blue"))
knitr::opts_chunk$set(echo = TRUE)
with(airquality, plot(Wind, Ozone, main = "Ozone and Wind in New York City", type = "n"))
with(subset(airquality, Month == 5), points(Wind, Ozone, col = "blue"))
with(subset(airquality, Month != 5), points(Wind, Ozone, col = "red"))
legend("topright", pch = 1, col = c("blue", "red"), legend = c("May", "Other Months"))
with(airquality, plot(Wind, Ozone, main = "Ozone and Wind in New York City", type = "n"))
with(subset(airquality, Month == 5), points(Wind, Ozone, col = "blue"))
with(subset(airquality, Month != 5), points(Wind, Ozone, col = "red"))
legend("topright", pch = 1, col = c("blue", "red"), legend = c("May", "Other Months"))
with(airquality, plot(Wind, Ozone, main = "Ozone and Wind in New York City", pch = 20))
model <- lm(Ozone ~ Wind, airquality)
abline(model, lwd = 2)
par(mfrow = c(1, 2))
with(airquality, {
plot(Wind, Ozone, main = "Ozone and Wind")
plot(Solar.R, Ozone, main = "Ozone and Solar Radiation")
})
par(mfrow = c(1, 3), mar = c(4, 4, 2, 1), oma = c(0, 0, 2, 0))
with(airquality, {
plot(Wind, Ozone, main = "Ozone and Wind")
plot(Solar.R, Ozone, main = "Ozone and Solar Radiation")
plot(Temp, Ozone, main = "Ozone and Temperature")
mtext("Ozone and Weather in New York City", outer = TRUE)
})
x <- rnorm(100)
hist(x)
with(faithful, plot(eruptions, waiting))
title(main = "Geither")
pdf(file = myplot.pdf)
pdf(file = "myplot.pdf")
title(main = "Old Faithful Geyser data")
with(faithful, plot(eruptions, waiting))
title(main = "Old Faithful Geyser data")
def.off
def.off()
dev.off()
par(mfrow = c(1))
par(mfrow = c(1,1))
par(mfcol = c(1,1))
with(faithful, plot(eruptions, waiting))
dev.cur()
dev.set
dev.set(3)
with(faithful, plot(eruptions, waiting))
dev.set(2)
with(faithful, plot(eruptions, waiting))
dev.copy(png, file = "geyserplot.png")
dev.off
dev.off()
dev.copy2pdf(file = "geyserplot.pdf")
dev.off()
with(faithful, plot(eruptions, waiting))
install_from_swirl("Exploratory Data Analysis")
library(swirl)
install_from_swirl("Exploratory Data Analysis")
swirl()
head(pollution)
dim(pollution)
summary(pollution$pm25)
quantile(ppm)
boxplot(ppm, col = "blue")
abline(h = 12)
hist(ppm, col = "green")
rug(ppm)
low
high
hist(ppm, col = "green", breaks = 100)
rug(ppm)
hist(ppm, col = "green")
abline(v = 12, lwd = 2)
abline(v = median(ppm), col = "magents", lwd = 4)
abline(v = median(ppm), col = "magenta", lwd = 4)
names(pollution)
reg <- table(pollution$region)
reg
barplot(reg, col = "wheat", main = "Number of Counties in Each Region")
boxplot(pm2 ~ region, data = pollution, col = "red")
boxplot(pm25 ~ region, data = pollution, col = "red")
par(mfrow=c(2,1),mar=c(4,4,2,1))
east <- subset(pollution, region == "east")
head(east)
hist(east$pm25, col = "green")
hist(subset(pollution, region == "west")$pm25, col = "green")
with(pollution, plot(latitude, pm25))
abline(h = 12, lwd = 2, lty = 2)
plot(pollution$latitude, ppm, col = pollution$region)
abline(h=12, lwd = 2, lty = 2)
par(mfrow = c(1, 2), mar = c(5, 4, 2, 1))
west <- subset(pollution, region == "west")
plot(west$latitude, west$pm25, main = "West")
plot(east$latitude, east$pm25, main = "East")
?Devices
plot(faithful, eruptions, waiting)
R(faithful, plot(eruptions, waiting))
plot(faithful, c("eruptions", "waiting"))
with(faithful, plot(eruptions, waiting))
with(faithful, plot(eruptions, waiting, main = "Old Faithful Geyser data"))
title(main = "Old Faithful Geyser data")
dev.cur()
pdf(file="myplot.pdf")
with(faithful, plot(eruptions, waiting))
title(main = "Old Faithful Geyser data")
dev.cur()
dev.off()
dev.cur()
with(faithful, plot(eruptions, waiting))
title(main = "Old Faithful Geyser data")
dev.copy(png, file = "geyserplot.png")
dev.off()
head(cars)
whith(cars, plot(speed, dist))
with(cars, plot(speed, dist))
text(mean(cars$speed), max(cars$dist), "SWIRL rules!")
head(state)
table(state$region)
xyplot(Life.Exp ~ Income | region, data = state, layout(c(4,1)))
xyplot(Life.Exp ~ Income | region, data = state, layout = c(4,1))
xyplot(Life.Exp ~ Income | region, data = state, layout = c(2,2))
head(mpg)
dim(mpg)
table(mpg$model)
qplot(displ, hwy, data = mpg)
head(airquality)
range(airquality$Ozone, na.rm = TRUE)
hist(airquality$Ozone)
table
tabletable(airquality$Month)
table(airquality$Month)
boxplot(Ozone~Month, airquality)
boxplot(Ozone~Month, airquality, xlab = "Month", ylab = "Ozone (ppb)", col.axis = "blue", col.lab = "red")
boxplot(Ozone~Month, airquality, xlab = "Month", ylab = "Ozone (ppb)", col.axis = "blue", col.lab = "red", main = "Ozone and Wind in New York City")
title(main="Ozone and Wind in New York City")
with(airquality, plot(Wind, Ozone))
title(main="Ozone and Wind in New York City")
length(par())
names(par)
names(par())
?par
par()$pin
par("fg")
par("pch")
?pch
par("lty")
scatterplot(airquality$Wind, airquality$Ozone, type = "n")
plot(airquality$Wind, airquality$Ozone, type = "n")
title(main = "Wind and Ozone in NYC")
may subset(airquality$Month == 5)
may <- subset(airquality$Month == 5)
may <- subset(airquality, airquality$Month == 5)
may <- subset(airquality, Month == 5)
points(may$Wind, may$Ozone, col = "blue", pch = 17)
notmay <- subset(airquality, !(Month == 5))
notmay <- subset(airquality, Month!=5)
notmay1 <- subset(airquality, !(Month == 5))
identical(notmay, notmay1)
points(notmay$Wind, notmay$Ozone, col = "red", pch = 8)
legend("topright", pch = c(17,8), col = c("blue","red"), legend = c("May","Other Months"))
abline(v = median(airquality$Wind), lty=2, lwd = 2)
par(mfrow = c(1,2))
plot(airquality$Wind, airquality$Ozone, main = "Ozone and Wind")
plot(airquality$Ozone, airquality$Solar.R, main = "Ozone and Solar Radiation")
par(mfrow = c(1, 3), mar = c(4, 4, 2, 1), oma = c(0, 0, 2, 0))
plot(airquality$Wind, airquality$Ozone, main = "Ozone and Wind")
plot(airquality$Ozone, airquality$Solar.R, main = "Ozone and Solar Radiation")
plot(airquality$Solar.R, airquality$Ozone, main = "Ozone and Solar Radiation")
plot(airquality$Temp, airquality$Ozone, main = "Ozone and SolarTemperature")
plot(airquality$Temp, airquality$Ozone, main = "Ozone and Temperature")
mtext("Ozone and Weather in New York City", outer = TRUE)
savehistory("~/work/data_science_coursera/coursera_course/h11.Rhistory")

class(my_vector[1])
length(my_vector[0])
for (i in 1:length(my_vector)){
print(i)
str1 <- my_vector[i]
str2 <- my_vector[i+1]
if (length(str1) > 0 && length(str2) > 0) {
print("length(str2) = ")
print(length(str2))
f_comp_p(str1, str2)
}
next
}
for (i in 1:length(my_vector)){
print("i = ")
print(i)
str1 <- my_vector[i]
str2 <- my_vector[i+1]
if (length(str1) > 0 && length(str2) > 0) {
print("length(str2) = ")
print(length(str2))
f_comp_p(str1, str2)
}
next
}
for (i in 1:length(my_vector) -1 ){
print("i = ")
print(i)
str1 <- my_vector[i]
str2 <- my_vector[i+1]
if (length(str1) > 0 && length(str2) > 0) {
print("length(str2) = ")
print(length(str2))
f_comp_p(str1, str2)
}
next
}
for (i in 1:length(my_vector) -1 ){
str1 <- my_vector[i]
str2 <- my_vector[i+1]
f_comp(str1, str2)
}
for (i in 1:length(my_vector) -1 ){
str1 <- my_vector[i]
str2 <- my_vector[i+1]
f_comp(str1, str2)
}
i
str1
str2
for (i in 1:length(my_vector) -1 ){
str1 <- my_vector[i]
str2 <- my_vector[i+1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp(str1, str2)
}
next
}
for (i in 1:length(my_vector) -1 ){
print("i = ")
print(i)
str1 <- my_vector[[i]]
str2 <- my_vector[][i+1]]
if (length(str1) > 0 && length(str2) > 0) {
print("length(str2) = ")
print(length(str2))
f_comp_p(str1, str2)
}
next
}
for (i in 1:length(my_vector) -1 ){
print("i = ")
print(i)
str1 <- my_vector[[i]]
str2 <- my_vector[[i+1]]
if (length(str1) > 0 && length(str2) > 0) {
print("length(str2) = ")
print(length(str2))
f_comp_p(str1, str2)
}
next
}
f_comp_coll <- function(str1, str2) {
res <- min(which(!(utf8ToInt(str1)-utf8ToInt(str2))==0))
print(res)
append(res_l, res)
}
for (i in 1:length(my_vector) -1 ){
str1 <- my_vector[i]
str2 <- my_vector[i+1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp(str1, str2)
}
next
}
res_l
res_l <- list()
f_comp_coll <- function(str1, str2) {
res <- min(which(!(utf8ToInt(str1)-utf8ToInt(str2))==0))
print(res)
append(res_l, res)
}
for (i in 1:length(my_vector) -1 ){
str1 <- my_vector[i]
str2 <- my_vector[i+1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2)
}
next
}
res_l
res_l <- list()
f_comp_coll <- function(str1, str2) {
res <- min(which(!(utf8ToInt(str1)-utf8ToInt(str2))==0))
print(res)
append(res_l, res, length(res_l))
}
for (i in 1:length(my_vector) -1 ){
str1 <- my_vector[i]
str2 <- my_vector[i+1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2)
}
next
}
res_l()
res_l
source(/Users/ashipunova/BPC/linda/)
source(/Users/ashipunova/BPC/linda/1_100.sorted.no_freq.txt)
source("/Users/ashipunova/BPC/linda/")
source("/Users/ashipunova/BPC/linda/1_100.sorted.no_freq.txt")
my_data <- read.table("/Users/ashipunova/BPC/linda/1_100.sorted.no_freq.txt", header = FALSE)
tot_length <- length( my_data)
tot_length
tot_length <- length([my_data])
my_data <- read.table("/Users/ashipunova/BPC/linda/1_100.sorted.no_freq.txt", header = FALSE)
View(my_data)
nrow(my_data)
tot_length <- nrow(my_data)
res_list <- vector("list", tot_length)
f_comp_coll <- function(str1, str2, i) {
res <- min(which(!(utf8ToInt(str1)-utf8ToInt(str2))==0))
res_list[[i]] <- res
}
my_data[i]
my_data[1]
my_data[0,1]
my_data[1,1]
my_data[1,2]
my_data[2,1]
input <- "/Users/ashipunova/BPC/linda/1_100.sorted.no_freq.txt"
my_seq <-  <- fread(input)
my_seq <- fread(input)
my_seq <- read(input)
class(my_data)
ncol(my_data)
f_comp_coll <- function(str1, str2, i) {
res <- min(which(!(utf8ToInt(str1)-utf8ToInt(str2))==0))
res_list[[i]] <- res
}
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_vector[i+1, 1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2, i)
}
next
}
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_data[i+1, 1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2, i)
}
next
}
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_data[i+1, 1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2, i)
}
next
}
str1
str2
utf8ToInt(str1)
typeof(str1)
class(str1)
head(my_data)
my_data[2,1]
class(my_data[[2,1]])
my_data[[2,1]]
typeof(my_data[[2,1]])
typeof(my_data[[2,"V1"]])
typeof(my_data[2,"V1"])
help(my_data)
head(my_data)
e1 <-  my_data[2,1]
e1 <-  my_data[[2,1]]
typeof(e1)
class(e1)
my_data[2, ]
v1 <- my_data[$V1]
v1 <- my_data[V1]
v1 <- my_data["V1"]
class(v1)
ncol(v1)
nrow(v1)
v1[1,1]
mydata[c(1,1)]
my_data[c(1,1)]
my_data[c(2,)]
my_data[c(2,1)]
summary(my_data)
str(my_data)
my_data[c(1,1), c(1,1)]
my_data[c(2,2), c(1,1)]
e1 <- my_data[c(1,1), c(1,1)]
length(e1)
my_data[1, 1]
my_data$V1[[1]]
e1 <- my_data$V1[[1]]
my_data[2]
my_data[1]
my_data[1,3]
my_data[3,1]
length(my_data[3,1])
str3 <- my_data[3,1]
utf8ToInt(str3)
my_data <- read.table("/Users/ashipunova/BPC/linda/1_100.sorted.no_freq.txt", header = FALSE, stringsAsFactors = FALSE)
length(my_data[3,1])
str3 <- my_data[3,1]
utf8ToInt(str3)
tot_length <- nrow(my_data)
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_data[i+1, 1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2, i)
}
next
}
head(res_list)
f_comp_coll <- function(str1, str2, i) {
res <- min(which(!(utf8ToInt(str1)-utf8ToInt(str2))==0))
print(res)
}
f_comp_coll <- function(str1, str2) {
res <- min(which(!(utf8ToInt(str1)-utf8ToInt(str2))==0))
print(res)
}
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_data[i+1, 1]
f_comp_coll(str1, str2, i)
f_comp_coll(str1, str2)
}
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_data[i+1, 1]
f_comp_coll(str1, str2)
}
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_data[i+1, 1]
f_comp_coll(str1, str2, i)
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2)
}
next
}
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_data[i+1, 1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2)
}
next
}
1 + 1
example <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8), nrow = 4, ncol = 2)
View(example)
iris
install.packages(c("ade4", "ape", "backports", "BH", "BiocManager", "bit", "bit64", "boot", "broom", "callr", "class", "cli", "clipr", "covr", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "devtools", "digest", "dplyr", "DT", "ellipsis", "fansi", "forcats", "foreach", "fs", "gdtools", "ggplot2", "gh", "git2r", "glue", "haven", "hms", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "iterators", "jsonlite", "KernSmooth", "knitr", "labeling", "later", "lattice", "latticeExtra", "lifecycle", "lubridate", "MASS", "Matrix", "matrixStats", "mgcv", "mime", "modelr", "nanotime", "nlme", "nnet", "openssl", "pillar", "pkgbuild", "pkgload", "plyr", "prettyunits", "processx", "promises", "ps", "purrr", "R.methodsS3", "R.oo", "R.utils", "R6", "Rcpp", "RcppCCTZ", "RcppParallel", "RCurl", "readr", "remotes", "reshape2", "rex", "rlang", "rmarkdown", "roxygen2", "rstudioapi", "rversions", "rvest", "scales", "selectr", "shiny", "spatial", "stringi", "survival", "svglite", "sys", "systemfonts", "testthat", "tibble", "tidyr", "tidyselect", "tidyverse", "tinytex", "usethis", "vctrs", "withr", "xfun", "xml2", "xts", "yaml", "zoo"))
version()
version
sessionInfo()
install.packages("ggplot2")
install.packages("devtools")
sessionInfo()
install.packages("KernSmooth")
library(KernSmooth)
detach("package:KernSmooth", unload = TRUE)
library(magrittr)
ymd(2007-02-01)
ymd("2007-02-01")
library(lubridate)
ymd("2007-02-01")
good_dates <- c(ymd("2007-02-01"), ymd("2007-02-02"))
good_dates
stamp_date("16/12/2006", ymd("2007-02-01"))
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
lines
lines <- c()
while(TRUE) {
line = readLines(data_file, 1)
if(length(line) == 0) break
else if(grepl("^2007-02-01;", line) | grepl("^2007-02-02;", line)) {
lines <- c(lines, line)
}
lines
while(TRUE) {
line = readLines(data_file, 1)
if(length(line) == 0) break
else if(grepl("^2007-02-01;", line) | grepl("^2007-02-02;", line)) {
lines <- c(lines, line)
}
while(TRUE) {
line = readLines(data_file, 1)
if(length(line) == 0) break
else if(grepl("^2007-02-01;", line) | grepl("^2007-02-02;", line)) {
lines <- c(lines, line)
}
data_file
# file_url <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip"
# if(!file.exists("./data")){ dir.create("./data") }
# temp <- tempfile()
# download.file(file_url, temp)
#
file_destination <- "./data/"
file_name <- paste(file_destination, "household_power_consumption.txt", sep = "")
debugSource('~/Documents/GitHub/datasciencecoursera/plot_project.R')
used_dates <- c("2007-02-01", "2007-02-02") -> as.Date(format = "%d/%m/%y")
used_dates <- c("2007-02-01", "2007-02-02") %>% as.Date(format = "%d/%m/%y")
library("dplyr")
used_dates <- c("2007-02-01", "2007-02-02") %>% as.Date(format = "%d/%m/%y")
used_dates
used_dates <- c("2007-02-01", "2007-02-02")
as.Date(used_dates, format = "%d/%m/%y")
as.Date(used_dates,
format = "%m/%d/%y")
a <- as.Date(used_dates,
format = "%m/%d/%y")
a
used_dates <- c("2007-02-01", "2007-02-02") %>%
ymd()
used_dates
format(used_dates, "%d/%m/%y")
format(used_dates, "%d/%m/%Y")
data_file <- file(file_name, "r")
used_dates <- c("2007-02-01", "2007-02-02") %>%
ymd() %>%
format("%d/%m/%Y")
used_dates <- c("2007-02-01", "2007-02-02") %>%
format("%d/%m/%Y")
used_dates <- c("2007-02-01", "2007-02-02") %>%
ymd() %>%
format("%d/%m/%Y")
grep_expr <- ""
for (d in used_dates) {
e <- paste("^" + d + ";", sep = "")
paste(grep_expr, e, sep = "|")
}
used_dates <- c("2007-02-01", "2007-02-02") %>%
ymd() %>%
format("%d/%m/%Y")
grep_expr <- ""
for (d in used_dates) {
e <- paste("^" + d + ";", sep = "")
paste(grep_expr, e, sep = "|")
}
debugSource('~/Documents/GitHub/datasciencecoursera/plot_project.R')
d
paste("^" + d + ";", sep = "")
e <- paste("^", d, ";", sep = "")
debugSource('~/Documents/GitHub/datasciencecoursera/plot_project.R')
paste(grep_expr, e, sep = "|")
grep_expr_l <- lapply(used_dates, function(d) {
list(paste("^", d, ";", sep = ""))
})
View(grep_expr_l)
library(stringr)
str_c(grep_expr_l, sep = "", collapse = NULL)
grep_expr_l <- lapply(used_dates, function(d) {
list(paste("^", d[1], ";", sep = ""))
})
str(grep_expr_l)
grep_expr_l <- lapply(used_dates, function(d) {
paste("^", d[1], ";", sep = "")
})
str_c(grep_expr_l, sep = "", collapse = NULL)
str_c(grep_expr_l, sep = "|", collapse = NULL)
str_c(grep_expr_l, sep = "|")
str_c(grep_expr_l, sep = "", collapse = "|")
gre<-str_c(grep_expr_l, sep = "", collapse = "|")
line
grep(gre, line, value = T)
debugSource('~/Documents/GitHub/datasciencecoursera/plot_project.R')
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
grep_expr
?strptime
used_dates <- c("2007-02-01", "2007-02-02") %>%
ymd() %>%
format("%e/%m/%Y") %>%
sub('/0','/')
used_dates <- c("2007-02-01", "2007-02-02") %>%
ymd() %>%
format("%e/%m/%Y")
used_dates %>%
gsub('/0','/')
gsub(used_dates[1], '/0','/')
gsub(used_dates[1], '(.+)/0(.+)','\1/\2')
gsub(used_dates[1], '(.+)/0(.+)','$1/$2')
x <- c("1jan1960", "2jan1960", "31mar1960", "30jul1960")
z <- as.Date(x, "%d%b%Y")
z
x <- "02"
trimws(x, whitespace = "0")
x = "01/02/2007"
trimws(x, whitespace = "/0")
trimws(x, whitespace = "0")
gsub("([ab])", "\\1_\\1_", "abc and ABC")
used_dates
gsub("/0", "/", used_dates)
used_dates <- c("2007-02-01", "2007-02-02") %>%
ymd() %>%
format("%e/%m/%Y")
single_digit_used_dates <- gsub("/0", "/", used_dates)
grep_expr_list <- lapply(single_digit_used_dates, function(d) {
paste("^", d[1], ";", sep = "")
})
grep_expr <- str_c(grep_expr_list, sep = "", collapse = "|")
grep_expr
debugSource('~/Documents/GitHub/datasciencecoursera/plot_project.R')
grep_expr_list <- lapply(single_digit_used_dates, function(d) {
paste("^", trimws(d[1]), ";", sep = "")
})
grep_expr_list
grep_expr <- str_c(grep_expr_list, sep = "", collapse = "|")
grep_expr
grep_expr <- str_c(grep_expr_list, sep = "", collapse = "\|")
grep_expr <- str_c(grep_expr_list, sep = "", collapse = "\\|")
x = "2/2/2007;23:50:00;3.624;0.104;241.110;15.000;0.000;0.000;18.000"
grep(grep_expr, x)
grep(grep_expr, x, value = T)
grep_expr <- str_c(grep_expr_list, sep = "", collapse = "|")
grep(grep_expr, x, value = T)
debugSource('~/Documents/GitHub/datasciencecoursera/plot_project.R')
lines
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
library(stringi)
t(stri_list2matrix(lines))
res <- read.table(text=paste(lines, collapse='\n'), header = TRUE, stringsAsFactors = FALSE, sep=';')
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
res <- read.table(text=paste(lines, collapse='\n'), header = TRUE, stringsAsFactors = FALSE, sep=';')
str(res)
unique(res$Sub_metering_1)
table(res$Sub_metering_1)
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
res <- fread(text = paste(lines, collapse='\n')
)
library(data.table)
)
res <- fread(text = paste(lines, collapse='\n'))
str(res)
identical(my_dataset, res)
diff(my_dataset, res)
my_dataset %>% transmute(Date, mdY()) %>% head()
my_dataset %>% transmute(Date, lubridate::mdY()) %>% head()
my_dataset %>% transmute(Date, lubridate::mdy()) %>% head()
my_dataset %>% transmute(Date, mdy()) %>% head()
library(anytime)
install.packages("anytime")
library(anytime)
my_dataset %>% transmute(Date, anydate()) %>% head()
my_dataset %>% transmute(Date = anydate()) %>% head()
my_dataset %>% transmute(Date = anydate(Date)) %>% head()
my_dataset %>% transmute(Date, mdy(Date)) %>% head()
my_dataset %>% transmute(Date = mdy(Date)) %>% head()
my_dataset %>% transmute(Date = mdy(Date), .keep = "unused") %>% head()
my_dataset %>% transmute(Date = mdy(Date), keep = "unused") %>% head()
my_dataset %>% mutate(Date = mdy(Date), .keep = "unused") %>% head()
my_dataset %>% mutate(Date = mdy(Date), .keep = "unused") %>% str()
my_dataset %>%
mutate(Date = mdy(Date), .keep = "unused") %>%
mutate(Time = hms(Time), .keep = "unused") %>%
str()
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
my_dataset ->   mutate(date_time = mdy_hms(c(Date, Time)), .keep = "unused") %>% head(n = 2)
res %>% head
res %>%   mutate(date_time = mdy_hms(paste(Date, Time)), .keep = "unused") %>% head(n = 2)
res %>%   mutate(date_time = mdy_hms(paste(Date, Time)), .keep = "unused") %>% str() %>% tail(n = 2)
res %>%   mutate(date_time = mdy_hms(paste(Date, Time)), .keep = "unused", .before = first_col()) %>% str() %>% tail(n = 2)
res %>%   mutate(date_time = mdy_hms(paste(Date, Time)), .keep = "unused") %>% relocate() %>% str()
res %>%   mutate(date_time = mdy_hms(paste(Date, Time)), .keep = "unused") %>% relocate(date_time) %>% str()
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
make_grep_expression()
read_data()
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
filter(my_dataset, Voltage = "?")
filter(my_dataset, Voltage == "?")
filter(my_dataset, Voltage == "NA")
filter(my_dataset, date_time == dmy_hms("21/12/2006 11:23:00"))
plot(my_dataset, Global_active_power)
plot(my_dataset$Global_active_power)
hist
hist(my_dataset$Global_active_power)
hist(my_dataset$Global_active_power, col = "red")
hist(my_dataset$Global_active_power, col = "red", xlab = "Global Active Power (kilowatts)")
hist(my_dataset$Global_active_power, col = "red", xlab = "Global Active Power (kilowatts)", main = "Global Active Power")
savehistory("~/work/data_science_coursera/coursera_course/h12.Rhistory")

dev.cur()
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
dev.off()
getws()
getwd()
plot(my_dataset$Global_active_power, my_dataset$date_time)
wday(my_dataset$date_time) %>% head()
table(wday(my_dataset$date_time))
sapply(my_dataset$date_time, function(x) {})
sapply(my_dataset$date_time, function(x) {lubridate::wday(x, label = TRUE, abbr = T) }) %>% head()
sapply(my_dataset$date_time, function(x) {lubridate::wday(x, label = TRUE, abbr = T) }) %>% table()
plot(my_dataset$Global_active_power, sapply(my_dataset$date_time, function(x) {lubridate::wday(x, label = TRUE, abbr = T) }))
plot(sapply(my_dataset$date_time, function(x) {lubridate::wday(x, label = TRUE, abbr = T) }), my_dataset$Global_active_power, )
plot(sapply(my_dataset$date_time, function(x) {lubridate::wday(x, label = TRUE, abbr = T) }), my_dataset$Global_active_power)
scatterplot(sapply(my_dataset$date_time, function(x) {lubridate::wday(x, label = TRUE, abbr = T) }), my_dataset$Global_active_power)
library(car)
data("cars")
force(cars)
scatterplot(mpg ~ wt | cyl, data=mtcars,
xlab="Weight of Car", ylab="Miles Per Gallon",
main="Enhanced Scatter Plot",
labels=row.names(mtcars))
xyplot(sapply(my_dataset$date_time, function(x) {lubridate::wday(x, label = TRUE, abbr = T) }), my_dataset$Global_active_power)
d2 <- mutate(my_dataset, wdays = lubridate::wday(date_time, label = T, abbr = T))
table(d2$wdays)
with(d2, plot(Global_active_power, wdays))
with(d2, plot(Global_active_power ~ wdays))
don <- xts(x = dataset$count, order.by = dataset$date_time)
lubridate::wday(ymd("2007-02-01"))
lubridate::wday(ymd("2007-02-01"), label = T)
lubridate::wday(ymd("2007-02-02"), label = T)
table(dataset$date_time)
table(my_dataset$date_time)
data(gtemp_land)
install.packages("astsa")
str(temp_land)
str(gtemp_land)
library(astsa)
str(gtemp_land)
plot(gtemp_land)
plot(date_time)
plot(d2$date_time)
plot(d2$date_time, d2$Global_active_power)
str(d2$date_time)
c("2007-02-01", "2007-02-02") %>%
ymd()
c("2007-02-01", "2007-02-02") %>%
ymd() %>%
day()
month()
c("2007-02-01", "2007-02-02") %>%
ymd() %>%
month()
c("2007-02-01", "2007-02-02") %>%
ymd() %>%
format("%e/%m/%Y")
c("2007-02-01", "2007-02-02") %>%
ymd() %>%
format("%e/%m/%Y") -> dd
month(dd)
day(dd)
dd
day(dd[1])
wday(dd[1])
wday(dd[1], label = T)
lubridate::wday(dd[1], label = T)
lubridate::wday(dd[2], label = T)
used_dates
used_dates <- c("2007-02-01", "2007-02-02") %>%
ymd() %>%
format("%e/%m/%Y")
single_digit_used_dates <- gsub("/0", "/", used_dates)
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
unique(day(my_dataset$date_time))
unique(lubridate::wday(my_dataset$date_time, label = T))
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
unique(lubridate::wday(my_dataset$date_time, label = T))
savehistory("~/work/data_science_coursera/coursera_course/h13.Rhistory")
if (length(str1) > 0 && length(str2) > 0) {
f_comp_p(str1, str2)
}
next
}
for (i in 1:length(my_list)){
print(i)
str1 <- my_list[i]
str2 <- my_list[i+1]
if (length(str1) > 0 && length(str2) > 0) {
print("length(str2)")
print(length(str2))
f_comp_p(str1, str2)
}
next
}
a <-my_list[1]
length(a)
length(a[0])
length(a[1])
a[1]
class(a[1])
class(a[1][1])
class(a[1][0])
my_vector < c("TGGGGAATATTGGACAATGGGGGCAACCCTGATCCAGCCATGCCGCGTGTGTGAAGAAGGCTTTCGGGTTGTAAAGCACTTTCAGTGAGGAGGAAAAGTT",
"TGGGGAATATTGGACAATGGGCGAAAGCCTGATCCAGCAATTCCGCGTGTGTGAAGAAGGCCTTAGGGTTGTAAAGCACTTTAGTTCGGGAAGAAAAAGC",
"TGGGGAATATTGGACAATGGGGGCAACCCTGATCCAGCCATGCCGCGTGTGTGAAGAAGGCTTTCGGGTTGTAAAGCACTTTCAGTGAGGAGGAAAACCT",
"TGGGGAATCTTGGACAATGGGGGCAACCCTGATCCAGCCATGCCGCGTGTGTGAAGAAGGCCTTCGGGTTGTAAAGCACTTTCAGTAGGGAGGAAGGCTT",
"TGGGGAATCTTGGACAATGGGGGCAACCCTGATCCAGCCATGCCGCGTGTGTGAAGAAGGCCTTCGGGTTGTAAAGCACTTTCAGCAGGGAGGAAGGCTT",
"TGGGGAATCTTAGACAATGGGCGCAAGCCTGATCTAGCGATGCCGCGTGAGTGATGAAGGCCTTAGGGTCGTAAAGCTCTTTCGCCTGTGAAGATAATGA",
"TGGGGAATCTTGCACAATGGGCGAAAGCCTGATGCAGCCATGCCGCGTGAATGATGAAGGCCTTAGGGTTGTAAAATTCTTTCGCTAGGGATGATAATGA",
"TGGGGAATATTGGACAATGGGGGCAACCCTGATCCAGCCATGCCGCGTGAGTGAAGAAGGCCTTCGGGTTGTAAAGCTCTTTCAGATGCGAAGATGATGA",
"TGGGGAATATTGGACAATGGGGGCAACCCTGATCCAGCCATGCCGCGTGTGTGAAGAAGGCCTTCGGGTTGTAAAGCACTTTCAGTTGTGAGGAAGGGGA",
"TGGGGAATATTGCACAATGGGGGAAACCCTGATGCAGCCATGCCGCGTGTGTGAAGAAGGCCTTCGGGTTGTAAAGCACTTTCAGTTGTGAGGAAAAGTT")
my_vector <- c("TGGGGAATATTGGACAATGGGGGCAACCCTGATCCAGCCATGCCGCGTGTGTGAAGAAGGCTTTCGGGTTGTAAAGCACTTTCAGTGAGGAGGAAAAGTT",
"TGGGGAATATTGGACAATGGGCGAAAGCCTGATCCAGCAATTCCGCGTGTGTGAAGAAGGCCTTAGGGTTGTAAAGCACTTTAGTTCGGGAAGAAAAAGC",
"TGGGGAATATTGGACAATGGGGGCAACCCTGATCCAGCCATGCCGCGTGTGTGAAGAAGGCTTTCGGGTTGTAAAGCACTTTCAGTGAGGAGGAAAACCT",
"TGGGGAATCTTGGACAATGGGGGCAACCCTGATCCAGCCATGCCGCGTGTGTGAAGAAGGCCTTCGGGTTGTAAAGCACTTTCAGTAGGGAGGAAGGCTT",
"TGGGGAATCTTGGACAATGGGGGCAACCCTGATCCAGCCATGCCGCGTGTGTGAAGAAGGCCTTCGGGTTGTAAAGCACTTTCAGCAGGGAGGAAGGCTT",
"TGGGGAATCTTAGACAATGGGCGCAAGCCTGATCTAGCGATGCCGCGTGAGTGATGAAGGCCTTAGGGTCGTAAAGCTCTTTCGCCTGTGAAGATAATGA",
"TGGGGAATCTTGCACAATGGGCGAAAGCCTGATGCAGCCATGCCGCGTGAATGATGAAGGCCTTAGGGTTGTAAAATTCTTTCGCTAGGGATGATAATGA",
"TGGGGAATATTGGACAATGGGGGCAACCCTGATCCAGCCATGCCGCGTGAGTGAAGAAGGCCTTCGGGTTGTAAAGCTCTTTCAGATGCGAAGATGATGA",
"TGGGGAATATTGGACAATGGGGGCAACCCTGATCCAGCCATGCCGCGTGTGTGAAGAAGGCCTTCGGGTTGTAAAGCACTTTCAGTTGTGAGGAAGGGGA",
"TGGGGAATATTGCACAATGGGGGAAACCCTGATGCAGCCATGCCGCGTGTGTGAAGAAGGCCTTCGGGTTGTAAAGCACTTTCAGTTGTGAGGAAAAGTT")
my_vector[0]
my_vector[1]
length(my_vector)
length(my_vector[1])
class(my_vector)
class(my_vector[1])
length(my_vector[0])
for (i in 1:length(my_vector)){
print(i)
str1 <- my_vector[i]
str2 <- my_vector[i+1]
if (length(str1) > 0 && length(str2) > 0) {
print("length(str2) = ")
print(length(str2))
f_comp_p(str1, str2)
}
next
}
for (i in 1:length(my_vector)){
print("i = ")
print(i)
str1 <- my_vector[i]
str2 <- my_vector[i+1]
if (length(str1) > 0 && length(str2) > 0) {
print("length(str2) = ")
print(length(str2))
f_comp_p(str1, str2)
}
next
}
for (i in 1:length(my_vector) -1 ){
print("i = ")
print(i)
str1 <- my_vector[i]
str2 <- my_vector[i+1]
if (length(str1) > 0 && length(str2) > 0) {
print("length(str2) = ")
print(length(str2))
f_comp_p(str1, str2)
}
next
}
for (i in 1:length(my_vector) -1 ){
str1 <- my_vector[i]
str2 <- my_vector[i+1]
f_comp(str1, str2)
}
for (i in 1:length(my_vector) -1 ){
str1 <- my_vector[i]
str2 <- my_vector[i+1]
f_comp(str1, str2)
}
i
str1
str2
for (i in 1:length(my_vector) -1 ){
str1 <- my_vector[i]
str2 <- my_vector[i+1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp(str1, str2)
}
next
}
for (i in 1:length(my_vector) -1 ){
print("i = ")
print(i)
str1 <- my_vector[[i]]
str2 <- my_vector[][i+1]]
if (length(str1) > 0 && length(str2) > 0) {
print("length(str2) = ")
print(length(str2))
f_comp_p(str1, str2)
}
next
}
for (i in 1:length(my_vector) -1 ){
print("i = ")
print(i)
str1 <- my_vector[[i]]
str2 <- my_vector[[i+1]]
if (length(str1) > 0 && length(str2) > 0) {
print("length(str2) = ")
print(length(str2))
f_comp_p(str1, str2)
}
next
}
f_comp_coll <- function(str1, str2) {
res <- min(which(!(utf8ToInt(str1)-utf8ToInt(str2))==0))
print(res)
append(res_l, res)
}
for (i in 1:length(my_vector) -1 ){
str1 <- my_vector[i]
str2 <- my_vector[i+1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp(str1, str2)
}
next
}
res_l
res_l <- list()
f_comp_coll <- function(str1, str2) {
res <- min(which(!(utf8ToInt(str1)-utf8ToInt(str2))==0))
print(res)
append(res_l, res)
}
for (i in 1:length(my_vector) -1 ){
str1 <- my_vector[i]
str2 <- my_vector[i+1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2)
}
next
}
res_l
res_l <- list()
f_comp_coll <- function(str1, str2) {
res <- min(which(!(utf8ToInt(str1)-utf8ToInt(str2))==0))
print(res)
append(res_l, res, length(res_l))
}
for (i in 1:length(my_vector) -1 ){
str1 <- my_vector[i]
str2 <- my_vector[i+1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2)
}
next
}
res_l()
res_l
source(/Users/ashipunova/BPC/linda/)
source(/Users/ashipunova/BPC/linda/1_100.sorted.no_freq.txt)
source("/Users/ashipunova/BPC/linda/")
source("/Users/ashipunova/BPC/linda/1_100.sorted.no_freq.txt")
my_data <- read.table("/Users/ashipunova/BPC/linda/1_100.sorted.no_freq.txt", header = FALSE)
tot_length <- length( my_data)
tot_length
tot_length <- length([my_data])
my_data <- read.table("/Users/ashipunova/BPC/linda/1_100.sorted.no_freq.txt", header = FALSE)
View(my_data)
nrow(my_data)
tot_length <- nrow(my_data)
res_list <- vector("list", tot_length)
f_comp_coll <- function(str1, str2, i) {
res <- min(which(!(utf8ToInt(str1)-utf8ToInt(str2))==0))
res_list[[i]] <- res
}
my_data[i]
my_data[1]
my_data[0,1]
my_data[1,1]
my_data[1,2]
my_data[2,1]
input <- "/Users/ashipunova/BPC/linda/1_100.sorted.no_freq.txt"
my_seq <-  <- fread(input)
my_seq <- fread(input)
my_seq <- read(input)
class(my_data)
ncol(my_data)
f_comp_coll <- function(str1, str2, i) {
res <- min(which(!(utf8ToInt(str1)-utf8ToInt(str2))==0))
res_list[[i]] <- res
}
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_vector[i+1, 1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2, i)
}
next
}
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_data[i+1, 1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2, i)
}
next
}
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_data[i+1, 1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2, i)
}
next
}
str1
str2
utf8ToInt(str1)
typeof(str1)
class(str1)
head(my_data)
my_data[2,1]
class(my_data[[2,1]])
my_data[[2,1]]
typeof(my_data[[2,1]])
typeof(my_data[[2,"V1"]])
typeof(my_data[2,"V1"])
help(my_data)
head(my_data)
e1 <-  my_data[2,1]
e1 <-  my_data[[2,1]]
typeof(e1)
class(e1)
my_data[2, ]
v1 <- my_data[$V1]
v1 <- my_data[V1]
v1 <- my_data["V1"]
class(v1)
ncol(v1)
nrow(v1)
v1[1,1]
mydata[c(1,1)]
my_data[c(1,1)]
my_data[c(2,)]
my_data[c(2,1)]
summary(my_data)
str(my_data)
my_data[c(1,1), c(1,1)]
my_data[c(2,2), c(1,1)]
e1 <- my_data[c(1,1), c(1,1)]
length(e1)
my_data[1, 1]
my_data$V1[[1]]
e1 <- my_data$V1[[1]]
my_data[2]
my_data[1]
my_data[1,3]
my_data[3,1]
length(my_data[3,1])
str3 <- my_data[3,1]
utf8ToInt(str3)
my_data <- read.table("/Users/ashipunova/BPC/linda/1_100.sorted.no_freq.txt", header = FALSE, stringsAsFactors = FALSE)
length(my_data[3,1])
str3 <- my_data[3,1]
utf8ToInt(str3)
tot_length <- nrow(my_data)
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_data[i+1, 1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2, i)
}
next
}
head(res_list)
f_comp_coll <- function(str1, str2, i) {
res <- min(which(!(utf8ToInt(str1)-utf8ToInt(str2))==0))
print(res)
}
f_comp_coll <- function(str1, str2) {
res <- min(which(!(utf8ToInt(str1)-utf8ToInt(str2))==0))
print(res)
}
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_data[i+1, 1]
f_comp_coll(str1, str2, i)
f_comp_coll(str1, str2)
}
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_data[i+1, 1]
f_comp_coll(str1, str2)
}
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_data[i+1, 1]
f_comp_coll(str1, str2, i)
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2)
}
next
}
for (i in 1:tot_length-1){
str1 <- my_data[i, 1]
str2 <- my_data[i+1, 1]
if (length(str1) > 0 && length(str2) > 0) {
f_comp_coll(str1, str2)
}
next
}
1 + 1
example <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8), nrow = 4, ncol = 2)
View(example)
iris
install.packages(c("ade4", "ape", "backports", "BH", "BiocManager", "bit", "bit64", "boot", "broom", "callr", "class", "cli", "clipr", "covr", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "devtools", "digest", "dplyr", "DT", "ellipsis", "fansi", "forcats", "foreach", "fs", "gdtools", "ggplot2", "gh", "git2r", "glue", "haven", "hms", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "iterators", "jsonlite", "KernSmooth", "knitr", "labeling", "later", "lattice", "latticeExtra", "lifecycle", "lubridate", "MASS", "Matrix", "matrixStats", "mgcv", "mime", "modelr", "nanotime", "nlme", "nnet", "openssl", "pillar", "pkgbuild", "pkgload", "plyr", "prettyunits", "processx", "promises", "ps", "purrr", "R.methodsS3", "R.oo", "R.utils", "R6", "Rcpp", "RcppCCTZ", "RcppParallel", "RCurl", "readr", "remotes", "reshape2", "rex", "rlang", "rmarkdown", "roxygen2", "rstudioapi", "rversions", "rvest", "scales", "selectr", "shiny", "spatial", "stringi", "survival", "svglite", "sys", "systemfonts", "testthat", "tibble", "tidyr", "tidyselect", "tidyverse", "tinytex", "usethis", "vctrs", "withr", "xfun", "xml2", "xts", "yaml", "zoo"))
version()
version
sessionInfo()
install.packages("ggplot2")
install.packages("devtools")
sessionInfo()
install.packages("KernSmooth")
library(KernSmooth)
detach("package:KernSmooth", unload = TRUE)
library(magrittr)
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
with(my_dataset,
plot(date_time, Voltage,
type = 'n',
ylab = "Voltage",
xlab = "datetime")
)
with(my_dataset,
lines(date_time, Voltage, pch = 20)
)
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
plot(x <- sort(rnorm(47)), type = "s", main = "plot(x, type = \"s\")")
points(x, cex = .5, col = "dark red")
plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10,
main = "rpois(100, lambda = 5)")
plot(cars)
lines(lowess(cars))
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
with(my_dataset,
plot(date_time, c,
type = 'n',
ylab = "Global Active Power",
xlab = "datetime")
)
with(my_dataset,
lines(date_time, Global_reactive_power, pch = 20)
)
dev.off()
with(my_dataset,
plot(date_time, Global_reactive_power,
type = 'n',
ylab = "Global Active Power",
xlab = "datetime")
)
with(my_dataset,
lines(date_time, Global_reactive_power, pch = 20)
)
with(my_dataset,
plot(date_time, Global_reactive_power,
type = 'n',
#ylab = "Global Active Power",
xlab = "datetime")
)
with(my_dataset,
lines(date_time, Global_reactive_power, pch = 20)
)
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
y <- "Global_reactive_power"
my_dataset[y,]
my_dataset[y]
my_dataset[[y]]
str(my_dataset[y])
str(my_dataset[[y]])
my_dataset$Global_reactive_power
plot(my_dataset$date_time, my_dataset[[y]],
type = 'n',
ylab = "Global Active Power (kilowatts)",
xlab = "")
lines(my_dataset$date_time, my_dataset[[y]], pch = 20)
graph_w_lines(my_dataset$Global_active_power,
ylab = "Global Active Power (kilowatts)")
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
graph_w_lines(my_dataset$Global_active_power,
ylab = "Global Active Power (kilowatts)")
graph_w_lines(my_dataset$Global_active_power,
ylab = "Global Active Power (kilowatts)")
graph_w_lines
plot(my_dataset$date_time, my_dataset[[y]],
type = 'n',
ylab = "Global Active Power (kilowatts)",
xlab = "")
lines(my_dataset$date_time, my_dataset[[y]], pch = 20)
graph_w_lines = function(y, ylab = "") {
plot(my_dataset$date_time, my_dataset[[y]],
type = 'n',
ylab = "Global Active Power (kilowatts)",
xlab = "")
lines(my_dataset$date_time, my_dataset[[y]], pch = 20)
}
dev.off()
browser()
png(file="plot2.png")
graph_w_lines(my_dataset$Global_active_power,
ylab = "Global Active Power (kilowatts)")
dev.off()
png(file="plot3.png")
png3()
dev.off()
png(file="plot4.png")
png4()
dev.off()
debugSource('~/Documents/GitHub/datasciencecoursera/plot_project.R')
force(ylab)
force(y)
graph_w_lines(my_dataset$Global_active_power,
ylab = "Global Active Power (kilowatts)")
force(y)
str(y)
str(my_dataset$date_time)
str(my_dataset$Global_reactive_power)
plot(my_dataset$date_time, my_dataset[[y]],
type = 'n',
ylab = "Global Active Power (kilowatts)",
xlab = "")
debugSource('~/Documents/GitHub/datasciencecoursera/plot_project.R')
plot(my_dataset$date_time, y,
type = 'n',
ylab = "Global Active Power (kilowatts)",
xlab = "")
lines(my_dataset$date_time, y, pch = 20)
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
date_time_graph_w_lines(my_dataset$Voltage, xlab = "datetime", ylab = "Voltage")
source('~/Documents/GitHub/datasciencecoursera/plot_project.R')
if(!file.exists('figures')) dir.create('figures')
png(filename = './figures/plot1.png', width = 480, height = 480, units='px')
# plot figure
with(my_dataset, hist(Global_active_power, xlab = 'Global Active Power (kilowatt)', main = 'Global Active Power', col = 'red'))
# close device
dev.off()
data$Date <- as.Date(data$Date, format = '%d/%m/%Y')
data$DateTime <- as.POSIXct(paste(data$Date, data$Time))
# open device
if(!file.exists('figures')) dir.create('figures')
png(filename = './figures/plot2.png', width = 480, height = 480, units='px')
# plot figure
Sys.setlocale(category = "LC_ALL", locale = "english")
plot(data$DateTime, data$Global_active_power, xlab = '', ylab = 'Global Active Power (kilowatt)', type = 'l')
# close device
dev.off()
data <- my_dataset
data$Date <- as.Date(data$Date, format = '%d/%m/%Y')
data$DateTime <- as.POSIXct(paste(data$Date, data$Time))
# open device
if(!file.exists('figures')) dir.create('figures')
png(filename = './figures/plot2.png', width = 480, height = 480, units='px')
# plot figure
Sys.setlocale(category = "LC_ALL", locale = "english")
plot(data$DateTime, data$Global_active_power, xlab = '', ylab = 'Global Active Power (kilowatt)', type = 'l')
# close device
dev.off()
str(data$Date)
data <- my_dataset
if(!file.exists('figures')) dir.create('figures')
png(filename = './figures/plot3.png', width = 480, height = 480, units='px')
# plot figure
Sys.setlocale(category = "LC_ALL", locale = "english")
plot(data$DateTime, data$Sub_metering_1, xlab = '', ylab = 'Energy sub metering', type = 'l')
lines(data$DateTime, data$Sub_metering_2, col = 'red')
lines(data$DateTime, data$Sub_metering_3, col = 'blue')
legend('topright', col = c('black', 'red', 'blue'), legend = c('Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3'), lwd = 1)
# close device
dev.off()
data <- my_dataset
if(!file.exists('figures')) dir.create('figures')
png(filename = './figures/plot4.png', width = 480, height = 480, units='px')
# plot figure
Sys.setlocale(category = "LC_ALL", locale = "english")
par(mfrow = c(2, 2))
plot(data$DateTime, data$Global_active_power, xlab = '', ylab = 'Global Active Power (kilowatt)', type = 'l')
plot(data$DateTime, data$Voltage, xlab = 'datetime', ylab = 'Voltage', type = 'l')
plot(data$DateTime, data$Sub_metering_1, xlab = '', ylab = 'Energy sub metering', type = 'l')
lines(data$DateTime, data$Sub_metering_2, col = 'red')
lines(data$DateTime, data$Sub_metering_3, col = 'blue')
legend('topright', col = c('black', 'red', 'blue'), legend = c('Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3'), lwd = 1)
plot(data$DateTime, data$Global_reactive_power, xlab = 'datetime', ylab = 'Global_reactive_power', type = 'l')
# close device
dev.off()
savehistory("~/work/data_science_coursera/coursera_course/h14.Rhistory")

swirl()
library(swirl)
swirl()
head(airquality)
xyplot(Ozone~Wind, ddata = airquality)
xyplot(Ozone~Wind, data = airquality)
dev.off()
xyplot(Ozone~Wind, data = airquality)
library(swirl)
swirl()
xyplot(Ozone~Wind, data = airquality, col = "red", pch = 8, main = "Big Apple Data")
xyplot(Ozone ~ Wind, data = airquality, pch=8, col="red", main="Big Apple Data")
xyplot(Ozone~Wind | as.factor(Month), data = airquality, layout = c(5,1))
xyplot(Ozone~Wind | Month, data = airquality, layout = c(5,1))
p <- xyplot(Ozone~Wind,data=airquality)
p
names(p)
mynames[myfull]
p[["formula"]]
p[["x.limits"]]
table(f)
xyplot(y~x|f, layout = c(2,1))
v1
v2
myedit("plot1.R")
source(pathtofile("plot1.R"), local = TRUE)
myedit("plot2.R")
source(pathtofile("plot2.R"), local = TRUE)
str(diamonds)
table(diamonds$color)
table(diamonds$color, diamonds$cut)
myedit("myLabels.R")
source(pathtofile("myLabels.R"), local = TRUE)
xyplot(price~carat | color*cut, data = diamonds, strip = FALSE, pch = 20, xlab = myxlab, ylab = myylab, main = mymain)
xyplot(price~carat | color*cut, data = diamonds, pch = 20, xlab = myxlab, ylab = myylab, main = mymain)
sample(colors(), 10)
pal <- colorRamp(c("red","blue"))
pal(0)
pal(1)
pal(seq(0,1,len=6))
p1 <- colorRampPalette(c("red","blue"))
p1(2)
p1(6)
0xcc
p2 <- colorRampPalette(c("red", "yellow"))
p2(2)
p2(10)
showMe(p1(20))
showMe(p2(20))
showMe(p2(2))
p1
?rgb
p3 <- colorRampPalette(c("blue", "green"), .5)
p3 <- colorRampPalette(c("blue", "green"), alpha=.5)
p3(5)
plot(x, y, pch = 19, col = rgb(0, .5, .5))
plot(x, y, pch = 19, col = rgb(0, .5, .5, .3))
cols <- brewer.pal(3, "BuGn")
showMe(cols)
pal <- colorRampPalette(cols)
showMe(pal(3))
showMe(pal(20))
image(volcano, col = pal(20))
image(volcano, col = p1(20))
str(mpg)
qplot(displ, hwy, data = mpg)
qplot(displ, hwy, data = mpg, color = drv)
qplot(displ, hwy, data = mpg, color = drv, geom = c("point", "smooth"))
qplot(hwy, data= mpg, color = drv)
qplot(y=hwy, data = mpg, color = drv)
myhigh
qplot(drv, hwy, data = mpg, geom = "boxplot")
qplot(drv, hwy, data = mpg, geom = "boxplot", color = manufacturer)
qplot(hwy, data = mpg, fill = drv)
qplot(displ, hwy, data = mpg, facets = . ~ drv)
qplot(hwy, data = mpg, facets = drv ~ ., binwidth = 2)
qplot(displ, hwy, data=mpg, geom = c("point", "smooth"), facets = .~drv)
g <- ggplot(mpg, aes(displ, hwy))
summary(g)
g+geom_point()
g+geom_point() + geom_smooth()
g+geom_point() + geom_smooth(method = "lm")
g+geom_point() + geom_smooth(method = "lm") + facet_grid(. ~ drv)
g+geom_point() + geom_smooth(method = "lm") + facet_grid(. ~ drv) + ggtitle("Swirl Rules!")
g + geom_point(color = "pink", size = 4, alpha = 1/2)
g + geom_point(size = 4, alpha = 1/2, aes(color = drv))
g + geom_point(aes(color = drv)) + labs(title = "Swirl Rules!") + labs(x = "Displacement", y = "Hwy Mileage")
g + geom_point(size = 4, alpha = 1/2, aes(color = drv)) + geom_smooth(size = 4, linetype = 3, method = "lm", se = FALSE)
g + geom_point(aes(color = drv),size=2,alpha=1/2) +geom_smooth(size=4,linetype=3,method="lm",se=FALSE)
g + geom_point(aes(color = drv)) + theme_bw(base_family = "Times")
plot(myx, myy, type="l", ylim=c(-3,3))
g <- ggplot(data = testdat, aes(x = myx, y = myy))
g + geom_line()
g + geom_line() + ylim(-3,3)
g + geom_line() + coord_cartesian(ylim(-3,3))
g + geom_line() + coord_cartesian(ylim = -3,3)
g + geom_line() + coord_cartesian(ylim = c(-3,3))
g <- ggplot(dataset, aes(x = displ, y = hwy, colo = factor(year)))
g <- ggplot(mpg, aes(x = displ, y = hwy, colo = factor(year)))
g <- ggplot(mpg, aes(x = displ, y = hwy, color = factor(year)))
g + geom_point()
g + geom_point() + facet_grid(drv~cyl, margins = T)
g + geom_point() + facet_grid(drv~cyl, margins = TRUE)
g + geom_point() + facet_grid(drv~cyl, margins = TRUE) + geom_smooth(method = "lm", se = FALSE, size = 2, color = "black")
g + geom_point() + facet_grid(drv~cyl, margins = TRUE) + geom_smooth(method = "lm", se = FALSE, size = 2, color = "black") + labs(x = "Displacement", y = "Highway Mileage", title = "Swirl Rules!")
str(diamonds)
qplot(price, data = diamonds)
range(diamonds$price)
qplot(price, data = diamonds, binwidth = 18497/30)
brk
counts
qplot(price, data = diamonds, binwidth = 18497/30, fill = cut)
qplot(price, data = diamonds, geom = "density")
qplot(price, data = diamonds, geom = "density", color = cut)
qplot(carat, price, data = diamonds)
qplot(carat, price, data = diamonds, shape = cut)
qplot(carat, price, data = diamonds, color = cut)
qplot(carat, price, data = diamonds, color = cut, geom_smooth(method = "lm"))
qplot(carat, price, data = diamonds, color = cut, geom_smooth())
qplot(carat, price, data = diamonds, color = cut, aes(geom_smooth()))
qplot(carat, price, data = diamonds, color = cut, aes(geom_smooth(method = "lm")))
qplot(carat, price, data = diamonds, color = cut)
qplot(carat,price,data=diamonds, color=cut) + geom_smooth(method="lm")
qplot(carat,price,data=diamonds, color=cut, facets = .~5) + geom_smooth(method="lm")
qplot(carat,price,data=diamonds, color=cut, facets = .~cut) + geom_smooth(method="lm")
g <- ggplot(diamonds, aes(depth, price))
summary(g)
g <- ggplot(diamonds, aes(depth, price)) + geom_point(alpha = 1/3)
g <- ggplot(diamonds, aes(depth, price))
g  + geom_point(alpha = 1/3)
cutpoints <- quantile(diamonds$carat, seq(0,1,length = 4), na.rm = TRUE)
cutpoints
diamonds$car2 <- cut(diamonds$carat, cutpoints)
summary(diamonds$car2)
g <- ggplot(diamonds,aes(depth,price))
g + geom_point(alpha = 1/3) + facet_grid(cut ~ car2)
diamonds[myd,]
g+geom_point(alpha=1/3)+facet_grid(cut~car2) + geom_smooth(method = "lm", size = 3, color = pink)
g+geom_point(alpha=1/3)+facet_grid(cut~car2) + geom_smooth(method = "lm", size = 3, color = "pink")
(diamonds, aes(carat, price)) + geom_boxplot() + facet_grid(. ~ cut)
ggplot2(diamonds, aes(carat, price)) + geom_boxplot() + facet_grid(. ~ cut)
ggplot(diamonds, aes(carat, price)) + geom_boxplot() + facet_grid(. ~ cut)
savehistory("~/work/data_science_coursera/coursera_course/h15.Rhistory")

library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight, panel.abline())
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight, panel.abline(3))
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
summary(p)
library(datasets)
data(airquality)
library(datasets)
data(airquality)
library(datasets)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(ggplot2)
library(ggplot2movies)
g <- ggplot(movies, aes(votes, rating))
print(g)
summary(ggplot2movies)
summary(movies)
install.packages("ggplot2movies")
library(ggplot2)
library(ggplot2movies)
g <- ggplot(movies, aes(votes, rating))
print(g)
summary(movies)
summary(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
jpeg("m1")
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
jpeg("m2")
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
data(airquality)
jpeg("m1")
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
dev.off
dev.off()
jpeg("m2.jpg")
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
dev.off()
heatmap(diamonds)
str(diamonds)
heatmap(diamonds$price, diamonds$carat)
heatmap(x as.numeric(diamonds$price), diamonds$carat)
heatmap(as.numeric(diamonds$price), diamonds$carat)
heatmap(table(diamonds$price, diamonds$carat))
gray()
gray(2)
gray(0.3)
swirl()
dist(dataFrame)
summary(distxy)
hc <- hclust(distxy)
plot(hc)
hc <- hclust(distxy
)
distxy
plot(as.dendrogram(hc))
abline(h = 1.5, col = "blue")
abline(h = .4, col = "red")
5
12
abline(h = .05, col = "green")
dFsm
dist(dFsm)
hc
heatmap
heatmap(dataMatrix,col=cm.colors(25))
str(mt)
heatmap(mt)
mt
plot(denmt)
distmt
cx
cmat
points(cx, cy, col = c("red", "orange", "purple", pch = 3, cex = 2, lwd = 2))
points(cx, cy, col = c("red", "orange", "purple"), pch = 3, cex = 2, lwd = 2)
mdist
mdist(x,y,cx,cy)
apply(distTMP, 2, which.min)
apply(distTmp, 2, which.min)
points(x, y, pch = 19, cex = 2, col = cols1[newClust])
tapply(x, newClust, mean)
newClust
tapply(y, newClust, mean)
newCx
points(newCx,newCy,col=cols1,pch=8,cex=2,lwd=2)
mdist(x, y, newCx, newCy)
apply(distTmp2, 2, which.min)
newClust2
points(x,y,pch=19,cex=2,col=cols1[newClust2])
tapply(x, newClust2, mean)
tapply(y, newClust2, mean)
finalCx
points(finalCx,finalCy,col=cols1,pch=9,cex=2,lwd=2)
kmeans(dataFrame, centers = 3)
kmObj
kmObj$iter
kmObj$cluster
plot(x,y,col=kmObj$cluster,pch=19,cex=2)
col=c("black","red","green")
points(kmObj$centers,col=c("black","red","green"),pch=3,cex=3,lwd=3)
kmeans(dataFrame,6)$cluster
plot(x,y,col=kmeans(dataFrame,6)$cluster,pch=19,cex=2)
head(dataMatrix)
heatmap(dataMatrix)
myedit("addPatt.R")
source("addPatt.R", local = TRUE)
heatmap(dataMatrix)
mat
svd(mat)
matu * diag * t(matv)
matu %*% diag %*% t(matv)
scale(mat)
svd(scale(mat))
prcomp(scale(mat))
svd1$v[,1]
svd1$d
View(svd1)
head(constantMatrix)
svd$d
svd2$d
svd2$v[,c(1,2)]
svd2$d
dim(faceData)
(svd1$u[,1] and svd1$d[1])
(svd1$u[,1], svd1$d[1])
(svd1$u[,1] * svd1$d[1])
a1 <- (svd1$u[,1] * svd1$d[1]) %*% t(svd1$v[,1])
image()
image(a1)
myImage
myImage(a1)
a2 <- (svd1$u[,1] %*% svd1$d[1:2]) %*% t(svd1$v[,1:2])
a2 <- (svd1$u[,1] %*% diag(svd1$d[1:2])) %*% t(svd1$v[,1:2])
a2 <- svd1$u[,1] %*% diag(svd1$d[1:2])
a2 <- svd1$u[,1] %*% diag(svd1$d[1])
a2 <- svd1$u[,1] * svd1$d[1]
a2 <- (svd1$u[,1:2] %*% diag(svd1$d[1:2])) %*% t(svd1$v[,1:2])
a2 <- svd1$u[,1:2] %*% diag(svd1$d[1:2]) %*% t(svd1$v[,1:2])
myImage(a2)
a5 <- svd1$u[,1:5] %*% diag(svd1$d[1:5]) %*% t(svd1$v[,1:5])
myImage(svd1$u[,1:5] %*% diag(svd1$d[1:5]) %*% t(svd1$v[,1:5]))
save.image("~/work/data_science_coursera/coursera_course/env_pca.RData")
View(myImage)
myImage(svd1$u[,1:10] %*% diag(svd1$d[1:10]) %*% t(svd1$v[,1:10]))
dim(ssid)
dim(sid)
dim(ssd)
names(ssd[562:563])
savehistory("~/work/data_science_coursera/coursera_course/h16.Rhistory")

table(ssd$subject)
sum(table(ssd$subject))
table(v)
table(ssd$activity)
sub1 <- subset(ssd, subset = 1)
sub1 <- subset(ssd, subset = true)
sub1 <- subset(ssd, subset = TRUE)
sub1 <- subset(ssd, subject == 1)
dim(sub1)
names(sub1)
names(sub1[1:12])
myedit("showXY.R")
showMe(1:6)
mdist
mdist <- dist(sub1[,1:3])
hclustering <- hclust(mdist)
myplclust(hclustering, lab.col = unclass(sub1$activity))
mdist <- dist(x[,10:12])
mdist <- dist(sub1[,10:12])
hclustering <- hclust(mdist)
myplclust(hclustering, lab.col = unclass(sub1$activity))
svd1 <- svd(scale(sub1[,-c(562,563)]))
dim(svd1$u)
maxCon <- which.max(svd1$v[,2])
mdist <- dist(c(sub1[10:12], maxCon)
)
mdist <- dist(sub1[c(10:12, maxCon)])
mdist <- dist(sub1[,c(10:12, maxCon)])
hclustering <- hclust(mdist)
myplclust(hclustering, lab.col = unclass(sub1$activity))
names(sub1[maxCon])
kClust <- kmeans(sub1[,-(562:563)], centers = 6)
kClust1 <- kClust
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6)
identical(kClust, kClust1)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[, -c(562, 563)], centers = 6, nstart = 100)
table(kClust$cluster, sub1$activity)
dim(kClust$centers)
laying <- which(kClust$size==29)
plot(kClust$centers[laying,1:12], pch = 19, ylab = "Laying Cluster")
names(sub1[,1:3])
walkdown <- which(kClust$size==49)
plot(kClust$centers[walkdown,1:12], pch = 19, ylab = "Walkdown Cluster")
dim(pm0)
head(pm0)
cnames
cnames <- strsplit(cnames, "|", fixed = TRUE)
cnames
View(ssd)
names(pm0) <- make.names(cnames[[1]][wcol])
head(pm0)
x0 <- pm0$Sample.Value
str(x0)
mean(is.na(x0))
names(pm1) <- make.names(cnames[[1]][wcol])
dim(pm1)
x1 <- pm1$Sample.Value
mean(is.na(x1))
summary(x0)
summary(x1)
boxplot(x0, x1)
boxplot(log10(x0), log10(x1))
negative <- x1<0
sum(negative, na.rm = TRUE)
mean(negative, na.rm = TRUE)
dates <- pm1$Date
str(dates)
dates <- as.Date(as.character(dates), "%Y%m%d")
head(dates)
hist(dates[negative], "month")
str(site0)
intersect(site0, site1)
both <- intersect(site0, site1)
both
head(pm0)
cnt0 <- subset(pm0, State.Code == 36 & State.Code %in% both)
cnt0 <- subset(pm0, State.Code == 36 & county.site %in% both)
cnt1 <- subset(pm1, State.Code == 36 & county.site %in% both)
sapply(split(cnt0, cnt0$county.site), nrow)
sapply(split(cnt1, cnt1$county.site), nrow)
pm0sub <- subset(cnt0, County.Code == 63 & Site.ID == 2008)
pm0sub1 <- subset(cnt0, county.site == "63.2008")
identical(pm0sub, pm0sub1)
pm1sub <- subset(cnt1, County.Code == 63 & Site.ID == 2008)
x0sub <- pm0sub$Sample.Value
x1sub <- pm1sub$Sample.Value
dates0 <- as.Date(as.character(pm0sub$Date), "%Y%m%d")
dates1 <- as.Date(as.character(pm1sub$Date), "%Y%m%d")
par(mfrow = c(1,2))
par(mfrow = c(1, 2), mar = c(4, 4, 2, 1))
plot(dates0, x0sub, pch = 20)
abline(h = median(x0sub, na.rm = TRUE))
abline(h = median(x0sub, na.rm = TRUE), lwd=2)
plot(dates1, x1sub, pch = 20)
abline(h = median(x1sub, na.rm = TRUE), lwd=2)
rng <- range(x0sub, x1sub, na.rm = TRUE)
rng
mn0 <- with(pm0, tapply(Sample.Value, State.Code, mean, na.rm = TRUE))
str(mn0)
mn1 <- with(pm1, tapply(Sample.Value, State.Code, mean, na.rm = TRUE))
str(mn1)
summary(mn0)
summary(mn1)
d0 <- data.frame(state = names(mn0), mean = mn0)
d1 <- data.frame(state = names(mn1), mean = mn1)
mrg <- merge(d0, d1, by = "state")
dim(mrg)
head(mrg)
with(mrg, plot(rep(1,52), mrg[,2], xlim = c(.5,2.5)))
with(mrg, points(rep(2,52), mrg[,3]))
segments(rep(1,52), rep(2,52))
segments(rep(1,52), mrg[,2], rep(2,52), mrg[,3])
mrg[mrg$mean.x < mrg$mean.y, ]
savehistory("~/work/data_science_coursera/coursera_course/h17.Rhistory")

source('~/work/data_science_coursera/coursera_course/project2_explan.R')
head(NEI)
source('~/work/data_science_coursera/coursera_course/project2_explan.R')
head(NEI)
source('~/work/data_science_coursera/coursera_course/project2_explan.R')
head(SCC)
head(NEI)
unique(NEI$Pollutant)
unique(NEI$POINT)
unique(NEI$type)
mn1 <- with(pm1, tapply(Sample.Value, State.Code, mean, na.rm = TRUE))
as.factor(NEI$year)
NEI$year <- as.factor(NEI$year)
tapply(NEI$Emissions, NEI$year, sum)
plot(c)
plot(tapply(NEI$Emissions, NEI$year, sum))
res1 <- tapply(NEI$Emissions, NEI$year, sum)
str(res1)
hist(res1)
y <- as.Date(as.character(NEI$year))
y <- as.Date(as.character(NEI$year), "%Y")
source('~/work/data_science_coursera/coursera_course/project2_explan.R')
res1 <- tapply(NEI$Emissions, NEI$year, sum)
summary(NEI$Emissions)
table(res1)
hist(NEI$Emissions)
hist(NEI$Emissions, NEI$year)
res2 <- split(NEI$Emissions, NEI$year)
res3 <- sapply(split(NEI$Emissions, NEI$year), sum)
str(res3)
table(res3)
data.table(res3)
data.frame(res3)
hist(data.frame(res3))
hist(data.frame(res3[,1]))
hist(data.frame(res3[1]))
str(data.frame(res3))
df3 <- data.frame(res3)
hist(df3$res3)
plot(df3$res3)
plot(df3$res3, xlab = rnames(res3) )
rownames(res3)
rownames(res1)
plot(df3$res3, xlab = rownames(res1) )
plot(df3$res3, rownames(res1) )
str(res1)
dim(res1)
as.data.frame(res1)
str(as.data.frame(res1))
rownames(as.data.frame(res1))
transform(as.data.frame(res1), year <- rownames(as.data.frame(res1)))
year <- rownames(as.data.frame(res1))
year
res4 <- transform(as.data.frame(res1), year = factor(rownames(as.data.frame(res1))))
View(res4)
with(res4, plot(year, res1))
res5 <- transform(as.data.frame(res1), year = rownames(as.data.frame(res1)))
View(res5)
res5 <- transform(as.data.frame(res1), year = rownames(res1))
res5 <- transform(res1, year = rownames(res1))
str(res5)
with(res5, plot(year, X_data))
with(res5, plot(year, X_data, ylab = "Total Emission"))
subset(NEI, sunset)
balt <- subset(NEI, fips == "24510")
source('~/work/data_science_coursera/coursera_course/project2_explan.R')
with(res2, plot(year, X_data, ylab = "Total Emissions", xlim = c(1990, 2012) ))
names(res2)
res1 <- tapply(NEI$Emissions, NEI$year, sum)
res2 <- transform(res1, year = rownames(res1))
names(res2)
names(res2) <- (c("Total.Emission", "Year"))
names(res2)
res1 <- tapply(NEI$Emissions, NEI$year, sum)
res2 <- transform(res1, year = rownames(res1))
names(res2) <- (c("Total.Emission", "Year"))
with(res2, plot(year, Total.Emission, ylab = "Total Emissions", xlim = c(1990, 2012) ))
with(res2, plot(year, Total.Emission, ylab = "Total Emissions", xlim = c(1998, 2010) ))
source('~/work/data_science_coursera/coursera_course/project2_explan.R')
balt <- transform(balt$type <- as.factor(balt$type))
str(balt)
balt <- subset(NEI, fips == "24510")
balt <- transform(balt$type <- as.factor(balt$type))
balt <- subset(NEI, fips == "24510")
transform(balt, new_type = as.factor(balt$type), new_tear = as.factor(year))
balt <- subset(NEI, fips == "24510")
balt1 <- subset(balt, new_type = as.factor(balt$type), new_tear = as.factor(year), Emissions)
balt1 <- transform(balt, new_type = as.factor(balt$type), new_tear = as.factor(year), Emissions)
str(balt)
str(balt1)
balt <- subset(NEI, fips == "24510")
balt1 <- transform(balt, new_type = as.factor(balt$type), new_tear = as.factor(year))
str(balt1)
library(ggplot2)
balt2 <- subset(NEI, fips == "24510", new_type = as.factor(balt$type), new_tear = as.factor(year))
str(balt2)
type1 <- split(balt1, balt1$new_type)
str(type1)
unique(type1$type)
balt <- subset(NEI, fips == "24510")
balt1 <- transform(balt, new_type = as.factor(balt$type), new_year = as.factor(balt$year))
type1 <- split(balt1, balt1$new_type)
str(type1)
plot1(type1)
type1[1]
plot1(type1[1])
str(type1[1])
str(type1[[1]])
plot1(type1[[1]])
plot1(type1[[2]])
plot1(type1[[3]])
plot1(type1[[4]])
title(main = unique(type1[[4]]$type))
for (i in range(1:4)) {}
for (i in range(1:4)) {print(i)
plot1(type1[[i]])
title(main = unique(type1[[i]]$type))
}
for (i in 1:4) {print(i)
plot1(type1[[i]])
title(main = unique(type1[[i]]$type))
}
par(mfrow = c(1, 4), mar = c(4, 4, 2, 1))
for (i in 1:4) {print(i)
plot1(type1[[i]])
title(main = unique(type1[[i]]$type))
}
for (i in 1:4) {
res1 <- tapply(NEI$Emissions, NEI$year, sum)
res2 <- transform(res1, year = rownames(res1))
names(res2) <- (c("Total.Emission", "Year"))
with(res2, plot(year, Total.Emission, ylab = "Total Emissions", xlim = c(1998, 2009) ))
ggplot(type1[[i]])
title(main = unique(type1[[i]]$type))
}
length(type1)
seq(length(type1))
source('~/work/data_science_coursera/coursera_course/project2_explan.R')
balt <- subset(NEI, fips == "24510")
balt1 <- transform(balt, new_type = as.factor(balt$type), new_year = as.factor(balt$year))
type1 <- split(balt1, balt1$new_type)
debugSource('~/work/data_science_coursera/coursera_course/project2_explan.R')
ggplot(red2$year, res2$Total.Emission)
ggplot(res2$year, res2$Total.Emission)
qplot(res2$year, res2$Total.Emission)
qplot(year, Total.Emission, data = res2, facets = new_type)
qplot(year, Total.Emission, data = res2, facets = type)
qplot(year, Total.Emission, data = res2, facets = . ~ type)
balt <- subset(NEI, fips == "24510")
balt1 <- transform(balt, new_type = as.factor(balt$type), new_year = as.factor(balt$year))
#  res1 <- tapply(balt1$Emissions, balt1$year, sum)
#  res2 <- transform(res1, year = rownames(res1))
qplot(year, Total.Emission, data = balt1, facets = . ~ new_type)
qplot(year, Emission, data = balt1, facets = . ~ new_type)
str(balt1)
qplot(year, Emissions, data = balt1, facets = . ~ new_type)
qplot(carat,price,data=diamonds, color=cut) + geom_smooth(method="lm")
qplot(year, Emissions, data = balt1, facets = . ~ as.factor(type)) + geom_smooth()
balt <- subset(NEI, fips == "24510")
qplot(as.factor(year), Emissions, data = balt, facets = . ~ as.factor(type)) + geom_smooth()
qplot(as.factor(year), Emissions, data = balt, facets = . ~ as.factor(type)) + geom_smooth(method = "lm")
qplot(as.factor(year), Emissions, data = balt, facets = . ~ as.factor(type)) + labs(x = "Years")
qplot(as.factor(year), Emissions, data = balt, facets = . ~ as.factor(type)) + labs(x = "Years", title = "Emissions in the Baltimore City")
source('~/Documents/GitHub/datasciencecoursera/project2_expl.R')
str(SCC)
?grep
grep("coal", SCC, ignore.case = T)
library(stringi)
names(SCC)
grep("coal", SCC$Short.Name, ignore.case = T, value = T )
View(SCC)
length(grep("coal", SCC$SCC.Level.Four, ignore.case = T, value = T ))
length(unique(grep("coal", SCC$SCC.Level.Four, ignore.case = T , value = T))
)
length(unique(grep("coal", SCC$SCC.Level.Four, ignore.case = T, value = T ))
)
length(unique(grep("combustion", SCC$SCC.Level.Four, ignore.case = T, value = T ))
)
length(unique(grep("combustion", SCC$Short.Name, ignore.case = T, value = T ))
)
comb <- unique(grep("combustion", SCC$Short.Name, ignore.case = T, value = T ))
comb_coal <- unique(grep("coal", comb, ignore.case = T, value = T ))
str(comb_coal)
comb14 <- unique(grep("combustion", SCC$SCC.Level.Four, ignore.case = T, value = T ))
comb4_coal <- unique(grep("coal", comb14, ignore.case = T, value = T ))
comb4_coal
comb_coal
grep("combustion", SCC$Short.Name, ignore.case = T) %>%
grep("coal", ignore.case = T)
library(dplyr)
grep("combustion", SCC$Short.Name, ignore.case = T) %>%
grep("coal", ignore.case = T)
coal_combustion0 <- grep("combustion", SCC$Short.Name, ignore.case = T)
coal_combustion1 <- grep("coal", coal_combustion0, ignore.case = T)
coal_combustion0 <- grep("combustion", SCC$Short.Name, ignore.case = T, value = T)
coal_combustion1 <- grep("coal", coal_combustion0, ignore.case = T)
coal_combustion0 <- grep("combustion", SCC$Short.Name, ignore.case = T, value = T)
coal_combustion1 <- grepl("coal", coal_combustion0, ignore.case = T)
coal_combustion2 <- subset(SCC$SCC, SCC$Short.Name[coal_combustion1])
coal_combustion2 <- subset(SCC$SCC, SCC$Short.Name == coal_combustion1)
coal_combustion2 <- SCC$SCC[SCC$Short.Name = coal_combustion1]
coal_combustion2 <- SCC$SCC[SCC$Short.Name == coal_combustion1]
coal_combustion <- grepl("(coal.*combustion)| (combustion.*coal)", SCC$Short.Name, ignore.case = T)
str(SCC$Short.Name)
sum(coal_combustion)
rr1 <- SCC$Short.Name[coal_combustion]
coal_combustion_logic <- grepl("(coal.*combustion)| (combustion.*coal)", SCC$Short.Name, ignore.case = T)
a <- matrix(1:9, nrow = 3)
colnames(a) <- c("A", "B", "C")
a
a[c(TRUE, FALSE, TRUE),]
coal_combustion_logic <- grepl("(coal.*combustion)| (combustion.*coal)", SCC$Short.Name, ignore.case = T)
filter(SCC, SCC == coal_combustion_logic)
SCC$SCC[coal_combustion_logic]
str(SCC$SCC[coal_combustion_logic])
ccl <- SCC$SCC[coal_combustion_logic]
filter(SCC, SCC in ccl) %>% head
filter(SCC, SCC == ccl) %>% head
coal_combustion_logic <- grepl("(coal.*combustion)| (combustion.*coal)", SCC$Short.Name, ignore.case = T)
# sum(coal_combustion) 8
ccl <- SCC$SCC[coal_combustion_logic]
SCC[,ccl]
SCC[,SCC[coal_combustion_logic]]
str(starwars)
filter(starwars, species == "Human") %>% head()
# coal_combustion_logic <- grepl("(coal.*combustion)| (combustion.*coal)", SCC$Short.Name, ignore.case = T)
# sum(coal_combustion) 8
# ccl <- SCC$SCC[coal_combustion_logic]
coal_combustion_df <- filter(SCC,
grepl("(coal.*combustion)| (combustion.*coal)", SCC$Short.Name, ignore.case = T))
coal_combustion_df <- filter(SCC,
grepl("(coal.*combustion)| (combustion.*coal)", Short.Name, ignore.case = T))
View(coal_combustion_df)
inner_join(coal_combustion_df, NEI, by = SCC) %>%
HEAD
inner_join(coal_combustion_df, NEI, by = SCC) %>%
head
head()
qq <- inner_join(coal_combustion_df, NEI, by = SCC)
NEI %>% inner_join(coal_combustion_df, by = "SCC") %>% head()
NEI %>% left_join(coal_combustion_df, by = "SCC") %>% head()
NEI %>% left_join(coal_combustion_df, by = "SCC") %>% dim()
NEI %>% left_join(coal_combustion_df, by = "SCC") %>% str()
NEI %>% left_join(coal_combustion_df, by = "SCC") -> coal_combustion_df_nei
length(unique(coal_combustion_df_nei$SCC))
length(unique(NEI$SCC))
length(unique(coal_combustion_df$SCC))
good_scc <- coal_combustion_df$SCC
savehistory("~/work/data_science_coursera/coursera_course/h18.Rhistory")

SCC[grepl("(coal.*combustion)|(combustion.*coal)", SCC$Short.Name, ignore.case = T),]
a1 <- SCC[grepl("(coal.*combustion)|(combustion.*coal)", SCC$Short.Name, ignore.case = T),]
identical(a1, coal_combustion_df)
a2 <- NEI[grepl("(coal.*combustion)|(combustion.*coal)", SCC$Short.Name, ignore.case = T),]
unique(as$SCC)
unique(a1$SCC)
unique(a2$SCC)
coal_combustion_logic <- grepl("(coal.*combustion)| (combustion.*coal)", SCC$Short.Name, ignore.case = T)
NEI[NEI$SCC = coal_combustion_logic,]
NEI[NEI$SCC == coal_combustion_logic,]
coal_combustion_val <- grep("(coal.*combustion)| (combustion.*coal)", SCC$Short.Name, ignore.case = T, value = T)
NEI[NEI$SCC = coal_combustion_val,]
NEI[NEI$SCC == coal_combustion_val,]
NEI$SCC == coal_combustion_val
NEI$SCC = coal_combustion_val
NEI$SCC in coal_combustion_val
str(coal_combustion_val)
coal_combustion_val
NEI$SCC %in% coal_combustion_val %>% head()
NEI[NEI$SCC %in% coal_combustion_val, ] %>% head()
NEI$SCC %in% coal_combustion_val
sum(NEI$SCC %in% coal_combustion_val)
NEI <- readRDS("data/summarySCC_PM25.rds")
SCC <- readRDS("data/Source_Classification_Code.rds")
clean_year(NEI)
sum(NEI$SCC %in% coal_combustion_val)
coal_combustion_val
a1 <- SCC[grepl("(coal.*combustion)|(combustion.*coal)", SCC$Short.Name, ignore.case = T),]
coal_combustion_val <- SCC[grepl("(coal.*combustion)|(combustion.*coal)", SCC$Short.Name, ignore.case = T), SCC$SCC]
a1$SCC
coal_combustion_val <- a1$SCC
NEI[NEI$SCC %in% coal_combustion_val, ] %>% head()
NEI %>% left_join(a1, by = "SCC") %>% head()
coal_combustion_df <- SCC[grepl("(coal.*combustion)|(combustion.*coal)", SCC$Short.Name, ignore.case = T),]
coal_combustion_val <- coal_combustion_df$SCC
coal_combustion_df_nei <- NEI[NEI$SCC %in% coal_combustion_val, ]
unique(coal_combustion_df_nei$SCC)
identical(unique(coal_combustion_df_nei$SCC), coal_combustion_val)
identical(unique(coal_combustion_df_nei$SCC), unique(coal_combustion_val))
unique(coal_combustion_val)
unique(coal_combustion_val) %>% order()
order(coal_combustion_val)
unique(coal_combustion_df_nei$SCC) %>% order()
unique(coal_combustion_df_nei$SCC) %>% ordered()
unique(coal_combustion_df_nei$SCC) %>% ordered() -> o2
ordered(coal_combustion_val)
identical(ordered(coal_combustion_val), 02)
identical(ordered(coal_combustion_val), o2)
source('~/Documents/GitHub/datasciencecoursera/project2_expl.R')
qplot(as.factor(year), Emissions, data = coal_combustion_df_nei, facets = . ~ as.factor(type)) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
source('~/Documents/GitHub/datasciencecoursera/project2_expl.R')
qplot(as.factor(year), Emissions, data = coal_combustion_df_nei) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
qplot(as.factor(year), Emissions, data = coal_combustion_df_nei, facets = . ~ as.factor(SCC)) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
NEI$SCC.Names = coal_combustion_names
source('~/Documents/GitHub/datasciencecoursera/project2_expl.R')
coal_combustion_df <- SCC[grepl("(coal.*combustion)|(combustion.*coal)", SCC$Short.Name, ignore.case = T),]
coal_combustion_val <- coal_combustion_df$SCC
coal_combustion_names <- coal_combustion_df$Short.Name
coal_combustion_names
coal_combustion_df_nei <- NEI[NEI$SCC %in% coal_combustion_val, ]
coal_combustion_df_nei %>% left_join(coal_combustion_names)
coal_combustion_df_nei %>% left_join(coal_combustion_names, copy = T)
coal_combustion_df_nei %>% left_join(coal_combustion_names, copy = T, by = SCC)
coal_combustion_df_nei %>% left_join(coal_combustion_names, copy = T, by = "SCC")
str(coal_combustion_df_nei)
merge(NEI, coal_combustion_df, by = "SCC")
merge(NEI, coal_combustion_df, by = "SCC") %>% str
source('~/Documents/GitHub/datasciencecoursera/project2_expl.R')
qplot(as.factor(year), Emissions, data = coal_combustion_df_nei) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
qplot(as.factor(year), Emissions, data = coal_combustion_df_nei, facets = . ~ as.factor(SCC)) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
qplot(as.factor(year), Emissions, data = coal_combustion_df_nei, facets = . ~ as.factor(Short.Name)) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
names(coal_combustion_df_nei)
coal_combustion_df <- SCC[grepl("(coal.*combustion)|(combustion.*coal)", SCC$Short.Name, ignore.case = T),]
coal_combustion_df_nei <- merge(NEI, coal_combustion_df, by = "SCC")
qplot(as.factor(year), Emissions, data = coal_combustion_df_nei, facets = . ~ as.factor(Short.Name)) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
coal_combustion_df_nei %>% unique(Short.Name)
unique(coal_combustion_df_nei$Short.Name)
qplot(as.factor(year), Emissions, data = coal_combustion_df_nei, facets = . ~ as.factor(CSS)) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
qplot(as.factor(year), Emissions, data = coal_combustion_df_nei, facets = . ~ as.factor(SCC)) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
vehicle_df <- SCC[grepl("vehicle", SCC$Short.Name, ignore.case = T),]
vehicle_df$Short.Name
vehicle_df <- SCC[grepl("Motor Vehicl", SCC$Short.Name, ignore.case = T),]
vehicle_df$Short.Name
merge(NEI, vehicle_df, by = "SCC") %>%
subset(fips == "24510") -> vehicle_df_nei_balt
qplot(as.factor(year), Emissions, data = vehicle_df_nei_balt, facets = . ~ as.factor(SCC)) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
str(vehicle_df_nei_balt)
vehicle_df_nei_balt$Short.Name
vehicle_df <- SCC[grepl("Motor Vehicl", SCC$Short.Name, ignore.case = T),]
vehicle_df_nei <- merge(NEI, vehicle_df, by = "SCC")
vehicle_df_nei_Balt <- subset(vehicle_df_nei, fips == "24510")
vehicle_df_nei_LA <- subset(vehicle_df_nei, fips == "06037")
str(vehicle_df_nei_LA)
str(vehicle_df_nei)
source('~/Documents/GitHub/datasciencecoursera/project2_expl.R')
qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
par(mfrow = c(1, 2), mar = c(4, 4, 2, 1))
qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA, facets = . ~ as.factor(SCC)) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
source('~/Documents/GitHub/datasciencecoursera/project2_expl.R')
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
labs(x = "Years", title = "Motor vehicle emissions in Baltimore") +
xlim("1999", "2008")
p2 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA) + labs(x = "Years", title = "Motor vehicle emissions in Los Angeles County, CA")
grid.arrange(p1, p2, nrow = 1)
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
labs(x = "Years", title = "Motor vehicle emissions in Baltimore") +
xlim(1999, 2008)
p2 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA) + labs(x = "Years", title = "Motor vehicle emissions in Los Angeles County, CA")
grid.arrange(p1, p2, nrow = 1)
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
labs(x = "Years", title = "Motor vehicle emissions in Baltimore") +
scale_x_continuous(name="Years", limits=as.factor(year))
p2 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA) + labs(x = "Years", title = "Motor vehicle emissions in Los Angeles County, CA")
grid.arrange(p1, p2, nrow = 1)
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
labs(x = "Years", title = "Motor vehicle emissions in Baltimore") +
scale_x_continuous(name="Years", limits=as.factor(year))
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
# labs(x = "Years", title = "Motor vehicle emissions in Baltimore") +
scale_x_continuous(name="Years", limits=as.factor(year))
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
labs(x = as.factor(year), title = "Motor vehicle emissions in Baltimore"))
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
labs(x = as.factor(year), title = "Motor vehicle emissions in Baltimore")
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
labs(x = as.factor(year), title = "Motor vehicle emissions in Baltimore")  + geom_point()
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) + geom_point()
p2 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA) + labs(x = "Years", title = "Motor vehicle emissions in Los Angeles County, CA")
grid.arrange(p1, p2, nrow = 1)
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) + scale_x_continuous(name="Years", limits=as.factor(year))
p2 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA) + labs(x = "Years", title = "Motor vehicle emissions in Los Angeles County, CA")
grid.arrange(p1, p2, nrow = 1)
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
scale_x_discrete(labels = as.factor(year))
p2 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA) + labs(x = "Years", title = "Motor vehicle emissions in Los Angeles County, CA")
grid.arrange(p1, p2, nrow = 1)
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
scale_x_discrete(labels = c(1999, 20002, 2005, 2008))
p2 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA) + labs(x = "Years", title = "Motor vehicle emissions in Los Angeles County, CA")
grid.arrange(p1, p2, nrow = 1)
all_years <- as.factor(year)
all_years
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
scale_x_discrete(labels = all_years)
p2 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA) + labs(x = "Years", title = "Motor vehicle emissions in Los Angeles County, CA")
grid.arrange(p1, p2, nrow = 1)
labs(x = "Years", title = "Motor vehicle emissions in Baltimore") +
scale_y_continuous(name="Years", limits = c(10, 66)) + geom_point()
qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
scale_x_discrete(labels = all_years)
labs(x = "Years", title = "Motor vehicle emissions in Baltimore") +
scale_y_continuous(name="Years", limits = c(10, 66)) + geom_point()
ggplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
scale_x_discrete(labels = all_years)
labs(x = "Years", title = "Motor vehicle emissions in Baltimore") +
scale_y_continuous(name="Years", limits = c(10, 66)) + geom_point()
ggplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
scale_x_discrete(labels = all_years)
labs(x = "Years", title = "Motor vehicle emissions in Baltimore") +
scale_y_continuous(name="Years", limits = c(10, 66)) + geom_point()
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
labs(x = "Years", title = "Motor vehicle emissions in Baltimore") +
scale_y_continuous(name = "Years", limits = c(10, 66)) + geom_point()
p2 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA) + labs(x = "Years", title = "Motor vehicle emissions in Los Angeles County, CA")
grid.arrange(p1, p2, nrow = 1)
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
labs(x = "Years", title = "Motor vehicle emissions in Baltimore") +
scale_y_continuous(name = "Years", limits = c(10, 66))
#+ geom_point()
p2 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA) +
labs(x = "Years", title = "Motor vehicle emissions in Los Angeles County, CA") +
scale_y_continuous(name = "Years", limits = c(10, 66))
grid.arrange(p1, p2, nrow = 1)
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
labs(x = "Years", title = "Motor vehicle emissions in Baltimore") +
scale_y_continuous(name = "Years", limits = c(10, 66))
#+ geom_point()
p2 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA) +
labs(x = "Years", title = "Motor vehicle emissions in Los Angeles County, CA") +
scale_y_continuous(name = "Years", limits = c(10, 66))
grid.arrange(p1, p2, nrow = 1)
p1 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_Balt) +
labs(x = "Years", title = "Motor vehicle emissions in Baltimore") +
scale_y_continuous(limits = c(10, 66)) +
scale_x_discrete(name = "Years", limits = all_years)
p2 = qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA) +
labs(x = "Years", title = "Motor vehicle emissions in Los Angeles County, CA") +
scale_y_continuous(name = "Years", limits = c(10, 66))
grid.arrange(p1, p2, nrow = 1)
source('~/Documents/GitHub/datasciencecoursera/project2_expl.R')
dev.off()
png(file = "plot3.png")
plot3(NEI)
dev.off()
png(file = "plot4.png")
plot4(NEI, SCC)
dev.off()
png(file = "plot5.png")
plot5(NEI, SCC)
dev.off()
source('~/Documents/GitHub/datasciencecoursera/project2_expl.R')
savehistory("~/work/data_science_coursera/coursera_course/h19.Rhistory")

source('~/Documents/GitHub/datasciencecoursera/project2_expl.R')
tot_by <- aggregate(Emisions ~ year, NEI, sum)
tot_by <- aggregate(Emissions ~ year, NEI, sum)
table(tot_by)
tot_by
tapply(NEI$Emissions, NEI$year, sum)
tot_by2 <- aggregate(Emissions ~ year + type, NEI, sum)
View(tot_by2)
geom_bar
barplot(height = tot_by$Emissions)
barplot(height = tot_by$Emissions, xlab = "Year")
barplot(height = tot_by$Emissions, xlab = tot_by$year)
barplot(height = tot_by$Emissions, xlab = "Year")
savehistory("~/work/data_science_coursera/coursera_course/h20.Rhistory")

library(kernlab)
install.packages(kernlab)
install.packages("kernlab")
library(kernlab)
data(spam)
set.seed(3435)
trainIndicator = rbinom(4601, size = 1, prob = 0.5)
table(trainIndicator)
trainSpam = spam[trainIndicator == 1, ]
testSpam = spam[trainIndicator == 0, ]
names(trainSpam)
head(trainSpam)
table(trainSpam$type)
plot(trainSpam$capitalAve ~ trainSpam$type)
plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type)
plot(log10(trainSpam[, 1:4] + 1))
hCluster = hclust(dist(t(trainSpam[, 1:57])))
plot(hCluster)
hClusterUpdated = hclust(dist(t(log10(trainSpam[, 1:55]))))
hClusterUpdated = hclust(dist(t(log10(trainSpam[, 1:55] + 1))))
plot(hClusterUpdated)
trainSpam$numType = as.numeric(trainSpam$type)-1
costFunction = function(x,y) sum(x!=(y > 0.5))
cvError = rep(NA,55)
library(boot)
for(i in 1:55){
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula,family="binomial",data=trainSpam)
cvError[i] = cv.glm(trainSpam,glmFit,costFunction,2)$delta[2]
}
names(trainSpam)[which.min(cvError)]
# ===
## Use the best model from the group
predictionModel = glm(numType ~ charDollar,family="binomial",data=trainSpam)
## Get predictions on the test set
predictionTest = predict(predictionModel,testSpam)
predictedSpam = rep("nonspam",dim(testSpam)[1])
## Classify as `spam' for those with prob > 0.5
predictedSpam[predictionModel$fitted > 0.5] = "spam"
table(predictedSpam,testSpam$type)
unzip("activity.zip", list = TRUE)
unzip("/Users/ashipunova/work/data_science_coursera/intro_r/RepData_PeerAssessment1/activity.zip", list = TRUE)
activity_data <- readr::read_csv(unzip("activity.zip", "activity.csv"))
str(activity_data)
activity_data <- readr::read_csv(unzip("activity.zip", "activity.csv"))
str(activity_data)
library(readr)
activity_data <- readr::read_csv(unzip("activity.zip", "activity.csv"))
str(activity_data)
library(readr)
setwd("/Users/ashipunova/work/data_science_coursera/intro_r/RepData_PeerAssessment1/")
# unzip("sales.zip", list = TRUE)
activity_data <- readr::read_csv(unzip("activity.zip", "activity.csv"))
str(activity_data)
View(activity_data)
transform(activity_data, date = ymd(date))
library(lubridate)
transform(activity_data, date = ymd(date))
activity_data$date[[1]]
type(activity_data$date[[1]])
type(activity_data$date[1])
str(activity_data$date[[1]])
wday(activity_data$date[[1]])
wday(activity_data$date[[1]], label = T)
summarise(activity_data)
summarise(activity_data, groups(date)
)
summarise(activity_data, groups(activity_data$date))
tot_by2 <- aggregate(steps ~ date, activity_data, mean, na.rm = T)
length(unique(activity_data$date))
length(unique(tot_by2$date))
aggregate(steps ~ date, activity_data, mean, na.rm = T)
activity_data[activity_data$date == "2012-10-03"]
activity_data[activity_data$date == "2012-10-03",activity_data$steps]
activity_data[activity_data$date == "2012-10-03",]
a <- activity_data[activity_data$date == "2012-10-03",]
str(a)
sum(a$steps)
activity_mean %>% group_by(date, steps) %>%
summarise(across(everything(), list(mean))) -> all_mean
activity_data %>% group_by(date, steps) %>%
summarise(across(everything(), list(mean))) -> all_mean
activity_data %>% group_by(date, steps) %>%
summarise(across(everything(), list(sum))) -> all_sum
table(all_sum$date, all_sum$steps)
mean_std_set %>% group_by(subject, activity) %>%
summarise(avg_tbodygyrojerkmag_mean_ = mean(tbodygyrojerkmag_mean_, na.rm = T)) %>% table()
mean_std_set %>% group_by(subject, activity) %>%
summarise(across(everything(), list(mean)))
activity_data %>% group_by(date) %T>%
str
savehistory("~/work/data_science_coursera/coursera_course/h21.Rhistory")

summarise(across(everything(), list(mean)))
library(dplyr)
activity_data %>% group_by(date) %T>%
str
activity_data %>% group_by(date) %T>%
str
library(magrittr)
activity_data %>% group_by(date) %T>%
str
activity_data %>% group_by(date) %T>%
str %>%
sapply(steps, sum, na.rm = T) %>% head()
activity_data %>% group_by(date) %T>%
str %T>%
sapply(steps, sum, na.rm = T) %>% head()
activity_data %>% group_by(date) %>%
sapply(steps, sum, na.rm = T) %>% head()
activity_data %>% group_by(date) -> gr_ac
with(gr_ac, sapply(steps, sum, na.rm = T)) %>% head
with(gr_ac, sapply(steps, sum, na.rm = T)) %>% str
with(gr_ac, sapply(steps, sum, na.rm = T)) %>% table
res1 <- tapply(activity_data$steps, activity_data$date, sum)
table(res1)
res2 <- transform(res1, year = rownames(res1))
table(res2)
qplot(as.factor(date), steps, data = activity_data)
aggregate(x = activity_data$steps,                # Specify data column
by = list(activity_data$date),              # Specify group indicator
FUN = sum)                            # Specify function (i.e. sum)
sum(a$steps)
aggregate(x = activity_data$steps,                # Specify data column
by = list(activity_data$date),              # Specify group indicator
FUN = mean, na.rm = T)                            # Specify function (i.e. sum)
View(all_mean)
View(activity_data)
View(tot_by2)
step_means <- aggregate(steps ~ date, activity_data, mean, na.rm = T)
qplot(step_means)
step_means <- aggregate(steps ~ date, activity_data, mean, na.rm = T)
qplot(date, steps, data = step_means)
step_means <- aggregate(steps ~ date, activity_data, mean, na.rm = T)
qplot(date, steps, data = step_means, geom = "smooth")
step_sums <- aggregate(steps ~ date, activity_data, sum, na.rm = T)
View(step_sums)
# qplot(date, steps, data = step_means, geom = "smooth")
qplot(step_sums$steps, geom="histogram")
step_sums <- aggregate(steps ~ date, activity_data, sum, na.rm = T)
sum_plot <- qplot(step_sums$steps, geom = "histogram")
print(sum_plot)
step_means <- aggregate(steps ~ date, activity_data, mean, na.rm = T)
# qplot(date, steps, data = step_means, geom = "smooth")
activity_data %>%
group_by(date) %>%
summarise(across(steps, list(mean = mean, median = median, na.rm = T)))
activity_data %>%
group_by(date) %>%
summarise(across(steps, list(mean = mean, median = median, na.rm = T)))
activity_data %>%
group_by(as.factor(as.character(date))) %>%
summarise(across(steps, list(mean = mean, median = median, na.rm = T)))
activity_data %>%
group_by(as.factor(as.character(date))) %>%
summarise(a(steps, list(mean = mean, median = median, na.rm = T)))
activity_data %>%
group_by(date) %>%
summarise(steps, list(mean = mean, na.rm = T))
activity_data %>%
group_by(date) %>%
summarise(steps, mean = mean, na.rm = T)
activity_data %>%
group_by(date) %>%
summarise(steps, mean, na.rm = T)
activity_data %>%
group_by(date) %>%
summarize(steps, median())
mtcars %>%
group_by(cyl) %>%
summarise(mean = mean(disp), n = n())
mtcars %>%
group_by(cyl) %>%
summarise(mean = mean(disp), median = median(disp))
activity_data %>%
group_by(date) %>%
summarize(mean = mean(steps, na.rm = T), median(steps))
activity_data %>%
group_by(date) %>%
summarize(mean = mean(steps, na.rm = T), median = median(steps))
activity_data %>%
group_by(date) %>%
summarize(mean = mean(steps, na.rm = T), median = median(steps, na.rm = T))
activity_data %>%
group_by(date) %>%
summarize(mean = mean(steps, na.rm = T), median = median(steps, na.rm = T)) -> mean_med
sum(mean_med$median)
sum(mean_med$median, na.rm = T)
activity_data %>%
group_by(date) %>%
summarize(sum = sum(steps, na.rm = T), mean = mean(steps, na.rm = T), median = median(steps, na.rm = T)) -> mean_med
View(mean_med)
aggregate(value ~ steps, data = activity_data, summary)
aggregate(steps ~ date, data = activity_data, summary)
aggr3 <- aggregate(steps ~ date, data = activity_data, summary)
str(aggr3)
View(aggr3)
activity_data %>%
group_by(date) %>%
summarize(sum = sum(steps, na.rm = T), mean = mean(steps, na.rm = T), median = median(steps, na.rm = T), mean_tr = mean(steps, na.rm = T, trim = 1)) -> mean_med
View(a)
median(a$steps)
mean(a$steps)
plot(a$steps)
hist(a$steps)
hist(step_sums$steps)
qplot(step_sums$steps, geom = "histogram")
qplot(step_sums$steps, geom = "histogram", binwidth = 10)
hist(step_sums$steps)
qplot(step_sums$steps, geom = "histogram", binwidth = 5000)
png("gp")
qplot(step_sums$steps, geom = "histogram", binwidth = 5000)
dev.off
dev.off()
png("bp")
hist(step_sums$steps)
dev.off()
p_avg_activ <- ggplot(activity_data$steps, aes(x=interval, y=date)) +
geom_line() +
xlab("")
p_avg_activ <- ggplot(activity_data, aes(x=interval, y=date)) +
geom_line() +
xlab("")
p
p_avg_activ <- ggplot(activity_data, aes(x=interval, y=date)) +
geom_line() +
xlab("")
p_avg_activ
p_avg_activ <- ggplot(activity_data, aes(x=interval ~ mean(steps, na.rm = T), y=date)) +
geom_line() +
xlab("")
p_avg_activ
p_avg_activ <- ggplot(activity_data, aes(x=interval ~ mean(steps, na.rm = T), y=date))
p_avg_activ <- qlot(x=interval ~ mean(steps, na.rm = T), y=date) +
geom_line()
p_avg_activ <- qplot(x=interval ~ mean(steps, na.rm = T), y=date) +
geom_line()
p_avg_activ
p_avg_activ <- qplot(x = interval, y =  mean(steps, na.rm = T)) +
geom_line()
p_avg_activ
p_avg_activ <- qplot(x = interval, y =  mean(steps, na.rm = T), data = activity_data) +
geom_line()
p_avg_activ
p_avg_activ <- qplot(x = interval,
y = function() {
aggregate(steps ~ date, activity_data, mean, na.rm = T)
},
data = activity_data) +
geom_line()
p_avg_activ
aggregate(steps ~ date, activity_data, mean, na.rm = T)
p_avg_activ <- qplot(x = interval,
y = function() {
ag <- aggregate(steps ~ date, activity_data, mean, na.rm = T)
ag$steps
},
data = activity_data) +
geom_line()
p_avg_activ
ag <- aggregate(steps ~ date, activity_data, mean, na.rm = T)
transform(activity_data, avg_steps = ag)
ag
savehistory("~/work/data_science_coursera/coursera_course/h22.Rhistory")

authors <- data.frame(
surname = I(c("Tukey", "Venables", "Tierney", "Ripley", "McNeil")),
nationality = c("US", "Australia", "US", "UK", "Australia"),
deceased = c("yes", rep("no", 4)))
books <- data.frame(
name = I(c("Tukey", "Venables", "Tierney",
"Ripley", "Ripley", "McNeil", "R Core")),
title = c("Exploratory Data Analysis",
"Modern Applied Statistics ...",
"LISP-STAT",
"Spatial Statistics", "Stochastic Simulation",
"Interactive Data Analysis",
"An Introduction to R"),
other.author = c(NA, "Ripley", NA, NA, NA, NA,
"Venables & Smith"))
(m1 <- merge(authors, books, by.x = "surname", by.y = "name"))
mm <- merge(activity_data, ag, by = date)
ag <- aggregate(steps ~ date, activity_data, mean, na.rm = T)
str(ag)
str(activity_data)
names(ag)
names(ag) = c("date", "avg_steps")
mm <- merge(activity_data, ag, by = "date")
View(mm)
mm$steps %>% sum
qplot(x = interval, y = unique(avg_steps), data = mm)
qplot(x = interval, y = avg_steps, data = mm)
plot(mm$interval, mm$avg_steps, type = l)
plot(mm$interval, mm$avg_steps, type = "l")
ag <- aggregate(steps ~ date, activity_data, mean, na.rm = T)
names(ag) = c("date", "avg_steps")
avg_steps_per_day <- merge(activity_data, ag, by = "date")
plot(avg_steps_per_day$interval, avg_steps_per_day$avg_steps, type = "l")
p_avg_activ <- qplot(x = interval,
y = avg_steps,
data = avg_steps_per_day, type = "l") +
geom_line()
p_avg_activ
ag <- aggregate(steps ~ date, activity_data, mean, na.rm = T)
names(ag) = c("date", "avg_steps")
avg_steps_per_day <- merge(activity_data, ag, by = "date")
plot(avg_steps_per_day$interval, avg_steps_per_day$avg_steps, type = "l")
qqplot(data = avg_steps_per_day, aes(x = interval,
y = avg_steps)) +
geom_line()+
geom_point()
View(avg_steps_per_day)
qqplot(data = avg_steps_per_day, aes(x = interval,
y = avg_steps), group = 1) +
geom_line()+
geom_point()
qqplot(data = avg_steps_per_day, aes(x = interval,
y = avg_steps), group = date) +
geom_line()+
geom_point()
qqplot(data = avg_steps_per_day, aes(x = interval,
y = avg_steps, group = date)) +
geom_line()+
geom_point()
names(avg_steps_per_day)
names(avg_steps_per_day) = c("dates", "steps", "intervals", "avg_steps")
ggplot(data = avg_steps_per_day, aes(x = interval,
y = avg_steps, group = date)) +
geom_line()+
geom_point()
ggplot(data = avg_steps_per_day, aes(x = intervals,
y = avg_steps, group = dates)) +
geom_line()+
geom_point()
ag <- aggregate(steps ~ date, activity_data, mean, na.rm = T)
names(ag) = c("date", "avg_steps")
avg_steps_per_day <- merge(activity_data, ag, by = "date")
plot(avg_steps_per_day$interval, avg_steps_per_day$avg_steps, type = "l")
ag <- aggregate(steps ~ date, activity_data, mean, na.rm = T)
names(ag) = c("date", "avg_steps")
avg_steps_per_day <- merge(activity_data, ag, by = "date")
p_avg_activ <- qplot(x = interval,
y = avg_steps,
data = avg_steps_per_day, type = "l") +
geom_line()
p_avg_activ
ag <- aggregate(steps ~ date, activity_data, mean, na.rm = T)
names(ag) = c("date", "avg_steps")
avg_steps_per_day <- merge(activity_data, ag, by = "date")
names(avg_steps_per_day) = c("dates", "steps", "intervals", "avg_steps")
p_avg_activ = ggplot(data = avg_steps_per_day,
aes(x = intervals,
y = avg_steps,
group = dates)) +
geom_line() +
geom_point()
p_avg_activ
names(avg_steps_per_day) = c("dates", "steps", "intervals", "avg_steps")
step_interv <- aggregate(steps ~ interval + date , activity_data, mean, na.rm = T)
str(step_interv)
head(step_interv)
plot(step_interv$interval, step_interv$steps, type = "l")
View(step_interv)
step_interv <- aggregate(steps ~ interval + date, activity_data, mean, na.rm = T)
plot(step_interv$interval, step_interv$steps, type = "l")
p_avg_activ = ggplot(data = step_interv,
aes(x = interval,
y = steps, group = date)) +
geom_line() +
geom_point()
p_avg_activ
step_interv <- aggregate(steps ~ interval + date , activity_data, mean, na.rm = T)
table(step_interv$interval, step_interv$steps)
wich.max(step_interv$steps)
which.max(step_interv$steps)
step_interv[step_interv$steps == 14476]
max(step_interv$steps)
step_interv[step_interv$steps == 806]
step_interv[step_interv$steps == 806, ]
step_interv[step_interv$steps == max(step_interv$steps), ]
step_interv[step_interv$steps == max(step_interv$steps), step_interv$interval]
step_interv[step_interv$steps == max(step_interv$steps), ]
step_interv[step_interv$steps == max(step_interv$steps), ] %>% interval
step_interv[step_interv$steps == max(step_interv$steps), ] %>% steps
aggregate(steps ~ interval, step_interv)
View(step_interv)
browseVignettes(package = "dplyr")
step_interv %>% group_by(interval
)
length(unique(step_interv$interval))
length(unique(activity_data$interval))
step_interv %>% group_by(interval) %>% tally()
step_interv %>% group_by(interval) %>% tally(sort = T)
step_interv %>% group_by(interval) %>% summarize()
mtcars %>%
summarise(mean = mean(disp), n = n())
mtcars %>%
group_by(cyl) %>%
summarise(mean = mean(disp), n = n())
step_interv %>% group_by(interval) %>% summarize(steps)
activity_data %>% group_by(interval) %>% summarize(steps, mean, na.rm = T) %>% head
activity_data %>% group_by(interval) %>% summarize(steps, mean, na.rm = T)
activity_data %>% group_by(`interval`) %>% summarize(steps, mean, na.rm = T)
activity_data %>% group_by(`interval`)
st_int_only <- select(step_interv, interval, steps)
st_int_only %>% group_by(interval)
st_int_only %>% group_by(interval) %>% summary()
sapply(activity_data, function(x) sum(is.na(x)))
mtcars %>%
select(everything()) %>%  # replace to your needs
summarise_all(funs(sum(is.na(.))))
mtcars %>%
select(everything()) %>%  # replace to your needs
summarise_all(sum(is.na(.)))
mtcars %>%
select(everything()) %>%  # replace to your needs
summarise_all(~ sum(is.na(.)))
activity_data %>% select(everything()) %>% summarise_all(~ sum(is.na(.)))
savehistory("~/work/data_science_coursera/coursera_course/h23.Rhistory")

summary(activity_data$steps)
summary(imputed_dataset$step_imp)
# summary(mean_med_imp)
imputed_dataset$weekday <- weekdays(imputed_dataset$date, abbreviate = T)
weekends <- list("Sat", "Sun")
is_weekend = function(x) {
x %in% weekends
}
imputed_dataset$is_weekend <- sapply(imputed_dataset$weekday, is_weekend)
imputed_dataset %>% head(3)
imputed_dataset$weekday <- weekdays(imputed_dataset$date, abbreviate = T)
weekends <- list("Sat", "Sun")
is_weekend = function(x) {
if_else(x %in% weekends, "weekend", "weekday")
}
imputed_dataset$is_weekend <- as.factor(sapply(imputed_dataset$weekday, is_weekend))
imputed_dataset %>% head(3)
step_interv <- aggregate(step_imp ~ interval + is_weekend, imputed_dataset, mean, na.rm = T)
plot(step_interv$interval, step_interv$step_imp, type = "l")
p_avg_activ_imp = ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp, group = is_weekend)) +
geom_line()
step_interv_week <- aggregate(step_imp ~ interval + is_weekend, imputed_dataset, mean, na.rm = T)
plot(step_interv_week$interval, step_interv_week$step_imp, type = "l")
p_avg_activ_imp = ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp, group = is_weekend)) +
geom_line()
p_avg_activ_imp
View(step_interv)
View(step_interv_week)
View(step_interv)
View(step_interv_week)
View(step_interv)
View(step_interv_week)
step_interv_weekdays <- filter(step_interv_week, is_weekend = "weekday")
step_interv_weekdays <- filter(step_interv_week, is_weekend == "weekday")
View(step_interv_weekdays)
step_interv_week <- aggregate(step_imp ~ interval + is_weekend, imputed_dataset, mean, na.rm = T)
step_interv_weekdays <- filter(step_interv_week, is_weekend == "weekday")
step_interv_weekends <- filter(step_interv_week, is_weekend == "weekend")
par(c(2,1))
with(step_interv_weekdays, plot(interval, step_imp, type = "l"))
par(mfrow = c(2,1))
with(step_interv_weekdays, plot(interval, step_imp, type = "l"))
par(mfrow = c(2,1))
with(step_interv_weekdays, plot(interval, step_imp, type = "l"))
with(step_interv_weekends, plot(interval, step_imp, type = "l"))
p_avg_activ_imp = ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line() +
facet_wrap(is_weekend, nrow = 2, ncol = 1)
p_avg_activ_imp
knitr::opts_chunk$set(cache = TRUE)
library(readr)
library(magrittr)
library(ggplot2)
library(dplyr)
setwd("/Users/ashipunova/work/data_science_coursera/intro_r/RepData_PeerAssessment1/")
# unzip("sales.zip", list = TRUE)
activity_data <- readr::read_csv(unzip("activity.zip", "activity.csv"))
str(activity_data)
# transform(activity_data, date = ymd(date))
step_sums <- aggregate(steps ~ date, activity_data, sum, na.rm = T)
step_sums %>% head()
sum_plot <- qplot(step_sums$steps, geom = "histogram", binwidth = 25000/5)
print(sum_plot)
activity_data %>%
group_by(date) %>%
summarise(
sum = sum(steps, na.rm = T),
mean = mean(steps, na.rm = T),
median = median(steps, na.rm = T)) -> mean_med
mean_med
# qplot(date, mean, data = mean_med)
#step_means_medians <-
# qplot(date, steps, data = step_means, geom = "smooth")
step_interv <- aggregate(steps ~ interval + date, activity_data, mean, na.rm = T)
plot(step_interv$interval, step_interv$steps, type = "l")
p_avg_activ = ggplot(data = step_interv,
aes(x = interval,
y = steps, group = date)) +
geom_line()
p_avg_activ
step_interv[step_interv$steps == max(step_interv$steps), ]
sapply(activity_data, function(x) sum(is.na(x)))
# NAs by day:
table(activity_data$date, is.na(activity_data$steps)) %>% head(3)
activity_data$step_imp <- ave(activity_data$steps, activity_data$interval,
FUN = function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x))
# activity_data$step_imp %>% head
sapply(activity_data, function(x) sum(is.na(x)))
activity_data %>% select(-c("steps")) %>%
{.} -> imputed_dataset
#imputed_dataset %>% head
imputed_dataset %>% head(3)
step_sums_imp <- aggregate(step_imp ~ date, imputed_dataset, sum, na.rm = T)
step_sums_imp %>% head(3)
sum_imp_plot <- qplot(step_sums$steps, geom = "histogram", binwidth = 25000/5)
print(sum_plot)
imputed_dataset %>%
group_by(date) %>%
summarise(
sum = sum(step_imp, na.rm = T),
mean = mean(step_imp, na.rm = T),
median = median(step_imp, na.rm = T)) %>%
#%T>% head(3) %>%
{.} -> mean_med_imp
mean_med_imp
summary(activity_data$steps)
summary(imputed_dataset$step_imp)
# summary(mean_med_imp)
imputed_dataset$weekday <- weekdays(imputed_dataset$date, abbreviate = T)
weekends <- list("Sat", "Sun")
is_weekend = function(x) {
if_else(x %in% weekends, "weekend", "weekday")
}
imputed_dataset$is_weekend <- as.factor(sapply(imputed_dataset$weekday, is_weekend))
(diamonds, aes(carat, price)) + geom_boxplot() + facet_grid(. ~ cut)
step_interv_week <- aggregate(step_imp ~ interval + is_weekend, imputed_dataset, mean, na.rm = T)
# step_interv_weekdays <- filter(step_interv_week, is_weekend == "weekday")
# step_interv_weekends <- filter(step_interv_week, is_weekend == "weekend")
# par(mfrow = c(2,1))
# with(step_interv_weekdays, plot(interval, step_imp, type = "l"))
# with(step_interv_weekends, plot(interval, step_imp, type = "l"))
# p_avg_activ_imp = facet_wrap(
#   facets,
#   nrow = NULL,
#   ncol = NULL)
# qplot(as.factor(year), Emissions, data = vehicle_df_nei_LA, facets = . ~ as.factor(SCC)) + labs(x = "Years", title = "Emissions from coal combustion-related sources")
#g <- ggplot(diamonds,aes(depth,price))
#g + geom_point(alpha = 1/3) + facet_grid(cut ~ car2)
#(diamonds, aes(carat, price)) + geom_boxplot() + facet_grid(. ~ cut)
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line() +
facet_wrap(is_weekend, nrow = 2, ncol = 1)
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line() +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1)
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line() +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1) +
labs("Interval", "Number of steps")
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line() +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1) +
labs(x = "Interval", y = "Number of steps")
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line() +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1) +
labs(x = "Interval", y = "Number of steps") +
theme_bw()
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line() +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = "blue") +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = "blue") +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_line(colour = "black"),
strip.background = element_rect(fill="pink"))
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = "blue") +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_line(colour = "black"),
strip.background = element_rect(fill = c(254,	229,	205))
)
p_avg_activ_imp
strip.background = element_rect(fill = c(rgb(254,	229,	205))
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = "blue") +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_line(colour = "black"),
strip.background = element_rect(fill = rgb(254,	229, 205))
)
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = "blue") +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.line = element_line(colour = "black"),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255))
)
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = "blue") +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255))
)
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = "cyan") +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255))
)
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = rgb(90, 163, 252, maxColorValue = 255)) +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255))
)
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = rgb(90, 163, 252, maxColorValue = 255)) +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1, scales = "free") +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255)) +
axis.ticks =
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = rgb(90, 163, 252, maxColorValue = 255)) +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1, scales = "free") +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255))
)
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = rgb(90, 163, 252, maxColorValue = 255)) +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1, scales = "free") +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255)),
strip.placement = "outside"
)
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = rgb(90, 163, 252, maxColorValue = 255)) +
facet_wrap(step_interv_week$is_weekend, nrow = 2, ncol = 1, scales = "free") +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255))
)
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = rgb(90, 163, 252, maxColorValue = 255)) +
facet_wrap(~is_weekend, nrow = 2) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255))
)
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = rgb(90, 163, 252, maxColorValue = 255)) +
facet_wrap(~is_weekend, nrow = 2, scales = "free") +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255))
)
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = rgb(90, 163, 252, maxColorValue = 255)) +
facet_wrap(~is_weekend, nrow = 2) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255)),
axis.ticks.length=unit(-0.25, "cm"),
axis.text.x = element_text(margin = margin(t = .5, unit = "cm")),
axis.text.y = element_text(margin = margin(r = .5, unit = "cm"))
)
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = rgb(90, 163, 252, maxColorValue = 255)) +
facet_wrap(~is_weekend, nrow = 2) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255)),
axis.ticks.length=unit(0.25, "cm"),
axis.text.x = element_text(margin = margin(t = .5, unit = "cm")),
axis.text.y = element_text(margin = margin(r = .5, unit = "cm"))
)
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = rgb(90, 163, 252, maxColorValue = 255)) +
facet_wrap(~is_weekend, nrow = 2) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255))
) +
annotation_logticks(sides = "blr")
p_avg_activ_imp
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = rgb(90, 163, 252, maxColorValue = 255)) +
facet_wrap(~is_weekend, nrow = 2) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255))
) +
annotation_ticks(sides = "blr")
p_avg_activ_imp <- ggplot(data = step_interv_week,
aes(x = interval,
y = step_imp)) +
geom_line(color = rgb(90, 163, 252, maxColorValue = 255)) +
facet_wrap(~is_weekend, nrow = 2) +
labs(x = "Interval", y = "Number of steps") +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
strip.background = element_rect(fill = rgb(254,	229, 205, maxColorValue = 255))
)
p_avg_activ_imp
imputed_dataset$weekday <- weekdays(imputed_dataset$date, abbreviate = T)
weekends <- list("Sat", "Sun")
is_weekend = function(x) {
if_else(x %in% weekends, "weekend", "weekday")
}
imputed_dataset$is_weekend <- as.factor(sapply(imputed_dataset$weekday, is_weekend))
p_avg_activ = ggplot(data = activity_data,
aes(x = interval,
y = steps, group = date)) +
geom_line()
p_avg_activ
step_interv <- aggregate(steps ~ interval + date, activity_data, mean, na.rm = T)
plot(step_interv$interval, step_interv$steps, type = "l")
p_avg_activ = ggplot(data = activity_data,
aes(x = interval,
y = steps, group = date)) +
geom_line()
p_avg_activ
knitr::opts_chunk$set(cache = F, echo = TRUE)
library(readr)
library(magrittr)
library(ggplot2)
library(dplyr)
if(!file.exists("./data")){ dir.create("./data") }
setwd("./data")
activity_data <- readr::read_csv(unzip("activity.zip", "activity.csv"))
str(activity_data)
step_sums <- aggregate(steps ~ date, activity_data, sum, na.rm = T)
step_sums %>% head()
sum_plot <- qplot(step_sums$steps, geom = "histogram", binwidth = 25000/5)
print(sum_plot)
activity_data %>%
group_by(date) %>%
summarise(
sum = sum(steps, na.rm = T),
mean = mean(steps, na.rm = T),
median = median(steps, na.rm = T)) -> mean_med
mean_med
step_interv <- aggregate(steps ~ interval + date, activity_data, mean, na.rm = T)
plot(step_interv$interval, step_interv$steps, type = "l")
step_interv[step_interv$steps == max(step_interv$steps), ]
sapply(activity_data, function(x) sum(is.na(x)))
# NAs by day:
table(activity_data$date, is.na(activity_data$steps)) %>% head(3)
tt <- table(activity_data$date, is.na(activity_data$steps))
str(tt)
names(tt)
as.data.frame(tt)
as.data.frame(tt) %>% head()
table(activity_data$date, is.na(activity_data$steps)) %>% as.data.frame() %>% head(3)
table(activity_data$date, is.na(activity_data$steps)) %>% as.data.frame() %>% names()
table(activity_data$date, is.na(activity_data$steps)) %>% as.data.frame() %>% filter(Freq == 288 & Var2 == TRUE)
table(activity_data$date, is.na(activity_data$steps)) %>% as.data.frame() %>% filter(Freq == 288 & Var2 == TRUE) %>% select(Var1)
sapply(activity_data, function(x) sum(is.na(x)))
# NAs by day:
# Days with NAs:
table(activity_data$date, is.na(activity_data$steps)) %>% as.data.frame() -> days_w_nas
names(days_w_nas) <- c("day", "has_nas", "freq")
days_w_nas %>% filter(freq > 0 & has_nas == TRUE) %>% select(has_nas)
days_w_nas %>% filter(freq > 0 & has_nas == TRUE) %>% select(day)
sessionInfo()
knitr::opts_chunk$set(echo = TRUE)
file_url = "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
if(!file.exists("./storm_data")){ dir.create("./storm_data") }
setwd("./storm_data")
storm_data <- readr::read_csv(unzip(file_url, "storm_data.csv"))
knitr::opts_chunk$set(echo = TRUE)
library(readr)
file_url = "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
if(!file.exists("./storm_data")){ dir.create("./storm_data") }
setwd("./storm_data")
storm_data_csv <- readr::read_csv(unzip(file_url, "storm_data.csv"))
file_url = "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
if(!file.exists("./storm_data")){ dir.create("./storm_data") }
setwd("./storm_data")
storm_data_csv <- readr::read_csv(file_url, "storm_data.csv")
file_url = "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
if(!file.exists("./storm_data")){ dir.create("./storm_data") }
setwd("./storm_data")
temp <- tempfile()
View(temp)
temp$V1
tem
temp
read.csv(temp) %>% head
file_url = "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
file_destination = "storm_data.csv"
if(!file.exists("./storm_data")){ dir.create("./storm_data") }
setwd("./storm_data")
temp <- tempfile()
download.file(file_url, temp)
unzip(temp, exdir = file_destination)
unlink(temp)
ls
ls()
savehistory("~/work/data_science_coursera/coursera_course/h24.Rhistory")
# ggplot(corr.m, aes(x = reorder(miRNA, -value), y = value, fill = variable)) +
#   geom_bar(stat = "identity")
new_data_health %>%
ungroup() %>%
arrange(-as.integer(total_number)) %>%
ggplot(
# data = new_data_health,
aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
# coord_flip() +
# geom_bar(stat = "identity", position = position_dodge()) +
geom_area(position="stack") +
geom_text(aes(label = total_number),
hjust = 1.6,
position = position_dodge(0.9),
size = 3.5) +
labs(y = "Event type", x = "Total number", title = "Types of events most harmful with respect to population health") +
guides(fill = guide_legend(title = "Harm type"))
# ggplot(corr.m, aes(x = reorder(miRNA, -value), y = value, fill = variable)) +
#   geom_bar(stat = "identity")
new_data_health %>%
ungroup() %>%
arrange(-as.integer(total_number)) %>%
ggplot(
# data = new_data_health,
aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
# coord_flip() +
geom_bar(stat = "identity", position = position_dodge()) +
geom_text(aes(label = total_number),
hjust = 1.6,
position = position_dodge(0.9),
size = 3.5) +
labs(y = "Event type", x = "Total number", title = "Types of events most harmful with respect to population health") +
guides(fill = guide_legend(title = "Harm type"))
# ggplot(corr.m, aes(x = reorder(miRNA, -value), y = value, fill = variable)) +
#   geom_bar(stat = "identity")
new_data_health %>%
ggplot(
# data = new_data_health,
aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
# coord_flip() +
geom_bar(stat = "identity", position = position_dodge()) +
geom_text(aes(label = total_number),
hjust = 1.6,
position = position_dodge(0.9),
size = 3.5) +
labs(y = "Event type", x = "Total number", title = "Types of events most harmful with respect to population health") +
guides(fill = guide_legend(title = "Harm type"))
# ggplot(corr.m, aes(x = reorder(miRNA, -value), y = value, fill = variable)) +
#   geom_bar(stat = "identity")
new_data_health %>%
ggplot(
# data = new_data_health,
aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
coord_flip() +
geom_bar(stat = "identity", position = position_dodge()) +
geom_text(aes(label = total_number),
hjust = 1.6,
position = position_dodge(0.9),
size = 3.5) +
labs(y = "Event type", x = "Total number", title = "Types of events most harmful with respect to population health") +
guides(fill = guide_legend(title = "Harm type"))
new_data_econ$total_number <- factor(new_data_econ$total_number, levels = new_data_econ$total_number)
new_data_econ$total_number <- factor(new_data_econ$total_number, levels = unique(new_data_econ$total_number))
ggplot(data = new_data_econ,
aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
geom_bar(stat = "identity", position = position_dodge()) +
geom_text(aes(label = total_number), vjust = 1.6, color = "white",
position = position_dodge(0.9), size = 3.5) +
labs(x = "Event type", y = "Total number", title = "Types of events most harmful with respect to economics") +
guides(fill = guide_legend(title = "Harm type"))
new_data_econ$total_number <- factor(new_data_econ$total_number, levels = unique(new_data_econ$total_number))
ggplot(data = new_data_econ,
aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
coord_flip() +
geom_bar(stat = "identity", position = position_dodge()) +
geom_text(aes(label = total_number), vjust = 1.6, color = "white",
position = position_dodge(0.9), size = 3.5) +
labs(x = "Event type", y = "Total number", title = "Types of events most harmful with respect to economics") +
guides(fill = guide_legend(title = "Harm type"))
new_data_econ$total_number <- factor(new_data_econ$total_number, levels = unique(new_data_econ$total_number))
ggplot(data = new_data_econ,
aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
coord_flip() +
geom_bar(stat = "identity", position = position_dodge()) +
geom_text(aes(label = total_number), hjust = 1.6,
position = position_dodge(0.9), size = 3.5) +
labs(x = "Event type", y = "Total number", title = "Types of events most harmful with respect to economics") +
guides(fill = guide_legend(title = "Harm type"))
new_data_econ$total_number <- factor(new_data_econ$total_number, levels = unique(new_data_econ$total_number))
ggplot(data = new_data_econ,
aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
# coord_flip() +
geom_bar(stat = "identity", position = position_dodge()) +
geom_text(aes(label = total_number), hjust = 1.6,
position = position_dodge(0.9), size = 3.5) +
labs(x = "Event type", y = "Total number", title = "Types of events most harmful with respect to economics") +
guides(fill = guide_legend(title = "Harm type"))
new_data_econ$total_number <- factor(new_data_econ$total_number, levels = unique(new_data_econ$total_number))
ggplot(data = new_data_econ,
aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
# coord_flip() +
geom_bar(stat = "identity", position = position_dodge()) +
# geom_text(aes(label = total_number), hjust = 1.6,
#           position = position_dodge(0.9), size = 3.5) +
labs(x = "Event type", y = "Total number", title = "Types of events most harmful with respect to economics") +
guides(fill = guide_legend(title = "Harm type"))
new_data_econ$total_number <- factor(new_data_econ$total_number, levels = unique(new_data_econ$total_number))
new_data_econ %>%
ggplot(aes(x = reorder(EVTYPE, -total_number), y = total_number, fill = dmg_type)) +
geom_bar(stat = "identity")
ggplot(data = new_data_econ,
aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
# coord_flip() +
geom_bar(stat = "identity", position = position_dodge()) +
# geom_text(aes(label = total_number), hjust = 1.6,
#           position = position_dodge(0.9), size = 3.5) +
labs(x = "Event type", y = "Total number", title = "Types of events most harmful with respect to economics") +
guides(fill = guide_legend(title = "Harm type"))
new_data_econ %>%
ggplot(aes(x = reorder(EVTYPE, -total_number), y = total_number, fill = dmg_type)) +
geom_bar(stat = "identity")
new_data_health %>%
ggplot(aes(x = reorder(EVTYPE, -total_number), y = total_number, fill = dmg_type)) +
geom_bar(stat = "identity")
new_data_health %>%
ggplot(aes(x = reorder(EVTYPE, total_number), y = total_number, fill = dmg_type)) +
geom_bar(stat = "identity")
new_data_health %>%
ggplot(aes(x = reorder(EVTYPE, total_number),
y = total_number,
fill = dmg_type)) +
geom_bar(stat = "identity")
new_data_health %>%
ggplot(aes(x = reorder(total_number, EVTYPE),
y = total_number,
fill = dmg_type)) +
geom_bar(stat = "identity")
# ggplot(corr.m, aes(x = reorder(miRNA, -value), y = value, fill = variable)) +
#   geom_bar(stat = "identity")
new_data_health %>%
ggplot(aes(x = reorder(total_number, EVTYPE),
y = total_number,
fill = dmg_type)) +
geom_bar(stat = "identity") +
labs(y = "Event type",
x = "Total number",
title = "Types of events most harmful with respect to population health") +
# new_data_health %>%
# ggplot(
#   # data = new_data_health,
#        aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
#   coord_flip() +
#   geom_bar(stat = "identity", position = position_dodge()) +
#   geom_text(aes(label = total_number),
#             hjust = 1.6,
#             position = position_dodge(0.9),
#             size = 3.5) +
#   labs(y = "Event type", x = "Total number", title = "Types of events most harmful with respect to population health") +
#   guides(fill = guide_legend(title = "Harm type"))
# ggplot(corr.m, aes(x = reorder(miRNA, -value), y = value, fill = variable)) +
#   geom_bar(stat = "identity")
new_data_health %>%
ggplot(aes(x = reorder(total_number, EVTYPE),
y = total_number,
fill = dmg_type)) +
geom_bar(stat = "identity") +
labs(y = "Event type",
x = "Total number",
title = "Types of events most harmful with respect to population health")
# new_data_health %>%
# ggplot(
#   # data = new_data_health,
#        aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
#   coord_flip() +
#   geom_bar(stat = "identity", position = position_dodge()) +
#   geom_text(aes(label = total_number),
#             hjust = 1.6,
#             position = position_dodge(0.9),
#             size = 3.5) +
#   labs(y = "Event type", x = "Total number", title = "Types of events most harmful with respect to population health") +
#   guides(fill = guide_legend(title = "Harm type"))
new_data_health %>%
ggplot(aes(x = reorder(total_number, EVTYPE),
y = total_number,
fill = dmg_type)) +
geom_bar(stat = "identity") +
labs(y = "Event type",
x = "Total number",
title = "Types of events most harmful with respect to population health")
writeLines("
caption {
color: black;
text-align: center;
font-weight: bold;
font-size: x-large;
}
",
con = "mystyle.css")
if(!file.exists("./storm_data")){ dir.create("./storm_data") }
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
knitr::opts_knit$set(root.dir = "./storm_data")
library(readr)
library(dplyr)
library(ggplot2)
library(kableExtra)
file_url = "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
file_destination = "StormData.csv.bz2"
download.file(file_url, destfile = file_destination)
storm_data_csv <- read.csv(file_destination)
get_max10 = function(input_data, clmn_name) {
input_data %>%
slice_max(order_by = !!as.symbol(clmn_name), n = 10)
}
prepare_for_join = function(input_data, clmn_name) {
input_data %>%
select(EVTYPE, total_number = !!as.symbol(clmn_name)) %>%
transform(dmg_type = clmn_name) %>%
group_by(EVTYPE)
}
unique_max = function(input_data) {
input_data %>%
aggregate(total_number ~ EVTYPE, ., max) %>%
left_join(input_data)
}
kable_tab = function(input_data, caption = "") {
input_data %>%
kable(caption = caption) %>%
kable_classic(full_width = F) %>%
kable_material("striped") %>%
kable_styling(fixed_thead = T) %>%
scroll_box(height = "20em")
}
by_state = function(input_data, clmn_name) {
input_data %>%
group_by(STATE) %>%
filter(!!as.symbol(clmn_name) == max(!!as.symbol(clmn_name))) %>%
select(STATE, EVTYPE) %>%
unique()
}
one_max_fat = storm_data_csv[storm_data_csv$FATALITIES == max(storm_data_csv$FATALITIES),]
one_max_inj = storm_data_csv[storm_data_csv$INJURIES == max(storm_data_csv$INJURIES),]
fat_10_max <- get_max10(storm_data_csv, "FATALITIES")
inj_10_max <- get_max10(storm_data_csv, "INJURIES")
new_data_inj0 <- prepare_for_join(inj_10_max, "INJURIES")
new_data_fat0 <- prepare_for_join(fat_10_max, "FATALITIES")
new_data_fat <- unique_max(new_data_fat0)
new_data_inj <- unique_max(new_data_inj0)
new_data_health <- rbind(new_data_fat, new_data_inj)
fatal_by_state <- by_state(storm_data_csv, "FATALITIES")
inj_by_state <- by_state(storm_data_csv, "INJURIES")
max_PROPDMG <- filter(storm_data_csv, PROPDMG == max(PROPDMG))
max_CROPDMG <- filter(storm_data_csv, CROPDMG == max(CROPDMG))
property_10_max <- get_max10(storm_data_csv, "PROPDMG")
crop_10_max <- get_max10(storm_data_csv, "CROPDMG")
new_data_crop0 <- prepare_for_join(crop_10_max, "CROPDMG")
new_data_property0 <- prepare_for_join(property_10_max, "PROPDMG")
new_data_property <- unique_max(new_data_property0)
new_data_crop <- unique_max(new_data_crop0)
new_data_econ <- rbind(new_data_property, new_data_crop)
PROPDMG_by_state <- by_state(storm_data_csv, "PROPDMG")
CROPDMG_by_state <- by_state(storm_data_csv, "CROPDMG")
# ggplot(corr.m, aes(x = reorder(miRNA, -value), y = value, fill = variable)) +
#   geom_bar(stat = "identity")
new_data_health %>%
ggplot(aes(x = reorder(total_number, EVTYPE),
y = total_number,
fill = dmg_type)) +
geom_bar(stat = "identity") +
geom_text(aes(label = total_number),
vjust = 1.6,
position = position_dodge(0.9),
size = 3.5) +
labs(x = "Event type",
y = "Total number",
title = "Types of events most harmful with respect to population health")
# new_data_health %>%
# ggplot(
#   # data = new_data_health,
#        aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
#   coord_flip() +
#   geom_bar(stat = "identity", position = position_dodge()) +
#   geom_text(aes(label = total_number),
#             hjust = 1.6,
#             position = position_dodge(0.9),
#             size = 3.5) +
#   labs(y = "Event type", x = "Total number", title = "Types of events most harmful with respect to population health") +
#   guides(fill = guide_legend(title = "Harm type"))
# ggplot(corr.m, aes(x = reorder(miRNA, -value), y = value, fill = variable)) +
#   geom_bar(stat = "identity")
new_data_health %>%
ggplot(aes(x = reorder(total_number, EVTYPE),
y = total_number,
fill = dmg_type)) +
geom_bar(stat = "identity") +
geom_text(aes(label = total_number),
vjust = 1.6,
position = position_dodge(0.9),
size = 3.5) +
labs(x = "Event type",
y = "Total number",
title = "Types of events most harmful with respect to population health") +
scale_x_discrete(labels=EVTYPE)
# ggplot(corr.m, aes(x = reorder(miRNA, -value), y = value, fill = variable)) +
#   geom_bar(stat = "identity")
new_data_health %>%
ggplot(aes(x = reorder(total_number, EVTYPE),
y = total_number,
fill = dmg_type)) +
geom_bar(stat = "identity") +
geom_text(aes(label = total_number),
vjust = 1.6,
position = position_dodge(0.9),
size = 3.5) +
labs(x = "Event type",
y = "Total number",
title = "Types of events most harmful with respect to population health") +
scale_x_discrete(labels = new_data_health$EVTYPE)
# new_data_health %>%
# ggplot(
#   # data = new_data_health,
#        aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
#   coord_flip() +
#   geom_bar(stat = "identity", position = position_dodge()) +
#   geom_text(aes(label = total_number),
#             hjust = 1.6,
#             position = position_dodge(0.9),
#             size = 3.5) +
#   labs(y = "Event type", x = "Total number", title = "Types of events most harmful with respect to population health") +
#   guides(fill = guide_legend(title = "Harm type"))
# ggplot(corr.m, aes(x = reorder(miRNA, -value), y = value, fill = variable)) +
#   geom_bar(stat = "identity")
new_data_health %>%
ggplot(aes(x = reorder(total_number, EVTYPE),
y = total_number,
fill = dmg_type)) +
geom_bar(stat = "identity") +
coord_flip() +
geom_text(aes(label = total_number),
vjust = 1.6,
position = position_dodge(0.9),
size = 3.5) +
labs(x = "Event type",
y = "Total number",
title = "Types of events most harmful with respect to population health") +
scale_x_discrete(labels = new_data_health$EVTYPE)
# new_data_health %>%
# ggplot(
#   # data = new_data_health,
#        aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
#   coord_flip() +
#   geom_bar(stat = "identity", position = position_dodge()) +
#   geom_text(aes(label = total_number),
#             hjust = 1.6,
#             position = position_dodge(0.9),
#             size = 3.5) +
#   labs(y = "Event type", x = "Total number", title = "Types of events most harmful with respect to population health") +
#   guides(fill = guide_legend(title = "Harm type"))
# ggplot(corr.m, aes(x = reorder(miRNA, -value), y = value, fill = variable)) +
#   geom_bar(stat = "identity")
new_data_health %>%
ggplot(aes(x = reorder(total_number, EVTYPE),
y = total_number,
fill = dmg_type)) +
geom_bar(stat = "identity") +
coord_flip() +
geom_text(aes(label = total_number),
hjust = 1.6,
position = position_dodge(0.9),
size = 3.5) +
labs(x = "Event type",
y = "Total number",
title = "Types of events most harmful with respect to population health") +
scale_x_discrete(labels = new_data_health$EVTYPE)
# new_data_health %>%
# ggplot(
#   # data = new_data_health,
#        aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
#   coord_flip() +
#   geom_bar(stat = "identity", position = position_dodge()) +
#   geom_text(aes(label = total_number),
#             hjust = 1.6,
#             position = position_dodge(0.9),
#             size = 3.5) +
#   labs(y = "Event type", x = "Total number", title = "Types of events most harmful with respect to population health") +
#   guides(fill = guide_legend(title = "Harm type"))
# ggplot(corr.m, aes(x = reorder(miRNA, -value), y = value, fill = variable)) +
#   geom_bar(stat = "identity")
new_data_health %>%
ggplot(aes(x = reorder(total_number, EVTYPE),
y = total_number,
fill = dmg_type)) +
geom_bar(stat = "identity") +
coord_flip() +
geom_text(aes(label = total_number),
hjust = 1.3,
position = position_dodge(0.9),
size = 3.5) +
labs(x = "Event type",
y = "Total number",
title = "Types of events most harmful with respect to population health") +
scale_x_discrete(labels = new_data_health$EVTYPE)
# new_data_health %>%
# ggplot(
#   # data = new_data_health,
#        aes(x = total_number, y = EVTYPE, fill = dmg_type)) +
#   coord_flip() +
#   geom_bar(stat = "identity", position = position_dodge()) +
#   geom_text(aes(label = total_number),
#             hjust = 1.3,
#             position = position_dodge(0.9),
#             size = 3.5) +
#   labs(y = "Event type", x = "Total number", title = "Types of events most harmful with respect to population health") +
#   guides(fill = guide_legend(title = "Harm type"))
new_data_econ %>%
ggplot(aes(x = reorder(total_number, EVTYPE),
y = total_number,
fill = dmg_type)) +
geom_bar(stat = "identity") +
coord_flip() +
geom_text(aes(label = total_number),
hjust = 1.3,
position = position_dodge(0.9),
size = 3.5) +
labs(x = "Event type",
y = "Total number",
title = "Types of events most harmful with respect to economics") +
scale_x_discrete(labels = new_data_econ$EVTYPE)
new_data_econ %>%
ggplot(aes(x = reorder(total_number, EVTYPE),
y = total_number,
fill = dmg_type))
new_data_econ %>%
ggplot(aes(x = reorder(total_number, EVTYPE),
y = total_number,
fill = dmg_type)) +
geom_bar(stat = "identity")
View(new_data_econ)
property_10_max <- get_max10(storm_data_csv, "PROPDMG")
crop_10_max <- get_max10(storm_data_csv, "CROPDMG")
property_10_max %>% head(2)
new_data_property0 <- prepare_for_join(property_10_max, "PROPDMG")
new_data_crop0 <- prepare_for_join(crop_10_max, "CROPDMG")
new_data_property0 %>% head(2)
new_data_property0 <- prepare_for_join(property_10_max, "PROPDMG")
new_data_crop0 <- prepare_for_join(crop_10_max, "CROPDMG")
View(new_data_property0)
View(new_data_crop0)
new_data_property <- unique_max(new_data_property0)
new_data_crop <- unique_max(new_data_crop0)
View(new_data_property)
View(new_data_crop)
new_data_property %>%
aggregate(total_number ~ EVTYPE, ., max) %>%
left_join(new_data_property) %>% unique()
new_data_property %>% unique()
with(unique(new_data_property), plot(EVTYPE, total_number))
with(unique(new_data_property), plot(as.factor(EVTYPE), total_number))
with(unique(new_data_property), plot(as.factor(EVTYPE), total_number, type = "l"))
with(unique(new_data_property), plot(total_number, as.factor(EVTYPE), type = "l"))
with(unique(new_data_property), plot(total_number, as.factor(EVTYPE)))
new_data_property %>% unique() %>% arrange(EVTYPE)
new_data_property %>% unique() %>% arrange(total_number)
new_data_property %>% unique() %>% arrange(total_number) %>% a
new_data_property %>% unique() %>% arrange(total_number) -> a
with(a, plot(total_number, as.factor(EVTYPE)))
View(new_data_econ)
new_data_econ %>% unique() %>% str()
new_data_econ %>% unique() %>% head
rbind(new_data_property, new_data_crop) %>%
unique() %>%
{.} -> new_data_econ
View(new_data_econ)
str(new_data_econ)
new_data_fat0 %>%
aggregate(total_number ~ EVTYPE, ., max) %>%
aggregate(total_number ~ EVTYPE, ., paste, collapse = ", ")
new_data_fat0 %>%
aggregate(total_number ~ EVTYPE, ., max) %>%
aggregate(total_number ~ EVTYPE, ., paste, collapse = ", ") %>%
left_join(new_data_fat0) %>%
unique()
new_data_fat0 %>%
aggregate(total_number ~ EVTYPE, ., max) %>%
aggregate(total_number ~ EVTYPE, ., paste, collapse = ", ") %>% str
new_data_fat0 %>%
aggregate(total_number ~ EVTYPE, ., max) %>%
aggregate(total_number ~ EVTYPE, ., paste, collapse = ", ") %T>% str %>%
mutate(total_number = numeric(total_number))  %T>% str
new_data_fat0 %>%
aggregate(total_number ~ EVTYPE, ., max)
new_data_fat0 %>%
aggregate(total_number ~ EVTYPE, ., max) %>%
aggregate(total_number ~ EVTYPE, ., paste, collapse = ", ")
new_data_fat0 %>%
aggregate(total_number ~ EVTYPE, ., max) %>%
aggregate(total_number ~ EVTYPE, ., paste, collapse = ", ") %T>% str %>%
mutate(total_number = numeric(total_number))
new_data_fat0 %>%
aggregate(total_number ~ EVTYPE, ., max) %>%
aggregate(total_number ~ EVTYPE, ., paste, collapse = ", ") %T>% str %>%
transform(total_number = numeric(total_number))  %T>% str
new_data_fat0 %>%
aggregate(total_number ~ EVTYPE, ., max) %>%
aggregate(total_number ~ EVTYPE, ., paste, collapse = ", ") %T>% str %>%
transform(total_number = as.numeric(total_number))  %T>% str
new_data_fat0 %>%
aggregate(total_number ~ EVTYPE, ., max) %>%
aggregate(total_number ~ EVTYPE, ., paste, collapse = ", ") %T>% str %>%
transform(total_number = as.numeric(total_number))  %T>% str %>%
left_join(new_data_fat0) %>%
unique()
savehistory("~/work/data_science_coursera/coursera_course/h25.Rhistory")
===
CROPDMGEXP
The columns PROPDMGEXP and CROPDMGEXP contain an exponential multipliers for the property and crop damages. The unique exponential multipliers are:

unique(subset$PROPDMGEXP)
## [1] "K" ""  "M" "B"
unique(subset$CROPDMGEXP)
## [1] "K" ""  "M" "B"

## Calculate property and crop loss by multiplying DMG column by exponent. Sum PROP and CROP LOSS to get TOTAL LOSS
subset <- subset[PROPDMGEXP == "", PROPLOSS := PROPDMG]
subset <- subset[PROPDMGEXP == "K", PROPLOSS := PROPDMG*10^3]
subset <- subset[PROPDMGEXP == "M", PROPLOSS := PROPDMG*10^6]
subset <- subset[PROPDMGEXP == "B", PROPLOSS := PROPDMG*10^9]

subset <- subset[CROPDMGEXP == "", CROPLOSS := CROPDMG]
subset <- subset[CROPDMGEXP == "K", CROPLOSS := CROPDMG*10^3]
subset <- subset[CROPDMGEXP == "M", CROPLOSS := CROPDMG*10^6]
subset <- subset[CROPDMGEXP == "B", CROPLOSS := CROPDMG*10^9]

subset <- subset[,TOTALLOSS := PROPLOSS+CROPLOSS]
subset <- subset[,HUMANLOSS := FATALITIES+INJURIES]

===
HUMANLOSS
===
multiplyexp <- function(x, n) {
  #print(n)
  if(is.numeric(n)){
  } else if (n == "K"){
    n = 3
  } else if (n == "M"){
    n = 6
  } else if (n == "B"){
    n = 9
  } else if (n == ""){
    n = 0
  } else {
    return(NA)
  }
  #print(x * 10^n)
  return(x * 10^n)
}

propdamage <- mapply(multiplyexp, data$PROPDMG, data$PROPDMGEXP)
damagedata = subset(data, propdamage > 0)
===
arrange(desc(totalpropdam)) %>% mutate(evtype = factor(evtype, levels = evtype))
https://www.coursera.org/learn/reproducible-research/discussions/weeks/4/threads/38y35MMiEeiERhLphT2-QA
==
https://rstudio-pubs-static.s3.amazonaws.com/58957_37b6723ee52b455990e149edde45e5b6.html
How To Handle Exponent Value of PROPDMGEXP and CROPDMGEXP

https://en.wikipedia.org/wiki/FIPS_county_code